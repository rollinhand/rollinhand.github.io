<?xml version="1.0"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>JBake</title>
    <link>https://kivio.org</link>
    <atom:link href="https://kivio.org/feed.xml" rel="self" type="application/rss+xml" />
    <description>JBake Bootstrap Template</description>
    <language>en-gb</language>
    <pubDate>Mon, 17 Feb 2025 12:47:00 +0000</pubDate>
    <lastBuildDate>Mon, 17 Feb 2025 12:47:00 +0000</lastBuildDate>

    <item>
      <title>SQLPlus mit Homebrew installieren</title>
      <link>https://kivio.org/blog/entry/2022/09/05/sqlplus-mit-homebrew-installieren.html</link>
      <pubDate>Mon, 5 Sep 2022 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2022/09/05/sqlplus-mit-homebrew-installieren.html</guid>
      	<description>
	&lt;p&gt;Homebrew ist der ultimative Paketmanager für macOS. Auch eher dem kommerziellen Bereich zuzuordnende Software wie bspw. Oracle SQLPlus lässt sich über Homebrew installieren.&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;Die Installation über Homebrew ist denkbar einfach und erfordert keine manuellen Schritte, kein Akzeptieren von Lizenzvereinbarungen und auch kein Kopieren von Dateien in irgendwelche Ordner.&lt;/p&gt;
&lt;p&gt;Im &lt;em&gt;Terminal&lt;/em&gt; müssen lediglich die folgenden drei Befehle abgesetzt werden:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ brew tap InstantClientTap/instantclient
$ brew install instantclient-basic
$ brew install instantclient-sqlplus
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Anschließend ist &lt;code&gt;sqlplus&lt;/code&gt; im Pfad verfügbar.&lt;/p&gt;
&lt;p&gt;Danke an &lt;a href=&quot;https://vanwollingen.nl/install-oracle-instant-client-and-sqlplus-using-homebrew-a233ce224bf&quot;&gt;Joost van Wollingen für diesen Tipp&lt;/a&gt;.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>JRE mit Eclipse RCP-Anwendung bündeln</title>
      <link>https://kivio.org/blog/entry/2020/07/09/jre-mit-eclipse-rcp-anwendung-bundeln.html</link>
      <pubDate>Thu, 9 Jul 2020 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2020/07/09/jre-mit-eclipse-rcp-anwendung-bundeln.html</guid>
      	<description>
	&lt;p&gt;Die Auslieferung der eigenen Eclipse RCP-Anwendung ist mit &lt;a href=&quot;../../../2020/06/28/eclipse-rcp-tipps-und-tricks.html&quot;&gt;Tycho fast ein Kinderspiel&lt;/a&gt;. Ebenso einfach lässt sich die Anwendung auch mit ihrer eigenen Java Laufzeitumgebung (JRE) bündeln. In diesem Beitrag zeige ich wie das funktioniert und stelle alternative Wege vor.&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;Seit einiger Zeit ist der Bau von Eclipse-Anwendungen mit Tycho der präferierte Weg, um eine auslieferbare Anwendung zu erstellen. Während in der guten, alten Plugin Development Environment (PDE) beim Produkt-Export eine Execution Environment angegeben werden kann, ist dies bei Tycho nicht so offensichtlich.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;rcp01-jre-product-launching.png&quot; style=&quot;width:70%;margin:auto&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Tycho nutzt das Konzept der &lt;a href=&quot;https://help.eclipse.org/2019-12/index.jsp?topic=%2Forg.eclipse.pde.doc.user%2Ftasks%2Fpde_rootfiles.htm&quot;&gt;Root files&lt;/a&gt; zur Einbindung von statischen Dateien und somit auch der JRE.&lt;/p&gt;
&lt;h2&gt;Nutzung von Root files&lt;/h2&gt;
&lt;p&gt;Die &lt;a href=&quot;https://help.eclipse.org/2019-12/index.jsp?topic=%2Forg.eclipse.pde.doc.user%2Ftasks%2Fpde_rootfiles.htm&quot;&gt;Root files&lt;/a&gt; sind ein Relikt aus dem PDE-Build. Root files finden immer dann Verwendung in einem Build von Eclipse-Anwendungen, wenn statische Dateien oder Ordner in eine Installation eingebunden werden müssen, die sich nicht über ein Feature oder Plugin abbilden lassen.&lt;/p&gt;
&lt;p&gt;Typische Beispiele sind die &lt;em&gt;config.ini&lt;/em&gt; oder Lizenzdateien. Ebenso Eclipse-Installationen mit einer paketierten JRE. Über die Datei &lt;em&gt;build.properties&lt;/em&gt; wird das Hinzufügen statischer Elemente zur Installation gesteuert. Die Konfiguration folgt einem Baum-artigen Muster bzw. ist vergleichbar mit den Property-Strukturen in Java. Die Parameter beginnen immer mit &lt;em&gt;root&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Details zu den &lt;a href=&quot;https://help.eclipse.org/2019-12/index.jsp?topic=%2Forg.eclipse.pde.doc.user%2Ftasks%2Fpde_rootfiles.htm&quot;&gt;Root files&lt;/a&gt; können der offiziellen &lt;a href=&quot;https://help.eclipse.org/2019-12/index.jsp?topic=%2Forg.eclipse.pde.doc.user%2Ftasks%2Fpde_rootfiles.htm&quot;&gt;Eclipse Hilfe&lt;/a&gt; entnommen werden. Die Möglichkeiten sind einen eigenen Blogbeitrag wert.&lt;/p&gt;
&lt;h2&gt;Statisches Bundling über Rootfiles&lt;/h2&gt;
&lt;p&gt;Zum &lt;a href=&quot;http://eclipseo.blogspot.com/2014/11/bundle-jre-along-with-your-product.html&quot;&gt;Bündeln der JRE mit dem eigenen Produkt&lt;/a&gt;, sollte zunächst ein eigenes Feature erstellt werden, dass ausschließlich für die Verwaltung der auszuliefernden Laufzeitumgebungen für die unterstützten Plattformen genutzt wird.&lt;/p&gt;
&lt;p&gt;Innerhalb des Features werden für die verschiedenen Umgebungen Ordner angelegt in die die JRE kopiert wird (siehe Screenshot).&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;rcp01-jre-folder-structure.png&quot; style=&quot;width:40%;margin:auto&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Dabei spielt die Bezeichnung des Root-Ordners keine Rolle. Wichtig ist der Ordner mit dem Namen &lt;em&gt;jre&lt;/em&gt; unterhalb. Beim Produktexport wird dieser in den Root-Ordner des Produkts exportiert. Die Eclipse-Launcher suchen parallel zu ihrem Installationsort nach einem Verzeichnis mit dem Namen &lt;em&gt;jre&lt;/em&gt; und nutzen die darin befindliche JRE zum Start der Eclipse-Anwendung.&lt;/p&gt;
&lt;p&gt;Im Screenshot sind die Laufzeitumgebungen für die 64-Bit Versionen von Windows, Linux und Mac OS zu sehen. Die Magie beim Bauen und die Zuordnung zur exportierten Umgebung erfolgt über die Datei &lt;em&gt;build.properties&lt;/em&gt;, die im Textmodus bearbeitet werden muss. Die grafische Ansicht in der Eclipse IDE unterstützt das Editieren von Root files derzeit nicht. In die Datei fügen wir die folgenden Zeilen ein:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;root.win32.win32.x86_64 = win64
root.macosx.cocoa.x86_64 = osx64
root.linux.gtk.x86_64 = lnx64
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Final sollte die &lt;em&gt;build.properties&lt;/em&gt; wie folgt aussehen:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;rcp01-jre-build-properties.png&quot; style=&quot;width:40%;margin:auto&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Die Struktur für die Definition der Root files folgt damit den Parametern zur Definition einer Target Environment in Tycho.&lt;/p&gt;
&lt;p&gt;Anschließend muss das Feature noch in der Produkt-Definition eingefügt werden, sodass es beim Materialisieren des Produkts berücksichtigt wird.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;rcp01-jre-product-definition.png&quot; width=&quot;894&quot; width=&quot;366&quot; style=&quot;width:70%;margin:auto&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Beim Bau der Anwendung mittels Maven/Tycho werden die Angaben für die Zielumgebung auf Basis der Architektur und des Betriebssystems interpretiert und im erstellten Produktverzeichnis jeweils ein Verzeichnis  mit dem Namen &lt;em&gt;jre&lt;/em&gt; passend zur exportierten Plattform erstellt.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;rcp01-jre-final-folder.png&quot; style=&quot;width:40%;margin:auto&quot; /&gt;&lt;/p&gt;
&lt;h2&gt;Mehr Dynamik mit dem Maven-Universum&lt;/h2&gt;
&lt;p&gt;Die vorangegangenen Ausführungen haben einen Schwachpunkt=Wenn das Projekt versioniert ist (was es in einem professionellen Kontext hoffentlich ist), so werden Binärdateien zusammen mit dem Source-Code eingecheckt. Das ist nicht schön und sehr statisch.&lt;/p&gt;
&lt;p&gt;Besser wäre es, die aktuelle JRE für die jeweiligen Umgebungen während des Builds zu laden und dynamisch einzubinden. Damit wird vergleichbar den Maven Dependencies ein Mechanismus geschaffen, der bei Bedarf Abhängigkeiten aus einer zentralen Quelle lädt. Damit dies nicht bei jedem Build von vorne passiert, sollte das dafür zuständige Plugin wissen, welche Dateien bereits geladen worden sind.&lt;/p&gt;
&lt;p&gt;Genau für diesen Zweck existiert das &lt;a href=&quot;https://github.com/maven-download-plugin/maven-download-plugin&quot;&gt;Download Plugin&lt;/a&gt; für Maven. Es besitzt das Goal &lt;em&gt;wget&lt;/em&gt; zum Laden von Dateien aus HTTP-Quellen ohne die Nutzung von zusätzlichen ANt Skripten. Weiterhin unterstützt es Caching und kann bei der Angabe eines MD5-Hashes die Signatur eines heruntergeladenen Artefakts prüfen.&lt;/p&gt;
&lt;p&gt;Ein weiteres Goodie=Mit der Option &lt;em&gt;unpack&lt;/em&gt; können komprimierte Artefakte direkt im Zielverzeichnis entpackt werden. Es ist nicht notwendig, das Maven Assembly-Plugin separat zu starten.&lt;/p&gt;
&lt;p&gt;In unserem vorangegangenem Beispiel wird nun die POM überarbeitet. Für alle unterstützten Zielarchitekturen laden wir das Adopt OpenJDK und entpacken es in das Zielverzeichnis.&lt;/p&gt;
&lt;p&gt;Anschließend wird das Verzeichnis noch in &lt;em&gt;jre&lt;/em&gt; mithilfe des Antrun-Plugins umbenannt.&lt;/p&gt;
&lt;script src=&quot;https://gist.github.com/rollinhand/2db9c15eb483fb9ab5a7f8765ea29599.js&quot;&gt;&lt;/script&gt;
&lt;p&gt;Das vollständige Beispiel inkl. kompilierfähiger und ausführbarer Anwendung findet sich auf &lt;a href=&quot;https://github.com/rollinhand/eclipse-rcp-examples&quot;&gt;Github&lt;/a&gt; in den RCP Examples als rcp01 klassifiziert.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>Eclipse RCP - Tipps und Tricks</title>
      <link>https://kivio.org/blog/entry/2020/06/28/eclipse-rcp-tipps-und-tricks.html</link>
      <pubDate>Sun, 28 Jun 2020 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2020/06/28/eclipse-rcp-tipps-und-tricks.html</guid>
      	<description>
	&lt;p&gt;&lt;a href=&quot;https://www.vogella.com&quot;&gt;Lars Vogel&lt;/a&gt; hat mit seinen &lt;a href=&quot;https://www.vogella.com&quot;&gt;Tutorials zu Eclipse RCP&lt;/a&gt; eine solide Basis geschaffen, um mit Eclipse RCP Anwendungen zu entwickeln. Es gibt allerdings trotz der umfangreichen Beispiele immer wieder Fallstricke, die das Arbeiten mit RCP zu keinem Genuss machen. In diesem Beitrag zeige ich ein paar immer wieder auftretende Probleme und wie diese gelöst werden können.&lt;/p&gt;
&lt;!--more--&gt;
&lt;h2&gt;RCP-Projekte mit Maven und Tycho bauen&lt;/h2&gt;
&lt;p&gt;Auf Eclipse RCP basierende Projekte lassen sich seit einigen Jahren fast problemlos mit &lt;a href=&quot;https://www.eclipse.org/tycho/&quot;&gt;Tycho&lt;/a&gt; bauen. Von der Eclipse Foundation wird der Ansatz mit Maven und Tycho weiter gefördert und gilt inzwischen als der präferierte Weg, eine RCP-Anwendung zu bauen und zu einem Produkt zu bündeln. Der Weg über die Plugin Development Environment (PDE) gilt inzwischen als &lt;em&gt;deprecated&lt;/em&gt; und sollte bei neuen Projekten nicht mehr genutzt werden. Die Abkehr von der PDE zeigt sich auch in der Projekthistorie: so finden Bugfixes und Backports keinen Eingang mehr in die PDE.&lt;/p&gt;
&lt;p&gt;Allerdings ist Tycho und insbesondere die Auflösung von Abhängigkeiten noch nicht perfekt und Fehlermeldungen sind beizeiten kryptisch.&lt;/p&gt;
&lt;p&gt;Beispiel gefällig?&lt;/p&gt;
&lt;h3&gt;Equinox-Launcher Artefakte für Produkt-Materialisierung einbinden&lt;/h3&gt;
&lt;p&gt;In der Produkt-Definition für eine RCP-Anwendung kann festgelegt werden, dass beim Build native Launcher-Artefakte erstellt werden. Das sind die Executables und Windows oder die paketierten App-Bundles unter Mac OS, die eine Java Laufzeitumgebung mit den notwendigen Artefakten und die Eclipse Runtime und weitere Plugins starten.&lt;/p&gt;
&lt;p&gt;Leider gehören die Artefakte weder zum &amp;ldquo;E4 RCP Feature&amp;rdquo; noch zum normalen &amp;ldquo;RCP Feature&amp;rdquo;. Wird der Build gestartet, so kommt es bei der Produkt-Materialisierung zu einer &lt;a href=&quot;https://www.eclipse.org/forums/index.php/t/1082939/&quot;&gt;Exception&lt;/a&gt;, die nicht sonderlich aussagekräftig ist.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;[DEBUG] No solution found because the problem is unsatisfiable.=[Unable to satisfy dependency from org.kivio.depot.product 1.0.0.qualifier to org.eclipse.equinox.executable.feature.group 0.0.0.; No solution found because the problem is unsatisfiable.]
[INFO] {osgi.os=win32, osgi.ws=win32, org.eclipse.update.install.features=true, osgi.arch=x86_64}
[ERROR] Cannot resolve project dependencies:
[ERROR] Software being installed=org.kivio.depot.product 1.0.0.qualifier
[ERROR] Missing requirement=org.kivio.depot.product 1.0.0.qualifier requires &apos;org.eclipse.equinox.executable.feature.group 0.0.0&apos; but it could not be found
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Hinter dem fehlenden Feature &amp;ldquo;org.eclipse.equinox.executable.feature.group&amp;rdquo; verbergen sich die &lt;a href=&quot;https://stackoverflow.com/questions/20235184/building-an-eclipse-plugin-using-maven&quot;&gt;&amp;ldquo;Eclipse Platform Launcher Executables&amp;rdquo;&lt;/a&gt;. Jeder RCP-Entwickler sollte dieses Feature also auch in seine Target Platform integrieren, wenn bei der Produkterstellung native Launcher erstellt werden sollen. Eine andere Lösung ist, den Haken für native Launcher in der &lt;a href=&quot;https://stackoverflow.com/questions/20235184/building-an-eclipse-plugin-using-maven&quot;&gt;Produktdefinition zu entfernen&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;OSGi-Bundles mit Apache Felix&lt;/h2&gt;
&lt;p&gt;Mit dem &lt;a href=&quot;https://felix.apache.org/components/bundle-plugin/&quot;&gt;Apache Maven Bundle&lt;/a&gt; lassen sich aus eigenem Code oder bestehenden Drittbibliotheken OSGi-Bundles erstellen, die zusätzliche Informationen zu den nach außen exponierten Packages sowie der internen Benennung und noch viel mehr enthalten. Entweder kann in der POM-Datei im Detail angegeben werden, wie die MANIFEST.MF erzeugt werden soll oder es kann eine feste MANIFEST.MF hinterlegt werden.&lt;/p&gt;
&lt;h3&gt;Dynamische MANIFEST.MF in Eclipse korrekt verwenden&lt;/h3&gt;
&lt;p&gt;Die dynamisch aus der POM erzeugte MANIFEST.MF sollte nach Möglichkeit nicht im &lt;em&gt;/target&lt;/em&gt;-Ordner erzeugt werden, da die Plugin-Entwicklung in Eclipse eigenen Gesetzen unterliegt, die historisch durch die PDE bedingt sind. Normalerweise haben Eclipse-Plugins die folgende Verzeichnisstruktur&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;+ my.plugin
+- bin
+- src
+- META-INF
+-- MANIFEST.MF
+- plugin.xml
+- build.properties
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In der POM sollte über das Attribut &lt;code&gt;manifestLocation&lt;/code&gt; das Verzeichnis &lt;em&gt;META-INF&lt;/em&gt; direkt unterhalb des Root-Verzeichnisses des Projekts erzeugt werden. Für den Build-Prozess über Maven ist das irrelevant, für den &lt;a href=&quot;https://github.com/takari/m2e-discovery-catalog&quot;&gt;M2E-Connector für das Maven Bundle (Tycho)&lt;/a&gt; nicht. Er interpretiert die Location in der POM-Datei und erzeugt über Alt+F5 das entsprechende Verzeichnis inkl. der zu generierenden MANIFEST.MF.&lt;/p&gt;
&lt;p&gt;So lässt sich nicht nur die MANIFEST.MF in einem grafischen Editor analysieren, sondern es ist auch möglich zwischen Eclipse-Plugins und OSGi-Bundles in Eclipse zu navigieren, indem die Dependencies angeklickt werden. Bei Projekten mit vielen Plugins und Abhängigkeiten, ein nicht zu unterschätzendes Feature.&lt;/p&gt;
&lt;h3&gt;Neu verpackte Bibliotheken&lt;/h3&gt;
&lt;p&gt;Code von Dritten, der keine OSGi-Informationen besitzt, kann mit dem Maven Bundle-Plugin neu verpackt werden, sodass dieser als Plugin bzw. Bundle in einer RCP-Anwendung genutzt werden kann.&lt;/p&gt;
&lt;p&gt;Es besteht die Option, den Code &lt;em&gt;inline&lt;/em&gt; zu übernehmen. Dabei wird das Original-JAR entpackt und die enthaltenen Code-Fragmente in ihre Original-Struktur in das neue Paket übernommen. dadurch kann als Classpath-Angabe in der MANIFEST.MF der Punkt (.) genutzt werden.&lt;/p&gt;
&lt;p&gt;Mit dieser Möglichkeit leidet allerdings der Komfort bei der Entwicklung in der Eclipse-Umgebung, wenn ausschließlich Drittbibliotheken neu paketiert und als Abhängigkeit verwendet werden sollen.&lt;/p&gt;
&lt;p&gt;Solange wie die Projekte als Abhängigkeit in der Eclipse geöffnet sind, versucht die IDE zunächst die Abhängigkeit in den eigenen Projekten aufzulösen. Das wird auch funktionieren. Dabei werden allerdings keine Sourcen gefunden, da &lt;em&gt;inline&lt;/em&gt; durch M2E Tycho nicht interpretiert wird. Abhängige Projekte zeigen dadurch Kompilierfehler an und werden in der IDE mit einem roten X markiert.&lt;/p&gt;
&lt;p&gt;Dieses Vorgehen ist mehr als verwirrend, da das fertig gebaute und transformierte Bundle natürlich die richtigen Sourcen enthält. Folgende beiden Best Practices bieten sich daher an:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Soll &lt;em&gt;inline&lt;/em&gt; genutzt werden, ist das Projekt zu bauen und in das lokale Maven Repository zu installieren. Es sollte nicht zusammen mit dem abhängigen Projekt in der Eclipse IDE geöffnet sein.&lt;/li&gt;
&lt;li&gt;Alternativ können auch die Original JAR-Dateien erhalten und der Classpath in der MANIFEST.MF auf die JAR-Datei erweitert werden. Dadurch kann das Projekt neben der Abhängigkeit in der Eclipse-Umgebung geöffnet bleiben, da Eclipse die Original JAR-Datei in die Abhängigkeiten zieht.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;M2Eclipse-Tycho - Achtung beim Einsatz von Felix Bundle Plugin&lt;/h3&gt;
&lt;p&gt;Bei dem Einsatz von Tycho zusammen mit Maven übernimmt in der Eclipse IDE der &lt;a href=&quot;https://github.com/takari/m2e-discovery-catalog&quot;&gt;M2E-Tycho Connector&lt;/a&gt; die Übersetzung der verschiedenen Maven Goals sowohl für Tycho als auch das Maven Bundle Plugin. So werden Code und MANIFEST-Dateien im Hintergrund erstellt.&lt;/p&gt;
&lt;p&gt;Aus einem nicht dokumentierten Grund hat die LATEST-Version aus dem 0.9.0-Zweig des M2E-Connectors eine Einschränkung auf die Maven Bundle Version bis 3.2.0. Höhere Versionen (aktuell ist 4.2.1) werden mit dem 0.9.0-Zweig nicht länger unterstützt. Kompiliert die Eclipse IDE im Hintergrund keinen Code mehr oder erzeugt keine MANIFEST-Datei, so ist der Fehler in der aktuellen Version des M2E-Connectors zu suchen.&lt;/p&gt;
&lt;p&gt;Es kann problemlos eine ältere Version des Connectors ohne Einschränkung über die Update site (statt dem M2E-Store) installiert werden. Es ist allerdings darauf zu achten, dass über den Update-Site Mechanismus zunächst die neuere Version des Connectors deinstalliert wird.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>Exception Mapper mit Apache CXF</title>
      <link>https://kivio.org/blog/entry/2020/06/11/exception-mapper-mit-apache-cxf.html</link>
      <pubDate>Thu, 11 Jun 2020 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2020/06/11/exception-mapper-mit-apache-cxf.html</guid>
      	<description>
	&lt;p&gt;Exception Mapper in Verbindung mit REST-Services vereinfachen nicht nur den Code, sondern sorgen auch dafür, dass Exceptions identisch behandelt und den gleichen Fehlercode an den Aufrufer zurückliefern. In diesem Blog-Beitrag zeige ich, wie das mit &lt;a href=&quot;http://cxf.apache.org&quot;&gt;Apache CXF&lt;/a&gt; und &lt;a href=&quot;../../../2020/04/30/meecrowave-microservices-ohne-aufwandiges-framework.html&quot;&gt;Meecrowave&lt;/a&gt; funktioniert und die Anwendung auch für andere Servlet-Container oder Java EE-Server portabel bleibt.&lt;/p&gt;
&lt;!--more--&gt;
&lt;h2&gt;Die individuelle Exception werfen&lt;/h2&gt;
&lt;p&gt;Exceptions sind dazu geschaffen worden, einer Methode die Möglichkeit zu bieten, die Verarbeitung umgehend und kontrolliert zu beenden und das &amp;ldquo;Problem&amp;rdquo; an den Aufrufer zu delegieren. Anstatt nun auf die Standard-Exceptions der Sprache Java zu setzen, erweist es sich als Good Practice eigene Exceptions zu definieren, um so die Verarbeitung im eigenen Code gezielter beeinflussen zu können.&lt;/p&gt;
&lt;p&gt;Gerade im Domain Driven Design sollten Objekte ihre eigenen Exceptions mitbringen, um in der gemeinsamen Sprachwelt (Ubiquitous Language) zu bleiben.&lt;/p&gt;
&lt;p&gt;Bei der Verwendung von REST-Services in einer Anwendung, kann der Service (der Aufgerufene) auch das Problem an den Aufrufer delegieren. Gründe hierfür könnten sein, dass&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;übergebene Parameter nicht plausibel sind,&lt;/li&gt;
&lt;li&gt;angeforderte Daten nicht verfügbar sind,&lt;/li&gt;
&lt;li&gt;die aufgerufene Aktion auf einen Fehler gelaufen ist.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Es lassen sich sicherlich noch viel mehr Gründe finden. Für mein Beispiel greife ich wieder auf den &lt;a href=&quot;https://github.com/rollinhand/meecrowave-example&quot;&gt;Person-Server&lt;/a&gt; zurück, der auch schon im initialen &lt;a href=&quot;../../../2020/04/30/meecrowave-microservices-ohne-aufwandiges-framework.html&quot;&gt;Blogbeitrag zu Meecrowave&lt;/a&gt; herangezogen worden ist.&lt;/p&gt;
&lt;p&gt;Im Model ist die Klasse &lt;code&gt;PersonException&lt;/code&gt; definiert, die im Backend immer geworfen wird, wenn eine Aktion auf einem Objekt der Klasse &lt;code&gt;Person&lt;/code&gt; fehlschlägt. Es handelt sich dabei um eine &lt;code&gt;RuntimeException&lt;/code&gt;, sodass diese auch nicht bei jedem Methodenaufruf definiert werden muss.&lt;/p&gt;
&lt;h2&gt;Der REST-Endpunkt&lt;/h2&gt;
&lt;p&gt;Im Beispiel existiert der REST-Endpunkt &lt;code&gt;PersonEndpoint&lt;/code&gt;, der verschiedene Aktionen bzw. Methoden zur Verfügung stellt. Ein Auszug ist im Folgenden dargestellt:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;@RequestScoped
@Path(&amp;quot;/person&amp;quot;)
public class PersonEndpoint {
  @Inject
  private IPersonService personService;

  @DELETE
  @Path(&amp;quot;/{id}&amp;quot;)
  public Response removeById(@PathParam(&amp;quot;id&amp;quot;) String id) {
    personService.removeById(id);
    return Response.ok().build();
  }
  // snipped other methods
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Die Klasse &lt;code&gt;PersonEndpoint&lt;/code&gt; delegiert die Aufrufe an eine Implementierung von &lt;code&gt;IPersonService&lt;/code&gt; und überlässt dieser die Verarbeitung. Für den weiteren Verlauf des Beispiels beschränke ich mich auf die Methode zum Löschen einer Person über ihre ID. (&lt;code&gt;removeById&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;Ist der Aufruf erfolgreich, so wird der HTTP-Status OK (200) an den Aufrufer zurückgeliefert. Aber was passiert, wenn der Aufruf scheitert, weil über die ID keine Person zur Löschung gefunden werden kann? Die Code-Passage im obigen Beispiel lässt auf den ersten Blick vermuten, dass immer OK an den Aufrufer zurückgeliefert wird.&lt;/p&gt;
&lt;p&gt;Im ersten Moment kribbelt es in den Fingern, die Code-Passage vielleicht so zu ändern:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;@DELETE
@Path(&amp;quot;/{id}&amp;quot;)
public Response removeById(@PathParam(&amp;quot;id&amp;quot;) String id) {
  if (personService.removeById(id)) {
    return Response.ok().build();
  } else {
    return Response.notModified().build();
  }	
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Schön geht anders und die Zeiten, dass Methoden oder Funktionen ihren Status über Codes oder boolesche Werte mitteilen sind seit der objektorientierten Programmierung und der Einführung von Exceptions vorbei.&lt;/p&gt;
&lt;p&gt;Ein Blick auf die Methode &lt;code&gt;removeById&lt;/code&gt; im eigentlichen Service bringt mehr Klarheit:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;@Override
public void removeById(String id) {
  Optional&amp;lt;Person&amp;gt; person = findById(id);

  if (person.isPresent()) {
    log.info(&amp;quot;Removing person {}&amp;quot;, person);
    remove(person.get());
  } else {
    throw new PersonException(&amp;quot;Person with UUID &amp;quot; + id + &amp;quot; not found&amp;quot;);
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Kann die Person nicht gefunden werden, so wird die &lt;code&gt;PersonException&lt;/code&gt; geworfen. Damit innerhalb des REST-Services keine Catch-Routinen eingeführt werden müssen, existieren im JAX-RS Standard Exception Mapper, die genau diese Rolle übernehmen und dafür sorgen, dass der Code aufgeräumter wirkt und einen aspektorientierten Ansatz bekommt.&lt;/p&gt;
&lt;h2&gt;Exception Mapper mit Apache CXF&lt;/h2&gt;
&lt;p&gt;Mit &lt;a href=&quot;http://cxf.apache.org&quot;&gt;Apache CXF&lt;/a&gt; lassen sich einfach REST- und SOAP-Services implementieren. Für REST bietet Apache CXF eine JAX-RS konforme Implementierung, sodass sich Exception Mapper definieren und einbinden lassen. Im Beispiel sieht der Exception Mapper wie folgt aus:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;@Provider
public class PersonExceptionMapper implements ExceptionMapper&amp;lt;PersonException&amp;gt;{
  @Override
  public Response toResponse(PersonException exception) {
    return Response.status(Status.NOT_ACCEPTABLE).entity(exception.getMessage()).build();
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Der Mapper sorgt dafür, dass jede im REST-Kontext über den &lt;code&gt;PersonService&lt;/code&gt; geworfene &lt;code&gt;PersonException&lt;/code&gt; abgefangen und in einen HTTP-Response mit einem einheitlichen Status gepackt wird.&lt;/p&gt;
&lt;p&gt;Über die Annotation &lt;em&gt;@Provider&lt;/em&gt; definiert der JAX-RS Standard, dass so Erweiterungen bekannt gemacht werden können. Leider interpretiert Apache CXF diese Annotation zum Zeitpunkt dieses Beitrags noch nicht und auch die Implementierung in Meecrowave bietet hierfür noch keine Unterstützung.&lt;/p&gt;
&lt;p&gt;Nur mit dieser Code-Passage wird die Exception folglich ungefiltert geworfen und führt zu einem &amp;ldquo;wunderbaren&amp;rdquo; Stack-Trace den wir nicht sehen wollen. Abhilfe lässt sich über die &lt;em&gt;beans.xml&lt;/em&gt; schaffen, die je nach Paketierung entweder in den Verzeichnissen WEB-INF oder META-INF abgelegt werden sollte.&lt;/p&gt;
&lt;p&gt;Dort kann die Erweiterung Apache CXF bekannt gemacht werden:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;jaxrs:server id=&amp;quot;personServer&amp;quot; address=&amp;quot;/&amp;quot;&amp;gt;
    &amp;lt;jaxrs:serviceBeans&amp;gt;
        &amp;lt;ref bean=&amp;quot;org.kivio.server.endpoints.PersonEndpoint&amp;quot; /&amp;gt;
    &amp;lt;/jaxrs:serviceBeans&amp;gt;
    &amp;lt;jaxrs:providers&amp;gt;
        &amp;lt;bean
            class=&amp;quot;org.kivio.server.endpoints.NullPointerExceptionMapper&amp;quot; /&amp;gt;
        &amp;lt;bean
            class=&amp;quot;org.kivio.server.endpoints.PersonExceptionMapper&amp;quot; /&amp;gt;
    &amp;lt;/jaxrs:providers&amp;gt;
&amp;lt;/jaxrs:server&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Über die zusätzliche Konfiguration in der &lt;em&gt;beans.xml&lt;/em&gt; wird zunächst im Attribut &lt;em&gt;serviceBeans&lt;/em&gt; festgelegt, welche Beans REST-Services nach dem JAX-RS Standard sind. Über das Attribut &lt;em&gt;providers&lt;/em&gt; werden die Klassen benannt, die Erweiterungen für JAX-RS bieten.&lt;/p&gt;
&lt;p&gt;Mit CURL kann die Funktionalität getestet werden:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;curl -v -XDELETE http://localhost:8080/person/2020
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Und erhalten als Ausgabe einen sauberen HTTP-Response und keinen Stack-Trace.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; DELETE /person/2020 HTTP/1.1
&amp;gt; Host=localhost:8080
&amp;gt; User-Agent=curl/7.64.1
&amp;gt; Accept=*/*
&amp;gt; 
&amp;lt; HTTP/1.1 406 
&amp;lt; Date=Thu, 11 Jun 2020 14:14:42 GMT
&amp;lt; Content-Type=application/octet-stream
&amp;lt; Content-Length=31
&amp;lt; 
* Connection #0 to host localhost left intact
Person with UUID 2020 not found* Closing connection 0
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;Portabilität&lt;/h2&gt;
&lt;p&gt;Wird die Anwendung in einem Java EE-Server betrieben, der keine Apache CXF-Implementierung sondern Jersey oder RESTEasy nutzt, kann die Konfiguration in der &lt;em&gt;beans.xml&lt;/em&gt; entfallen.&lt;/p&gt;
&lt;h2&gt;Zusammenfassung&lt;/h2&gt;
&lt;p&gt;Mit Exception Mappern lässt sich auch in Verbindung mit Apache CXF verständlicher und schlanker Code schreiben. Boilerplate-Code innerhalb des REST-Services wird somit vermieden und Exceptions werden nach außen einheitlich behandelt. Die Idee hinter Exceptions, den Fehler an den Aufrufer zu delegieren wird direkt unterstützt. Auch wenn zusätzliche Konfiguration in der &lt;em&gt;beans.xml&lt;/em&gt; notwendig ist, bleibt die Anwendung dennoch portabel.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>Hibernate&amp;#58; Hilfe, mein Class-Mapping funktioniert nicht mehr</title>
      <link>https://kivio.org/blog/entry/2020/06/04/hibernate-hilfe-mein-class-mapping-funktioniert-nicht-mehr.html</link>
      <pubDate>Thu, 4 Jun 2020 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2020/06/04/hibernate-hilfe-mein-class-mapping-funktioniert-nicht-mehr.html</guid>
      	<description>
	&lt;p&gt;Zuletzt war ich in einem Projekt beschäftigt, dass für seine Persistenz noch auf Hibernate 3.2.0 und Mapping-Dateien (hbm-Dateien) im XML-Format gesetzt hat aus dem sich auch persistente Klassen generieren lassen. Mit dem zunächst sanften Upgrade auf Hibernate 3.6.10 konnten persistente Klassen nicht mehr über die Klasse &lt;code&gt;Configuration&lt;/code&gt; gefunden werden. Oups! Was war zu tun?&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;In vielen Legacy-Projekten mit Hibernate gibt es die berühmt berüchtigte Klasse HibernateUtil, die bspw. genutzt wird die Konfiguration einzulesen, die SessionFactory zur Verfügung zu stellen und sonstige Funktionalitäten, die von einer Utility-Klasse erwartet werden.&lt;/p&gt;
&lt;p&gt;Unter anderem auch die Möglichkeit, dass aus dem kanonischen Namen einer Klasse die Mapping-Informationen aufgelöst werden können:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;Configuration cfg = Configuration.configure();
String className = &amp;quot;org.kivio.depot.Aktie&amp;quot;;
PersistentClass cls  = cfg.getClassMapping(className); 
Table tbl = cls.getTable();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Seit Hibernate 3.6 liefert &lt;code&gt;cfg.getClassMapping&lt;/code&gt; einen Null-Wert zurück und beim Debuggen stellt sich heraus, dass die zugrunde liegende Map in der Klasse &lt;code&gt;Configuration&lt;/code&gt; keine Werte enthält. Das bedeutet, dass beim Erzeugen der &lt;code&gt;Configuration&lt;/code&gt; die Mappings nicht mehr erzeugt bzw. übersetzt werden.&lt;/p&gt;
&lt;p&gt;Damit dies auch mit neueren Versionen von Hibernate funktioniert, sind die Mappings explizit zu erzeugen. Die Übersetzung aus den Mapping-XML-Dateien benötigt einen Moment und da der Trend zu Annotationen-basierter Programmierung geht, wurde diese für die Initialisierung aufwändige Funktionalität aus dem automatischen Prozess entfernt.&lt;/p&gt;
&lt;p&gt;Damit die Mappings auch weiterhin über &lt;code&gt;getClassMapping&lt;/code&gt; abgerufen werden können, ist die obige Code-Passage um die Anweisung &lt;code&gt;cfg.buildMappings()&lt;/code&gt; zu ergänzen.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;Configuration cfg = Configuration.configure();
cfg.buildMappings();    // call explicit
String className = &amp;quot;org.kivio.depot.Aktie&amp;quot;;
PersistentClass cls  = cfg.getClassMapping(className); 
Table tbl = cls.getTable();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Dadurch verlängert sich die Initialisierung und die Erstellung der Konfiguration, im Anschluss stehen die Mapping-Informationen allerdings wieder programmatisch zur Verfügung.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>Maven Surefire und Probleme mit dem Classpath</title>
      <link>https://kivio.org/blog/entry/2020/05/29/maven-surefire-und-probleme-mit-dem-classpath.html</link>
      <pubDate>Fri, 29 May 2020 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2020/05/29/maven-surefire-und-probleme-mit-dem-classpath.html</guid>
      	<description>
	&lt;p&gt;In meinem letzten Projekt beim Kunden bin ich auf ein interessantes Problem im Maven Surefire Plugin gestoßen. Während meine Unit-Tests in der Eclipse-Umgebung problemlos liefen, warf Maven auf der Kommandozeile beim Aufruf von &lt;code&gt;Class.forName()&lt;/code&gt; eine ClassNotFoundException. Was war da los?&lt;/p&gt;
&lt;!--more--&gt;
&lt;h2&gt;Der zu testende Code&lt;/h2&gt;
&lt;p&gt;Die zu testende Code-Passage, die mit Maven Surefire und Junit 4.12 auf der Kommandozeile immer wieder fehlegschlagen ist, sah in etwa so aus:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;final String className = &amp;quot;org.kivio.depot.Isin&amp;quot;
Class&amp;lt;?&amp;gt; clazz = (Class&amp;lt;?&amp;gt;)Class.forName(className);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;An dieser Stelle zunächst nichts besonderes. Die Klasse &lt;code&gt;Isin&lt;/code&gt; befindet sich allerdings in einem als Dependency deklarierten Jar-File, dass für den Test benötigt wird.&lt;/p&gt;
&lt;h2&gt;Die Besonderheit von Maven Surefire&lt;/h2&gt;
&lt;p&gt;Seit &lt;a href=&quot;surefire&quot;&gt;Maven Surefire 2.8.2&lt;/a&gt; ist die Behandlung des Classpath und somit auch die Testausführung geändert worden. Standardmäßig ist der System Class Loader aktiv und Maven Surefire startet alle Tests mit einem Manifest-Only JAR.&lt;/p&gt;
&lt;p&gt;Hierbei wird ein temporäres JAR erzeugt, dass nur den Inhalt &lt;code&gt;META-INF/MANIFEST.MF&lt;/code&gt; enthält. In dem MANIFEST sind über das Attribut &lt;em&gt;Class_Path&lt;/em&gt; alle notwendigen Abhängigkeiten für die Testausführung mit ihren absoluten Pfaden gesetzt.&lt;/p&gt;
&lt;p&gt;Und hier kommen wir zum eigentlichen Problem=System Class Loader, Thread Context Class Loader und der Default Class Loader sind identisch und verweisen auf das Maven Surefire Booter JAR, das wiederum Einträge zu den JAR-Dateien mit Klassen enthält, die in einem anderen Kontext geladen worden sind.&lt;/p&gt;
&lt;p&gt;Wenn eine Anwendung ihren Class Loader selbst nach JAR-Dateien oder Klassen befragt, ist es besser, wenn ein isolierter Class Loader genutzt wird, der alle Abhängigkeiten kennt. Das wäre in diesem Fall der korrekte Weg, um den Test zu starten und auf den System Class Loader zu setzen. Dies kann aber gerade im Embedded Kontext - also wenn Maven in einer IDE gestartet wird - wiederum zu anderen Problemen führen.&lt;/p&gt;
&lt;p&gt;Ein weiterer Grund doch eher auf den Manifest-Only-Ansatz zu setzen, ist die Möglichkeit, dass Surefire Tests parallel ausführen kann und daher Forks vom Hauptprozess erstellt. Beim Forken scheinen allerdings die Class Loader durcheinander zu kommen und die Wiederverwendung eines Forks durch Surefire sollte unterbunden werden. Und mit exakt diesem Ansatz kann das Class Loading-Problem umgangen werden.&lt;/p&gt;
&lt;h2&gt;Ein Parameter bringt die Rettung&lt;/h2&gt;
&lt;p&gt;Eine einfache Änderung der Konfiguration des Surefire-Plugins sorgt dafür, dass &lt;code&gt;Class.forName&lt;/code&gt;-Anweisungen im zu testenden Code funktionieren:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;plugin&amp;gt;
  &amp;lt;groupId&amp;gt;org.apache.maven.plugins&amp;lt;/groupId&amp;gt;
  &amp;lt;artifactId&amp;gt;maven-surefire-plugin&amp;lt;/artifactId&amp;gt;
  &amp;lt;configuration&amp;gt;
    &amp;lt;reuseForks&amp;gt;false&amp;lt;/reuseForks&amp;gt;
  &amp;lt;/configuration&amp;gt;
&amp;lt;/plugin&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Mit &lt;code&gt;reuseForks&lt;/code&gt; kann gesteuert werden, ob Surefire einen geforkten Prozess für einen weiteren Unit Test wiederverwenden soll. Durch die Unterbindung wird für jeden Testfall ein neuer Prozess gestartet und der Classpath korrekt gesetzt.&lt;/p&gt;
&lt;p&gt;Allerdings hat dieses Vorgehen auch einen gravierenden Nachteil, der nicht verschwiegen werden sollte=Bei vielen durchzuführenden Tests kommt die Garbage Collection ggf. nicht nach und es kommt zu einem Überschreiten des GC Overhead Limits.&lt;/p&gt;
&lt;p&gt;Die Option sollte also mit Vorsicht gesetzt werden.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>Meecrowave Maven Plugin mit Java 11 oder neuer</title>
      <link>https://kivio.org/blog/entry/2020/05/22/meecrowave-maven-plugin-mit-java-11-oder-neuer.html</link>
      <pubDate>Fri, 22 May 2020 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2020/05/22/meecrowave-maven-plugin-mit-java-11-oder-neuer.html</guid>
      	<description>
	&lt;p&gt;Das Meecrowave Maven Plugin sorgt nicht nur für die korrekte Bündelung der eigenen Anwendung in den Meecrowave Container sondern kann auch während der Entwicklung genutzt werden, um den Server zu starten und Debugging-Aktionen durchzuführen. Mit Java 11 und neuer kann das schief laufen. In dem Beitrag zeige ich, wie das Plugin weiterhin voll funktionsfähig bleibt.&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;Wer das Meecrowave Maven Plugin in einer älteren Version zusammen mit Java 11 oder neuer nutzt, stößt bei der Ausführung des Kommandos &lt;code&gt;mvn meecrowave:run&lt;/code&gt; schnell auf die Fehlermeldung:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;Caused by=java.lang.ClassNotFoundException=javax.xml.bind.JAXBException
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Seit Java 11 sind die &lt;em&gt;javax&lt;/em&gt;-Pakete aus der Java VM entfernt worden, sodass auch der Schalter &lt;code&gt;--add-modules ALL_SYSTEM&lt;/code&gt; keine Wirkung mehr zeigt. Es gehörte mit der Einführung von Jigsaw in Java 9 bereits zum schlechten Stil, auf diesem Weg auf der Streichliste stehende Module zu aktivieren.&lt;/p&gt;
&lt;p&gt;Um das Meecrowave Maven Plugin trotzdem zum Laufen zu bekommen, genügt es, dem Plugin eine zusätzliche Abhängigkeit mitzugeben:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-xml&quot;&gt;&amp;lt;plugin&amp;gt;
  &amp;lt;groupId&amp;gt;org.apache.meecrowave&amp;lt;/groupId&amp;gt;
  &amp;lt;artifactId&amp;gt;meecrowave-maven-plugin&amp;lt;/artifactId&amp;gt;
  &amp;lt;version&amp;gt;1.2.9&amp;lt;/version&amp;gt;
  &amp;lt;dependencies&amp;gt;
    &amp;lt;dependency&amp;gt;
      &amp;lt;groupId&amp;gt;javax.xml.bind&amp;lt;/groupId&amp;gt;
      &amp;lt;artifactId&amp;gt;jaxb-api&amp;lt;/artifactId&amp;gt;
      &amp;lt;version&amp;gt;2.3.1&amp;lt;/version&amp;gt;
    &amp;lt;/dependency&amp;gt;
  &amp;lt;/dependencies&amp;gt;
&amp;lt;/plugin&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Anschließend kann das Plugin wieder wie gewohnt benutzt werden.&lt;/p&gt;
&lt;p&gt;Und wer diese Verrenkung nicht vornehmen möchte, der wechselt auf die aktuellste Version von Meecrowave derzeit in der Version 1.2.9. Ab der Version 1.2.6 tritt der Fehler im Maven Plugin nicht mehr auf.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>Meecrowave und Docker - so einfach gehts</title>
      <link>https://kivio.org/blog/entry/2020/05/06/meecrowave-und-docker-so-einfach-gehts.html</link>
      <pubDate>Wed, 6 May 2020 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2020/05/06/meecrowave-und-docker-so-einfach-gehts.html</guid>
      	<description>
	&lt;p&gt;In einem meiner &lt;a href=&quot;../../../2020/04/30/meecrowave-microservices-ohne-aufwandiges-framework.html&quot;&gt;letzten Blogbeiträge&lt;/a&gt; habe ich darüber berichtet, wie einfach mit &lt;a href=&quot;https://openwebbeans.apache.org/meecrowave/&quot;&gt;Meecrowave&lt;/a&gt; ein Microservice erstellt werden kann. Heute geht es darum, den Microservice in ein Docker-Image zu bündeln und als Container zu starten.&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;Für das Beispiel mit Docker greife ich wieder auf mein Beispiel-Projekt aus dem &lt;a href=&quot;../../../2020/04/30/meecrowave-microservices-ohne-aufwandiges-framework.html&quot;&gt;initialen Blogbeitrag&lt;/a&gt; zu Meecrowave zurück. Zur besseren Nachvollziehbarkeit findet sich der Source-Code auf &lt;a href=&quot;https://github.com/rollinhand/meecrowave-example&quot;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Für das Docker-Experiment benötige ich die folgenden Plugins:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://openwebbeans.apache.org/meecrowave/meecrowave-maven/index.html&quot;&gt;Meecrowave Maven Plugin&lt;/a&gt;&lt;/strong&gt;=Mit diesem Plugin lässt sich nicht nur ein Meecrowave-Projekt mittels Maven starten, sondern über den Befehl &lt;code&gt;mvn meecrowave:bundle&lt;/code&gt; eine Distribution von Meecrowave erstellen, die alle notwendigen Bibliotheken sowie Skripte zum Starten und Stoppen des Servers mitliefert.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/fabric8io/docker-maven-plugin&quot;&gt;Docker Maven Plugin&lt;/a&gt;&lt;/strong&gt;=Das von Fabric8 bereitgestellte Plugin kann aus einem Dockerfile und ein wenig Konfiguration in Maven ein Docker-Image erzeugen. Dabei kann die Konfiguration des Docker-Images komplett über Maven oder ein natives Dockerfile vorgenommen werden.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Mit diesen zusätzlichen Plugins wird das Modul &lt;em&gt;person-server&lt;/em&gt; ausgestattet. Ich werde weiter unten im Blogbeitrag auf die Details eingehen.&lt;/p&gt;
&lt;h2&gt;Dockerfile bereitstellen&lt;/h2&gt;
&lt;p&gt;Ich habe mich dazu entschieden, nicht alle Funktionen des Docker Maven Plugins auszureizen, sondern auf ein natives &lt;em&gt;Dockerfile&lt;/em&gt; zurückzugreifen. Somit besteht nicht nur die Möglichkeit, das Image mit Maven zu bauen, sondern auch mittels &lt;code&gt;docker build&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Vergleichbar mit dem &lt;a href=&quot;https://helidon.io/#/&quot;&gt;Helidon-Projekt&lt;/a&gt; liegt das &lt;em&gt;Dockerfile&lt;/em&gt; im Root-Verzeichnis des Maven-Moduls &lt;em&gt;person-server&lt;/em&gt;.&lt;/p&gt;
&lt;script src=&quot;https://gist.github.com/rollinhand/c2f0f2fb2b6c74cb1a24b937e88e7423.js&quot;&gt;&lt;/script&gt;
&lt;p&gt;Das &lt;em&gt;Dockerfile&lt;/em&gt; basiert auf Adopt OpenJDK 8 und enthält zwei Besonderheiten in den Zeilen 8 und 13.&lt;/p&gt;
&lt;p&gt;Mit dem Meecrowave Maven Plugin lässt sich eine Distribution erzeugen, die in verschiedenen Unterverzeichnissen alle notwendigen Dateien enthält, um Meecrowave auf einem Unix- oder Windows-System zu starten.&lt;/p&gt;
&lt;p&gt;Damit die Distribution automatisch durch den Befehl &lt;strong&gt;ADD&lt;/strong&gt; entpackt wird, muss diese im Format &lt;em&gt;tar.gz&lt;/em&gt; vorliegen. Das ebenfalls produzierbare ZIP-Format wird durch Docker nicht als komprimiertes Archiv erkannt. In unserem Arbeitsverzeichnis &lt;em&gt;/opt&lt;/em&gt; wird das gepackte Verzeichnis in den Ordner &lt;em&gt;person-server&lt;/em&gt; extrahiert.&lt;/p&gt;
&lt;p&gt;Meecrowave bietet bei den Start-Skripten die Möglichkeit, verschiedene Parameter mitzugeben, sodass der Server entweder im Vorder- oder Hintergrund gestartet wird. Der Parameter &lt;strong&gt;run&lt;/strong&gt; sorgt für den Start im Vordergrund und dafür, dass der Docker-Container nach dem Start nicht wieder beendet wird.&lt;/p&gt;
&lt;p&gt;Nachteilig ist bei der gewählten Variante, dass ein &lt;code&gt;docker stop&lt;/code&gt; den Server nicht sauber terminiert, sondern nach dem Timeout ein SIGKILL sendet und der laufende Prozess brutal abgebrochen wird.&lt;/p&gt;
&lt;p&gt;Mit diesem &lt;em&gt;Dockerfile&lt;/em&gt; sind wir bereits soweit, mittels&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;mvn clean package meecrowave:build
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;und einem anschließenden &lt;code&gt;docker build .&lt;/code&gt; ein Image zu erzeugen, welches einen Meecrowave-Server startet.&lt;/p&gt;
&lt;p&gt;Das reicht mir aber noch nicht. Das Modul &lt;em&gt;person-server&lt;/em&gt; soll mittels &lt;code&gt;mvn clean package&lt;/code&gt; vollständig inklusive Docker-Image gebaut werden.&lt;/p&gt;
&lt;h2&gt;Maven anpassen und Paketierung automatisieren&lt;/h2&gt;
&lt;p&gt;Für den optimierten Bau wird über das Meecrowave Maven Plugin die Erzeugung der Distribution beeinflusst. Standardmäßig erzeugt das Plugin eine Distribution im Format ZIP und den unintuitiven Verzeichnisnamen &lt;em&gt;person-server-distribution&lt;/em&gt;. Dabei setzt sich der Verzeichnisname für das zu entpackende Archiv per Definition immer aus &lt;em&gt;${project.artifactId}-distribution&lt;/em&gt; zusammen.&lt;/p&gt;
&lt;script src=&quot;https://gist.github.com/rollinhand/0252ff141f1fc15ab1eba75efba62d01.js&quot;&gt;&lt;/script&gt;
&lt;p&gt;Durch die Definition der Formate (Zeile 6-9) wird jeweils eine Distribution als ZIP-Archiv und als Tarball Gnu-Zip erzeugt. Letzteres wird verwendet, um das Docker-Image zu erzeugen. Das ZIP-Archiv kann bspw. verwendet werden, um die Anwendung für ein Windows-System bereitzustellen.&lt;/p&gt;
&lt;p&gt;Mit &lt;em&gt;rootName&lt;/em&gt; (Zeile 10) wird der Name des gepackten Verzeichnisses beeinflusst. Statt &lt;em&gt;person-server-distribution&lt;/em&gt; heißt das gepackte Verzeichnis nun nur noch wie unser Modul &lt;em&gt;person-server&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Durch die Konfiguration der &lt;em&gt;executions&lt;/em&gt;-Passage koppeln wir den Prozess der Distributionserstellung automatisch an den Maven-Lebenszyklus &lt;strong&gt;package&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Fehlt noch der automatische Bau des Docker-Images - darum kümmern wir uns jetzt.&lt;/p&gt;
&lt;h2&gt;Docker-Image mit Maven automatisieren&lt;/h2&gt;
&lt;p&gt;Damit das Docker-Image reproduzierbar und automatisch über den Build-Prozess erzeugt werden kann, gibt es das Docker Maven-Plugin. Wenn man so wie ich ein natives &lt;em&gt;Dockerfile&lt;/em&gt; verwendet, ist das Plugin einfach konfiguriert. Damit sich das Docker-Image sowohl mit Maven als auch mit &lt;code&gt;docker build&lt;/code&gt; erstellen lässt, sind einige Dinge zu beachten.&lt;/p&gt;
&lt;script src=&quot;https://gist.github.com/rollinhand/8988d7176d771a103f690d31cb785c1c.js&quot;&gt;&lt;/script&gt;
&lt;p&gt;Das Plugin ist ziemlich mächtig und seine Funktionalitäten mache ich mir zunutze, den Build-Prozess zu automatisieren. Auf die allgemeine Konfiguration des Plugins gehe ich in diesem Beitrag nicht ein. Die &lt;a href=&quot;https://github.com/fabric8io/docker-maven-plugin&quot;&gt;Dokumentation&lt;/a&gt; des Projekts ist ziemlich ausführlich, sodass ich mich hier auf die Besonderheiten beschränken will:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;name&lt;/strong&gt; und &lt;strong&gt;alias&lt;/strong&gt; (Zeile 7/8) sorgen dafür, dass das erzeugte Image sich eindeutig in den lokalen Docker-Images wiederfinden lässt.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;contextDir&lt;/strong&gt; gibt an, wo das native Dockerfile gespeichert ist. In diesem Fall im Root-Verzeichnis des Moduls.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;name&lt;/strong&gt; (Zeile 12) ist eine Besonderheit, um die Kompatibilität zu &lt;code&gt;docker build&lt;/code&gt; aufrecht zu erhalten. Standardmäßig legt das Plugin alle für das Image notwendigen Dateien unter &lt;em&gt;build/maven&lt;/em&gt; relativ zu seinem eigenen Arbeitsverzeichnis ab. Durch das Überschreiben des Namens werden fortan die Dateien relativ unter &lt;em&gt;build/target&lt;/em&gt; abgelegt und sowohl &lt;code&gt;docker build&lt;/code&gt; als auch das Maven Plugin können mit dem gleichen nativen Dockerfile arbeiten.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;fileSet&lt;/strong&gt; (Zeile 14-20) sorgt dafür, dass Maven Assembly genutzt wird und nur unsere Distribution in das Docker-Image übertragen wird. Das Plugin unterstützt zwar auch die Assembly-Befehle wie &lt;em&gt;project&lt;/em&gt; oder &lt;em&gt;artifact&lt;/em&gt;, diese wären an dieser Stelle allerdings ungeeignet.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Die Abbildung zeigt das Ergebnis der Verwendung von &lt;strong&gt;name&lt;/strong&gt; und &lt;strong&gt;fileSet&lt;/strong&gt;. Das Unterverzeichnis unterhalb von &lt;em&gt;build&lt;/em&gt; lautet auf &lt;em&gt;target&lt;/em&gt; und es wird ausschließlich die erzeugte Tarball-Distribution in das Arbeitsverzeichnis kopiert.&lt;/p&gt;
&lt;p&gt;&lt;img style=&quot;width:70%;margin:auto&quot; src=&quot;meecrowave-docker-target.png&quot; width=&quot;750px&quot; alt=&quot;Docker Maven Plugin&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Mit der Konfiguration unter &lt;em&gt;executions&lt;/em&gt; wird wieder dafür gesorgt, dass das Docker-Image bereits in der Phase &lt;strong&gt;package&lt;/strong&gt; erstellt wird.&lt;/p&gt;
&lt;p&gt;Nun sind wir in der Lage mittels &lt;code&gt;mvn clean package&lt;/code&gt; die Anwendung inkl. Docker-Image zu erstellen und anschließend einen Container zu starten:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;docker run -d -p 8080:8080 person-server
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Über &lt;code&gt;curl http://localhost:8080/person&lt;/code&gt; lässt sich prüfen, oder der Microservice korrekt arbeitet.&lt;/p&gt;
&lt;h2&gt;Zusammenfassung&lt;/h2&gt;
&lt;p&gt;Mit dem Meecrowave Maven Plugin und dem Docker Maven Plugin lässt sich die Erstellung eines Microservices auf Basis von Apache Meecrowave soweit automatisieren, dass am Ende des Build-Prozesses ein fertiges Docker-Image für das Deployment auf einer Kubernetes- oder &lt;a href=&quot;../../../2018/06/23/container-verwalten-mit-dc-slash-os.html&quot;&gt;Mesos-Umgebung&lt;/a&gt; zur Verfügung steht.&lt;/p&gt;
&lt;p&gt;Der Aufwand für die Erweiterung eines bereits bestehenden Projekts hält sich dabei in Grenzen.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>Meecrowave - Microservices ohne aufwändiges Framework</title>
      <link>https://kivio.org/blog/entry/2020/04/30/meecrowave-microservices-ohne-aufwandiges-framework.html</link>
      <pubDate>Thu, 30 Apr 2020 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2020/04/30/meecrowave-microservices-ohne-aufwandiges-framework.html</guid>
      	<description>
	&lt;p&gt;Die Apache Foundation hat mit &lt;a href=&quot;https://openwebbeans.apache.org/meecrowave/&quot;&gt;Meecrowave&lt;/a&gt; einen Microprofil-Server auf den Weg gebracht, der durch seine geringe Größe und niedrigen Speicherverbrauch besticht. Inwiefern er genutzt werden kann, um einfach Microservices zu schreiben, habe ich mir genauer angesehen.&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;Apache Meecrowave ist ein Server, der ausschließlich auf Technologien der Apache Foundation basiert und in seiner Basisausstattung überschaubar ist. Im Kern werkelt eine Tomcat-Server als Servlet-Container und zusätzlich sind die folgenden Komponenten enthalten:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CDI (&lt;a href=&quot;https://openwebbeans.apache.org&quot;&gt;OpenWebBeans&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;JAX-RS (&lt;a href=&quot;https://cxf.apache.org&quot;&gt;CXF&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;JSON (&lt;a href=&quot;https://johnzon.apache.org&quot;&gt;Johnzon&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Zum Erstellen eines einfachen Microservice ist lediglich eine Maven-Abhängigkeit zu definieren und schon kann mit der Entwicklung des eigenen Microservice begonnen werden.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;dependency&amp;gt;
  &amp;lt;groupId&amp;gt;org.apache.meecrowave&amp;lt;/groupId&amp;gt;
  &amp;lt;artifactId&amp;gt;meecrowave-core&amp;lt;/artifactId&amp;gt;
  &amp;lt;version&amp;gt;${meecrowave.version}&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Meecrowave ist derzeit in der Version 1.2.9 verfügbar. Die Version stammt von September 2019. Seitdem hat sich an den EE-Spezifikationen wenig verändert, sodass keine neuen Komponenten veröffentlicht worden sind.&lt;/p&gt;
&lt;p&gt;Mit dem Maven-Goal &lt;code&gt;meecrowave:bundle&lt;/code&gt; lässt sich ein ZIP-Archiv erzeugen, dass alle notwendigen Abhängigkeiten und Start-Skripte beinhaltet, sodass ein in sich geschlossener Service ausgeliefert oder in einen Docker-Container deployt werden kann. Das Deployment in einen Docker-Container beschreibe ich in einem &lt;a href=&quot;../../../2020/05/06/meecrowave-und-docker-so-einfach-gehts.html&quot;&gt;anderen Blog-Beitrag&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Doch zurück zum eigentlichen entwickeln mit Meecrowave. Zur besseren Nachvollziehbarkeit, welche Möglichkeiten in Meecrowave stecken, habe ich auf &lt;a href=&quot;https://github.com/rollinhand/meecrowave-example/&quot;&gt;GitHub&lt;/a&gt; ein Projekt angelegt. Es besteht aus zwei Modulen und soll ein etwas komplexeres Beispiel statt dem üblichen Hello World darstellen:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;person-model=Enthält unsere Modellklassen, die von der Verarbeitungslogik separiert sind.&lt;/li&gt;
&lt;li&gt;person-server=Enthält unseren Microservice auf Basis von Meecrowave.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Für diesen Blog-Beitrag relevant ist nur das Modul &lt;em&gt;person-server&lt;/em&gt;. Und das schauen wir uns nun genauer an.&lt;/p&gt;
&lt;h2&gt;Eine Starterklasse anlegen&lt;/h2&gt;
&lt;p&gt;Um eine Instanz von Meecrwave starten zu können, wird eine Startklasse benötigt. Der Name der Klasse ist hierbei gleichgültig - ich habe sie &lt;em&gt;Starter&lt;/em&gt; genannt - sie muss lediglich eine statische Main-Methode enthalten in der Meecrowave konfiguriert und gestartet wird.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;public class Starter {
  public static void main(String[] args) {
    Meecrowave.Builder builder = new Meecrowave.Builder();
    builder.setHttpPort(8080);
    
    try(final Meecrowave meecrowave = new Meecrowave(builder)) {
      meecrowave.bake().await();
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Eine Meecrowave-Instanz lässt sich programmatisch, per Konfigurationsdatei oder durch Parameter auf der Kommandozeile konfigurieren. In dem gezeigten Beispiel wird der Listener-Port auf 8080 konfiguriert. Weitere Parameter wären über den Builder möglich. Auf den Seiten zum Meecrowave-Projekt findet sich eine lange Liste der Einstellmöglichkeiten.&lt;/p&gt;
&lt;p&gt;Durch &lt;code&gt;bake()&lt;/code&gt; wird der Server gestartet und mit &lt;code&gt;await()&lt;/code&gt; in den Modus versetzt, auf eingehende Requests zu warten. Mit der laufenden Instanz im Hintergrund kann nun der eigentliche REST-Service implementiert werden.&lt;/p&gt;
&lt;h2&gt;Einen REST-Service implementieren&lt;/h2&gt;
&lt;p&gt;In dem Person-Server können die Mitglieder einer Familie angezeigt, entfernt oder neue hinzugefügt werden. Unser Beispiel implementiert also einen typischen CRUD-Service. Mit den bekannten JAX-RS Annotationen haben wir in Kürze in der Klasse &lt;em&gt;PersonEndpoint&lt;/em&gt; einen REST-Service implementiert.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@RequestScoped
@Path(&amp;quot;/person&amp;quot;)
public class PersonEndpoint {
  @Inject
  private IPersonService personService;
	
  @POST
  public Response createPerson(Person person) {
    personService.add(person);
    return Response.status(Status.CREATED).entity(person).build();
  }
	
  @DELETE
  public Response removePerson(Person person) throws PersonException {
    personService.remove(person);
    return Response.ok(person).build();
  }
	
  @GET
  public Response listAll() {
    return Response.ok(personService.listAll()).build();
  }
  [...]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Beim Start des Containers wird die Klasse gefunden und der Endpunkt registriert. Mit &lt;em&gt;curl&lt;/em&gt; oder &lt;em&gt;Postman&lt;/em&gt; kann mit den Endpunkten interagiert werden. Die eigentliche Geschäftslogik für die Bereitstellung der Daten wurde wiederum in einem eigenen Service bzw. einer eigenständigen Bean gekapselt. Die Arbeitsweise des Services dürfte durch die sprechenden Methodennamen selbsterklärend sein. Für die Details zur Arbeitsweise lohnt sich ein Blick in das &lt;a href=&quot;https://github.com/rollinhand/meecrowave-example/&quot;&gt;Repository&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl http://localhost:8080/person
[{&amp;quot;id&amp;quot;:&amp;quot;e0f6bf13-2deb-4831-a779-5aa34fe7e5e6&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;Simpson&amp;quot;,&amp;quot;surname&amp;quot;:&amp;quot;Homer&amp;quot;},
{&amp;quot;id&amp;quot;:&amp;quot;3348f546-4ab3-4af0-97c4-6ce8a2d04ce1&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;Simpson&amp;quot;,&amp;quot;surname&amp;quot;:&amp;quot;Marge&amp;quot;},
{&amp;quot;id&amp;quot;:&amp;quot;81a038aa-5dd7-4550-9cff-b2dab4b59c9a&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;Simpson&amp;quot;,&amp;quot;surname&amp;quot;:&amp;quot;Bart&amp;quot;},
{&amp;quot;id&amp;quot;:&amp;quot;7e5ee7a1-70d5-4540-b304-36a67bb969f1&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;Simpson&amp;quot;,&amp;quot;surname&amp;quot;:&amp;quot;Lisa&amp;quot;},
{&amp;quot;id&amp;quot;:&amp;quot;a6e08d08-f6b2-4e9d-98b8-a80ffd5f04e7&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;Simpson&amp;quot;,&amp;quot;surname&amp;quot;:&amp;quot;Maggie&amp;quot;}]
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;TDD mit Meecrowave&lt;/h2&gt;
&lt;p&gt;Spring wird für seine gute Testbarkeit gelobt. Insbesondere Integrationstests sind in Spring einfacher zu erstellen als in Java EE. Wer im EE-Kontext Integrationstests schreiben will, muss sich erst umständlich in &lt;a href=&quot;http://arquillian.org&quot;&gt;Arquillian&lt;/a&gt; einarbeiten.&lt;/p&gt;
&lt;p&gt;Die Entwickler von Meecrowave haben diesen Umstand berücksichtigt und ein zusätzliches Plugin geschaffen, dass in Maven eingebunden, dafür sorgt, dass Test Driven Development mit Meecrowave komfortabel möglich ist. Und es arbeitet perfekt mit JUnit 4 und JUnit 5 zusammen.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;dependency&amp;gt;
  &amp;lt;groupId&amp;gt;org.apache.meecrowave&amp;lt;/groupId&amp;gt;
  &amp;lt;artifactId&amp;gt;meecrowave-junit&amp;lt;/artifactId&amp;gt;
  &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;
  &amp;lt;version&amp;gt;${meecrowave.version}&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Es kann mit &lt;em&gt;meecrowave-junit&lt;/em&gt; ein oder mehrere Endpunkte getestet werden. Dazu wird zu Beginn der Tests der Container hochgefahren. Da für die Tests ggf. Informationen aus der Konfiguration des Servers notwendig sind, können diese über die Junit 5 Erweitereung &lt;code&gt;@MonoMeecrowaveConfig&lt;/code&gt; ausgelesen werden.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@MonoMeecrowaveConfig
public class PersonEndpointTest {
  private WebTarget baseTarget;
	
  @ConfigurationInject
  private Meecrowave.Builder config;
	
  @BeforeEach
  public void setUp() {
    String baseUrl = String.format(&amp;quot;http://localhost:%d/person&amp;quot;, config.getHttpPort());
    Client client = ClientBuilder.newClient();
    baseTarget = client.target(baseUrl);
  }
	
  @Test
  public void itListsAllExisting() {
    List&amp;lt;Person&amp;gt; personList = baseTarget.request(MediaType.APPLICATION_JSON)
         .get(new GenericType&amp;lt;List&amp;lt;Person&amp;gt;&amp;gt;() {});
    
    assertNotNull(personList);
    assertFalse(personList.isEmpty());
  }
[...]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In dem Beispiel ist die Verwendung von &lt;code&gt;@MonoMeecrowaveConfig&lt;/code&gt; dargestellt. Die Annotation ist vergleichbar mit den aus Junit 4 verwendeten &lt;code&gt;@RunWith&lt;/code&gt;-Annotation und sorgt dafür, dass der Container vor der Ausführung der eigentlichen Tests hochgefahren wird.&lt;/p&gt;
&lt;p&gt;Mit &lt;code&gt;@ConfigurationInject&lt;/code&gt; haben wir die Möglichkeit auf eine Meecrowave Builder-Instanz zuzugreifen und somit die Parameter des laufenden Containers abzufragen. Wir benutzen dies, um den Port in der &lt;em&gt;setUp&lt;/em&gt;-Methode für unsere URL zu erfahren. Diese bildet die Basis für unseren JAX-RS Client mit dem die verschiedenen Endpunkte getestet werden sollen.&lt;/p&gt;
&lt;h2&gt;Weitere Möglichkeiten&lt;/h2&gt;
&lt;p&gt;Wer mehr Funktionalitäten aus dem Java EE-Kontext benötigt, dem stellt das Meecrowave noch weitere &lt;a href=&quot;https://openwebbeans.apache.org/meecrowave/components.html&quot;&gt;Komponenten&lt;/a&gt; zur Verfügung:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;meecrowave-jpa&lt;/strong&gt;=Hierbei handelt es sich um einen zusätzliches Layer, dass auf JPA aufbaut und ähnlich wie der Server an sich mit einem Builder zur programmatischen Konfiguration der Persistenzschicht.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;meecrowave-jolokia&lt;/strong&gt;=Komponenten zur Integration von Monitoring auf Basis von Jolokia.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;meecrowave-oauth2&lt;/strong&gt;=Experimentelles Modul zur Einbindung einer OAuth2-Implementiierung auf Basis von Apache CXF.&lt;/li&gt;
&lt;li&gt;Weiterhin besteht die Möglichkeit, SSL-Verschlüsselung über Let&amp;rsquo;s Encrypt einzubinden.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Zusammenfassung&lt;/h2&gt;
&lt;p&gt;Mit dem Meecrowave-Projekt hat die Apache Foundation unter der Schirmherrschaft des &lt;a href=&quot;https://openwebbeans.apache.org&quot;&gt;OpenWebBeans&lt;/a&gt;-Projekts einen kleinen, schlanken Microprofil-Server geschaffen, der auf dem Besten aus dem Java EE-Stack aufsetzt.&lt;/p&gt;
&lt;p&gt;Wer keine großen Frameworks für einen einfachen Microservice benötigt, der ist bei Meecrowave genau richtig, denn eine großartige Einarbeitung ist nicht notwendig.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>Technische Schulden und wie sie getilgt werden</title>
      <link>https://kivio.org/blog/entry/2020/04/04/technische-schulden-und-wie-sie-getilgt-werden.html</link>
      <pubDate>Sat, 4 Apr 2020 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2020/04/04/technische-schulden-und-wie-sie-getilgt-werden.html</guid>
      	<description>
	&lt;p&gt;Im Buch &lt;a href=&quot;https://amzn.to/39oKRQE&quot;&gt;&amp;ldquo;Hybride Softwareentwicklung&amp;rdquo;&lt;/a&gt; gehe ich mit meinen Co-Autoren Philip Knott und Gregor Sandhaus in Kapitel 4 auf das Thema technische Schulden ein. Es zeigt sich anhand aktueller Fachartikel und auch in Gesprächen mit Kunden, dass das Thema in der Digitalisierungswelle einen neuen Stellenwert einnimmt. Zeit sich mit dem Thema etwas ausführlicher auseinander zu setzen.&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;Was sind eigentlich technische Schulden und warum sind sie negativ konnotiert? Schauen wir zunächst auf die Begrifflichkeit der Schulden.&lt;/p&gt;
&lt;h2&gt;Schulden - nur im deutschsprachigen Raum mit negativer Bedeutung&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://de.wikipedia.org/wiki/Schulden&quot;&gt;Wikipedia&lt;/a&gt; beschreibt Schulden als &amp;ldquo;Verbindlichkeiten, die mit Rückzahlungsverpflichtungen von natürlichen oder juristischen Personen gegenüber Gläubigern verbunden sind&amp;rdquo;. Weiterhin heisst es in dem Artikel, dass die negative Konnotation des Begriffs &lt;em&gt;Schulden&lt;/em&gt; mit &lt;em&gt;Schuld&lt;/em&gt; nur im deutschsprachigen Raum besteht. So wird im angelsächsischen Raum der Begriff &lt;em&gt;debt&lt;/em&gt; für Schulden und &lt;em&gt;guilt&lt;/em&gt; für die Schuld verwendet.&lt;/p&gt;
&lt;p&gt;Der Begriff &lt;em&gt;debt&lt;/em&gt; ist von dem &lt;a href=&quot;https://www.latein.me/formen/debere&quot;&gt;lateinischen Verb &lt;em&gt;debere&lt;/em&gt;&lt;/a&gt; abgeleitet und bedeutet soviel wie &lt;em&gt;sollen&lt;/em&gt; aber auch &lt;em&gt;schulden&lt;/em&gt; bzw. &lt;em&gt;verdanken&lt;/em&gt; und ist damit deutlich positiver besetzt. Aus diesem Grund wird auch der Begriff &lt;em&gt;technical debt&lt;/em&gt; im englischsprachigen Raum verwendet.&lt;/p&gt;
&lt;p&gt;Der Begriff der finanziellen Schuld bedeutet, jemandem Geld zu schulden und damit in der Pflicht zu stehen, diese Schulden auch zurückzuzahlen. In der Finanzwelt existiert hierfür der Begriff &lt;em&gt;Kredit&lt;/em&gt;, der wiederum von dem &lt;a href=&quot;https://www.latein.me/latein/credit&quot;&gt;lateinischen Wort &lt;em&gt;credere&lt;/em&gt;&lt;/a&gt; abstammt und soviel wie &lt;em&gt;glauben&lt;/em&gt;, &lt;em&gt;anvertrauen&lt;/em&gt; und &lt;em&gt;verleihen&lt;/em&gt; bedeutet. In der 3. Person Singular ergibt sich das Wort &lt;em&gt;credit&lt;/em&gt;, ergo &amp;ldquo;er verleiht&amp;rdquo; oder aber auch &amp;ldquo;er vertraut [mir] an&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.faz.net/aktuell/finanzen/meine-finanzen/finanzieren/wirtschaftswunder-schulden-machen-lohnt-sich-15813983.html&quot;&gt;Finanzielle Schuld&lt;/a&gt; in Form eines Kredits und moralische Schuld hängen eng miteinander zusammen. Kommt der Schuldner seiner Verpflichtung zur Rückzahlung der Schulden nicht nach, entsteht neben dem rechtlichen Problem auch ein Vertrauensproblem.&lt;/p&gt;
&lt;p&gt;Auf diesen Punkt werde ich später noch einmal zurückkommen. Zunächst schauen wir uns den Kontext der technischen Schulden an.&lt;/p&gt;
&lt;h2&gt;Technische Schulden sorgen für den Verfall von Software&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;http://wiki.c2.com/?WardExplainsDebtMetaphor&quot;&gt;Ward Cunningham&lt;/a&gt; hat die Metapher der technischen Schulden (&lt;em&gt;technical debt&lt;/em&gt;) in der Informatik eingeführt, um die Konsequenzen schlechter technischer Umsetzung von Software mit wenigen Worten beschreiben zu können. Es ist gleichzeitig die Metapher für den zu erbringenden Mehraufwand, der für die Erweiterung einer bestehden Software notwendig ist.&lt;/p&gt;
&lt;p&gt;Es gibt viele Ursachen für die Entstehung von technischen Schulden. Jeder der professionell Softwareentwicklung betreibt, kennt das Problem vernachlässigter bzw. verfallender Software. Dazu gehören unter anderem:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Änderungen und Fehlerkorrekturen werden unüberlegt, unvollständig oder schlampig durchgeführt; entweder aus Unwissenheit, Zeitmangel oder der gestiegenen Komplexität der Software.&lt;/li&gt;
&lt;li&gt;Parameter werden hart einkodiert, statt sie flexibel und von außen steuerbar zu gestalten.&lt;/li&gt;
&lt;li&gt;Durch unkontrollierte Weiterentwicklung und Wartung verfällt die ursprünglich geplante Architektur bzw. passt nicht mehr zu den sich ändernden Einsatzszenarien.&lt;/li&gt;
&lt;li&gt;Copy &amp;amp; Paste statt Zusammenfassung und Modularisierung.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Die Liste ließe sich beliebig lang fortsetzen. Kurz gefasst=Der Verfall der Code- und Architektur-Qualität führt mittel- bis langfristig zu technischen Schulden. Nach &lt;a href=&quot;https://amzn.to/3atDSqH&quot;&gt;Chris Sterling&lt;/a&gt; lassen sich diese Ursachen auf zwei Begriffe zusammenfassen= &lt;em&gt;Unvollständigkeit&lt;/em&gt; und &lt;em&gt;Schlampigkeit&lt;/em&gt;. Aber scheinbar nehmen Kunden, Anwender und Product-Owner die Verschlechterung der Codebasis billigend in Kauf wenn dadurch Release-Termine eingehalten werden.&lt;/p&gt;
&lt;p&gt;Aber stimmt das wirklich? Nehmen die Interessierten (neudeutsch &lt;em&gt;Stakeholder&lt;/em&gt;) einer Software tatsächlich die technischen Schulden billigend in Kauf? Sind sie in der Lage, die langfristigen Auswirkungen der getroffenen Entscheidungen zu bewerten?&lt;/p&gt;
&lt;p&gt;Ein Großteil der heute für eine Anwendung verantwortlichen Personen besitzt nicht das technische Verständnis, um die Auswirkungen von technischen Schulden bewerten zu können. Tools wie &lt;a href=&quot;https://www.sonarqube.org&quot;&gt;Sonarqube&lt;/a&gt; helfen Entwicklern und Verantwortlichen technische Schulden zu identifizieren und diese in Form eines Schweregrads als auch einer Kennzahl - nämlich dem Aufwand zur Behebung - zu visualiseren.&lt;/p&gt;
&lt;p&gt;Mit einem solchen Tool lässt sich bedingt die Codequalität bewerten, aber was sagt die statische Codeanalyse bspw. über die Qualität der Software-Architektur?&lt;/p&gt;
&lt;h2&gt;Von Vertrauen, Krediten und Tilgung bei technischen Schulden&lt;/h2&gt;
&lt;p&gt;Die Stakeholder einer Software vertrauen in die Entwickler, die ihnen die Anwendung erstellen. Sie bauen darauf, dass diese die richtigen Entscheidungen treffen. Neben dem finanziellen Vorschuss (sie finanzieren das Projekt) übertragen sie den Entwicklern auch einen Vertrauensvorschuss.&lt;/p&gt;
&lt;p&gt;Dieser &amp;ldquo;Kredit&amp;rdquo; hat weitreichende Auswirkungen, denn aus der Praxis weiß jeder Softwareentwickler, dass sich technische Schulden nicht vermeiden lassen. Wir treffen und unterstützen fast täglich Entscheidungen von der Benennung einer Methode und seinen Eingangsparametern bis hin zu komplexen Architekturentscheidungen (Cloud-native, Monolith, Microservices).&lt;/p&gt;
&lt;p&gt;Dabei werden wir Menschen durch den &lt;em&gt;Bandwagon Effect&lt;/em&gt; beeinflusst. Der &lt;em&gt;Mitläufer-Effekt&lt;/em&gt; oder auch &lt;em&gt;Herdentrieb&lt;/em&gt; ist in der Mikroökonomie bekannt und besagt, dass die Steigerung eines Konsumguts aufgrund der Tatsache, dass andere Konsumenten dieses Gut gekauft haben, zurückzuführen ist. In der IT lässt sich dieses Phänomen ebenfalls beobachten=&amp;ldquo;Je häufiger ein Thema in Fachzeitschriften und [auf] Konferenzen besprochen wird, [desto] stärker scheint der Druck zu wachsen, es auch im eigenen Unternehmen einsetzen zu müssen.&amp;rdquo; (&lt;a href=&quot;https://webreader.objektspektrum.de/de/profiles/7d30f3fc5f62-objektspektrum/editions/objektspektrum-06-2019&quot;&gt;Wirdemann, Lueckow; OBJEKTspektrum 06/2019, S. 20&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Entwickler werden folglich extrinsisch beeinflusst und das hat Auswirkungen auf ihre Entscheidungen. Denn wer fragt sich nicht, ob er mit seiner Architektur noch am Puls der Zeit ist oder ob die ausgewählte Programmiersprache, die richtige Lösung für das Problem ist?&lt;/p&gt;
&lt;p&gt;Alle Entscheidungen können - nicht müssen - zu technischen Schulden führen. Auf den ersten Blick sieht es so aus, als obliegt es allein den Entwicklern, der Verpflichtung zur &amp;ldquo;Rückzahlung&amp;rdquo; nachzukommen und die technischen Schulden kontinuierlich zu minimieren bzw. zu &amp;ldquo;tilgen&amp;rdquo;. Im weiteren Verlauf der Ausführungen zeige ich noch, dass diese nicht der Fall ist.&lt;/p&gt;
&lt;p&gt;Eines der häufigsten Mittel zur Minimierung der technischen Schulden ist das &lt;em&gt;kontinuierliche Refactoring&lt;/em&gt;. Hierfür bedarf es auf jeden Fall &lt;em&gt;automatisierter Tests&lt;/em&gt;, sodass nach dem Aufräumen und Umbauen sichergestellt ist, dass die Anwendung bzw. der Code weiterhin korrekt funktioniert.&lt;/p&gt;
&lt;p&gt;Hier stellt sich allerdings die Frage, wer für die Aufwände der Refaktorisierung und den damit einhergehenden Kosten aufkommt? Die Stakeholder einer Software lehnen die Kosten für die Refaktorisierung einer Software häufig ab, da der Nutzen nicht ersichtlich und aus fachlicher Sicht keine Wertsteigerung der Software zu erwarten ist.&lt;/p&gt;
&lt;p&gt;Kommen wir an dieser Stelle zurück zur Realwirtschaft und den finanziellen Schulden. Ein Begriff aus der Kreditwirtschaft wurde bislang noch nicht erwähnt=der Zins. Schuldner zahlen dem Gläubiger Zinsen und sind somit Aufwand. Weiterhin stellt der Zins eine Risikoprämie für die Unsicherheit der Rückzahlung des Kapitals dar. Je mehr Risiko der Gläubiger eingeht, desto höher fällt der Zins aus, um einen Anreiz zu schaffen, auf das Kreditgeschäft einzugehen.&lt;/p&gt;
&lt;h2&gt;Alternde Systeme und die Beseitigung von technischen Schulden&lt;/h2&gt;
&lt;p&gt;Kontinuierliche Refaktorisierung beseitigt nicht nur technische Schulden, sondern verlängert auch die Lebenszeit eines Systems. Und das hat immense Auswirkungen auf zukünftige Kosten. Wird ein System nicht kontinuierlich angepasst, gibt es am Ende seiner Lebenszeit fünf Wege zur Modernisierung:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;die Beschaffung eines Standardprodukts&lt;/li&gt;
&lt;li&gt;die Entwicklung eines neuen Systems&lt;/li&gt;
&lt;li&gt;die Kapselung des alten Systems&lt;/li&gt;
&lt;li&gt;die Konvertierung des alten Systems und&lt;/li&gt;
&lt;li&gt;die Re-Implementierung des alten Systems&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Alle diese Wege sind ebenfalls mit Aufwand versehen. Dieser Aufwand lässt sich über die Laufzeit eines Systems &amp;ldquo;abzinsen&amp;rdquo;. Die Frage, die sich Stakeholder bei dem Betrieb eines Systems immer stellen müssen ist=Wie hoch ist der Aufwand für einen dieser fünf Wege im Gegensatz zur kontinuierlichen Pflege und technischen Optimierung meines bestehenden Systems.&lt;/p&gt;
&lt;p&gt;Das kontinuierliche Refaktorisieren kann dazu dienen die Risikoprämie zu senken. Verallgemeinert ist das Risiko die Zukunftssicherheit des Systems und seine mögliche Nutzensteigerung im Verhältnis zu einer Modernisierung &amp;ldquo;from scratch&amp;rdquo;. Demnach gilt ebenfalls=Je komplexer das System mit der Zeit wird, desto höher fällt auch die Risikoprämie aus und somit der Aufwand, der in das System gesteckt werden muss.&lt;/p&gt;
&lt;p&gt;Betrachtet aus einem Gläubiger-Schuldner-Verhältnis bleibt die Frage offen, wer die Aufwände für die Tilgung und die Zinsen trägt? Ganz so einfach wie in der Kreditwirtschaft lässt sich die Frage im Kontext der Softwareentwicklung nicht beantworten.&lt;/p&gt;
&lt;p&gt;Auftraggeber für die Entwicklung eines Systems lassen sich gerne zu der Aussage hinreissen, dass &lt;em&gt;der&lt;/em&gt; Entwickler auch im Vorfeld bereits die &lt;em&gt;richtige&lt;/em&gt; Entscheidung hätte treffen können, sodass keine technischen Schulden entstanden wären.&lt;/p&gt;
&lt;p&gt;Die meisten Entscheidungen treffen Menschen unbewusst auf Basis von gesammelten Informationen. Viele davon laufen routiniert und unbewusst ab. Diese alltäglichen Entscheidungen wie die morgendliche Routine, den Schutz bei Regenwetter oder den Umgang mit anderen Menschen spulen wir wie selbstverständlich ab. Dieses Denken in Mustern (Schubladendenken) sorgt dafür, dass wir Menschen wenig Energie für wiederkehrende Entscheidungen aufwenden müssen. Zeitgleich sorgt dieses Verhalten auch für &lt;a href=&quot;https://karrierebibel.de/bias/&quot;&gt;Verzerrungen&lt;/a&gt;, die unseren Alltag negativ beeinflussen und uns zu vorschnellen Entscheidungen verleiten können. Hierzu gehört auch der eingangs beschriebene Mitläufer-Effekt, der zwangsläufig zum Availability Bias führt.&lt;/p&gt;
&lt;p&gt;Aus diesem Grund hat &lt;a href=&quot;https://martinfowler.com/bliki/TechnicalDebtQuadrant.html&quot;&gt;Martin Fowler&lt;/a&gt; technische Schulden in Quadranten unterteilt und unterscheidet zwischen Schulden, die bewusst und unwissentlich eingegangen worden sind. Übeträgt man die Quadranten auf die Aussagen von Chris Sterling, so kann das Modell von Martin Fowler wie in der ersten Abbildung gezeigt erweitert werden.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;quadrant_technical_debt01.png&quot; alt=&quot;Quadrant technische Schulden&quot; /&gt; &lt;em&gt;Abb. 1=Quadrant technische Schulden&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Folglich sind alle rücksichtslosen bzw. schlampigen Entscheidungen &amp;ndash; ob bewusst oder versehentlich &amp;ndash; keine technischen Schulden im eigentlichen Sinne, sondern fallen unter handwerkliche Fehler und gehören in die Kategorie Regress oder Gewährleistung. Aus Sicht der Stakeholder kann auch von Vorsatz gesprochen werden.&lt;/p&gt;
&lt;p&gt;Anders verhält es sich mit den Entscheidungen aus der Spalte &lt;em&gt;umsichtig&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Enge Release-Termine werden von den Stakeholdern vorgegeben und selten von Entwicklern. Die Entscheidung ausgelassene Tätigkeiten zu einem späteren Zeitpunkt - nach dem Go-Live - anzugehen treffen beide Parteien gemeinsam. Allerdings sieht die Realität häufig anders aus und die in die Zukunft verschobenen Tätigkeiten und Entscheidungen geraten in Vergessenheit. Die daraus resultierenden technischen Schulden wachsen somit mit Verstreichen der Zeit.&lt;/p&gt;
&lt;p&gt;Den Stakeholdern sollte daran gelegen sein, diese Tätigkeiten zeitnah nachzuholen, da neben den Aufwänden für die Beseitigung der technischen Schulden auch die Risikoprämie zur Erhaltung und Optimierung der Software steigt.&lt;/p&gt;
&lt;p&gt;Minimal viable products (MVP) bzw. Prototypen minimieren fehlerhafte Design- und Architekturentscheidungen bzw. dienen zur Erprobung von Programmiersprachen oder Frameworks für den Lösungseinsatz. Mit diesem Ansatz kann der Mitläufer-Effekt und der damit einhergehende Availability Bias mitigiert werden.&lt;/p&gt;
&lt;p&gt;Dieses Vorgehen zahlt indirekt auf das Konto zur Vermeidung von technischen Schulden ein, da im Vorfeld Prävention für Fehlentscheidungen getroffen wird. Der Quadrant vier (umsichtig, versehentlich) kann somit vom zukünftigen Risiko minimiert werden.&lt;/p&gt;
&lt;p&gt;Den Stakeholdern eines Systems sollte an der Risikominimierung gelegen sein, da es sich direkt auf die zukünftige zu zahlende Risikoprämie für das System auszahlt.&lt;/p&gt;
&lt;p&gt;Die Abbildung 2 zeigt zusammenfassend, welche Partei die Beseitigung von technischen Schulden zu finanzieren hat.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;quadrant_technical_debt02.png&quot; alt=&quot;Wer die technischen Schulden bezahlt&quot; /&gt; &lt;em&gt;Abb. 2=Wer die technischen Schulden bezahlt&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;Fazit&lt;/h2&gt;
&lt;p&gt;Betrachtet man das Thema technische Schulden aus der Brille der Kreditwirtschaft, so kann von gemeinsam in Kauf genommenen Schulden nur aus der Säule &lt;em&gt;Unvollständigkeit&lt;/em&gt; gesprochen werden. Ausschließlich in diesem Bereich existiert konkludentes Handeln zwischen zwei Parteien bei denen das Vertrauensverhältnis nicht verletzt wird.&lt;/p&gt;
&lt;p&gt;Im ersten Fall wird ein Risiko in Kauf genommen, um der Komponente Zeit Rechnung zu tragen. Beide Parteien müssen sich sowohl auf das Vorgehen als auch die mitigierenden Maßnahmen verständigen. Der Stakeholder des Systems sollte dabei sowohl die Aufwände für die Beseitigung der technischen Schulden als auch die Erhöhung seiner Risikoprämie (Zukunftsfähigkeit des Systems) im Auge behalten.&lt;/p&gt;
&lt;p&gt;Um nicht in den Umstand zu laufen, versehentlich eine architektonische Fehlentscheidung getroffen zu haben, die sich erst spät in der Zukunft auswirkt, existiert das Konzept des MVP. Es dient ebenfalls als mitigierende Maßnahme und ist insbesondere in iterativen Entwicklungsmethoden ein willkommener Ansatz zur Verprobung neuer Technologien.&lt;/p&gt;
&lt;p&gt;Als dritter Ansatz zur Reduktion von technischen Schulden als auch zur Reduktion der Risikoprämie, ist das kontinuierliche Refactoring eines Systems zu berücksichtigen. Durch kontinuierliche, technische Optimierungen, die keinen fachlichen Nutzen bringen, sichern die Stakeholder die Zukunftsfähigkeit des Systems und reduzieren die Risikoprämie, die sich aus den abgezinsten Kosten einer Modernisierung des kompletten Systems in der Zukunft ergeben würde.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>Apache NetBeans 10.0 veröffentlicht</title>
      <link>https://kivio.org/blog/entry/2018/12/30/apache-netbeans-10-veroeffentlicht.html</link>
      <pubDate>Sun, 30 Dec 2018 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2018/12/30/apache-netbeans-10-veroeffentlicht.html</guid>
      	<description>
	&lt;p&gt;Apache hat NetBeans in der Version 10.0 Ende Dezember veröffentlicht. Die aktuelle Version unterstützt neue Funktionalitäten aus dem JDK 11, vermisst aber immer noch einige wichtige bzw. aktualisierte Plugins - unter anderem das Plugin zur Java EE-Entwicklung.&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;Mit der Version 10.0 hat Apache das zweite offizielle Release unter dem Dach der Apache Software Foundation (ASF) am 27. Dezember 2018 veröffentlicht. Die Entwicklungsumgebung befindet sich immer noch im Apache Incubator und in der Transitionsphase zu Apache.&lt;/p&gt;
&lt;p&gt;Das bedeutet, dass noch nicht alle Codepassagen durch Oracle an die Apache Software Foundation (ASF) übergeben worden sind und die Überprüfung des Codes auf Konformität zur Apache License noch nicht vollständig abgeschlossen sind.&lt;/p&gt;
&lt;p&gt;NetBeans 10.0 unterstützt die im JDK 11 implementierten neuen Funktionalitäten wie &lt;em&gt;var&lt;/em&gt;-Support für implizit typisierte Lamda-Ausdrücke. Java-Entwickler wird weiter freuen, dass die Unterstützung für JUnit 5 weiter optimiert wurde.&lt;/p&gt;
&lt;p&gt;Zudem wurde die Unterstützung für verschiedene PHP-Versionen verbessert. Mit dem aktuellen Stand der Entwicklungsumgebung lassen sich problemlos Java SE-, Scala-, Groovy-, JavaScript- und PHP-Anwendungen erstellen.&lt;/p&gt;
&lt;p&gt;Bereits seit der Portierung fehlt die Unterstützung für Java EE-Anwendungen, da der Code von Oracle bisher nicht offiziell an die ASF übergeben worden ist. Inwieweit das Plugin offiziell für NetBeans wieder verfügbar sein wird, ist mit dem Entfernen der Java EE-Pakete aus dem JDK 11 immer mehr fraglich.&lt;/p&gt;
&lt;p&gt;Wer dennoch Java EE-Anwendungen mit NetBeans entwickeln will, der kann das &lt;a href=&quot;https://dzone.com/articles/notes-on-java-eejakarta-ee-support-for-netbeans-9&quot;&gt;offizielle Plugin-Repository von NetBeans 8.2 einbinden&lt;/a&gt; und neben dem Java EE-Plugin auch noch weitere Plugins installieren, die weder in NetBeans 9.0 noch 10.0 verfügbar sind.&lt;/p&gt;
&lt;p&gt;Nachdem sich NetBeans seit 2016 in der Incubator-Phase befindet, hat sich bisher nur der Kern weiterentwickelt. Viele der Plugins sind nach wie vor nicht auf die Version 9.0, geschweige denn auf die Version 10.0 portiert bzw. auf Kompatibiltät geprüft worden.&lt;/p&gt;
&lt;p&gt;Weiterhin existiert kein Installer für die unter dem Hause der ASF weiterentwickelten Version. Die kompilierten Binär-Versionen müssen auch mit dem zweiten Release weiterhin über Shell- oder Batch-Scripte gestartet werden. Unter Windows oder macOS fühlt sich dies nach wie vor merkwürdig an.&lt;/p&gt;
&lt;p&gt;Alle kleinen und größeren Änderungen an NetBeans können den &lt;a href=&quot;https://cwiki.apache.org/confluence/display/NETBEANS/Apache+NetBeans+10&quot;&gt;offiziellen Release-Notes&lt;/a&gt; für NetBeans entnommen werden.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>C3Faces 1.4 officially released</title>
      <link>https://kivio.org/blog/entry/2018/08/19/c3faces-1-dot-4-officially-released.html</link>
      <pubDate>Sun, 19 Aug 2018 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2018/08/19/c3faces-1-dot-4-officially-released.html</guid>
      	<description>
	&lt;p&gt;C3Faces is a chart library for JSF based on c3.js. I want to announce the fourth official version of this library released to &lt;a href=&quot;https://search.maven.org/#artifactdetails%7Corg.kivio%7Cc3faces%7C1.0%7Cjar&quot;&gt;Maven central&lt;/a&gt; coming with dynamic category-based axes.&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;C3Faces 1.4 fixes bug #2 filed as not updating categories on dynamic changes. Using the &lt;em&gt;axis&lt;/em&gt; attribute with categories will still keep fixed category names until the whole diagram is reloaded in your web-session (or session is restarted). If you want to react on dynamic changes, use the &lt;em&gt;axis&lt;/em&gt; attribute without fixed category names and use the newly introduced &lt;em&gt;Xkey&lt;/em&gt; class to define dynamic category names for X-axis (it is only available for X-axis).&lt;/p&gt;
&lt;p&gt;An example for clarification:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;JSF&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;c3:line id=&amp;quot;chart&amp;quot; data=&amp;quot;#{dashboardViewBean.data}&amp;quot; &amp;gt;
	&amp;lt;c3:axes&amp;gt;
		&amp;lt;c3:axisX type=&amp;quot;category&amp;quot; /&amp;gt;
	&amp;lt;/c3:axes&amp;gt;
&amp;lt;/c3:line&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Bean&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;private final Data data = new Data();
...

// New dynamic view for categories on X-axis
C3ViewDataSet categoriesView = new C3ViewDataSet(getMonths());
data.getDataSets().add(categoriesView);
data.addChild(new XKey(categoriesView.getId()));
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is it. After new data is added, you have to refresh the C3ViewDataSet programmatically.&lt;/p&gt;
&lt;h2&gt;Showcase update&lt;/h2&gt;
&lt;p&gt;If you want to see version 1.2 with axis configuration in action, please visit the &lt;a href=&quot;http://c3faces.kivio.org&quot;&gt;official showcase&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Further information&lt;/h2&gt;
&lt;p&gt;Changelog about further changes between previous version and the present one can be found in the official &lt;a href=&quot;https://github.com/rollinhand/c3faces/blob/master/CHANGELOG.md&quot;&gt;Changelog&lt;/a&gt; in the GitHub repository.&lt;/p&gt;
&lt;p&gt;Have fun while playing around with C3Faces and if you find any issues or have suggestions for new features please &lt;a href=&quot;https://github.com/rollinhand/c3faces/issues&quot;&gt;leave a comment&lt;/a&gt;.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>Container verwalten mit DC/OS</title>
      <link>https://kivio.org/blog/entry/2018/06/23/container-verwalten-mit-dc-slash-os.html</link>
      <pubDate>Sat, 23 Jun 2018 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2018/06/23/container-verwalten-mit-dc-slash-os.html</guid>
      	<description>
	&lt;p&gt;Die Themen Cloud und Container stammen nicht aus Wolkenkuckucksheim, sondern beschäftigen in der Realität die IT-Abteilungen großer und kleiner Unternehmen. Hinter diesen Ideen steckt der Wunsch, Hardware-Ressourcen effizienter auszulasten, Spitzenlasten abzufangen und Anwendungen bzw. Services beliebig skalieren zu können. Hierbei können Plattformen wie DC/OS helfen.&lt;/p&gt;
&lt;!--more--&gt;
&lt;!--![Photo by [Erwan Hesry](https://unsplash.com/photos/RJjY5Hpnifk?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText)
on [Unsplash](https://unsplash.com/search/photos/container?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText)]
(https://cdn-images-1.medium.com/max/1000/1*VZf19QtcEYsMaA912V0pkQ.jpeg)--&gt;
&lt;h3&gt;Container &amp;mdash; die Logistikbranche macht es vor&lt;/h3&gt;
&lt;p&gt;Bereits 1956 wurden die ersten Frachtcontainer entwickelt. Das typische Umladen einzelner Gebinde in den Frachthäfen sollte durch die Container optimiert werden. Die &lt;a href=&quot;https://de.wikipedia.org/wiki/ISO-Container&quot;&gt;ISO-Container&lt;/a&gt; wie wir sie heute kennen, haben sich allerdings erst ab 1966 durchgesetzt. Ihr großer Vorteil ist, dass sie dank der Normierung über Land und Wasser transportiert werden können, ohne ein einziges Mal entladen werden zu müssen.&lt;/p&gt;
&lt;p&gt;Übertragen auf die IT sind Container ein Deploymentformat für Anwendungen. Ähnlich wie in der Logistik gibt es auch hier Bemühungen, ein einheitliches Format zu schaffen=den OCI-Container. Führende Unternehmen und Cloud-Betreiber wie Google, Amazon und RedHat haben sich zur &lt;a href=&quot;https://www.opencontainers.org/&quot;&gt;Open Container Initiative&lt;/a&gt; zusamengeschlossen und treiben das Format voran, das aus Docker hervorgegangen ist.&lt;/p&gt;
&lt;h3&gt;Container brauchen Infrastruktur&lt;/h3&gt;
&lt;p&gt;Was würde der Logistikbranche ein Frachtcontainer bringen, wenn die Frachträume der Containerschiffe falsch dimensioniert wären, es keine einheitlichen Kräne gäbe, und die Lastkraftwagen zu kleine Auflieger hätten? Container schaffen eine Abstraktionsschicht, aber die eigentliche Arbeit verrichtet die Infrastruktur.&lt;/p&gt;
&lt;p&gt;Bis zu einer bestimmten Grenze lassen sich auch Docker-Container ohne besondere Werkzeuge betreiben. Was aber, wenn die Systemlandschaft aus Containern nicht klein und überschaubar bleibt? Steigen die Anforderungen an ein verteiltes System, gewinnt auch der Betrieb schnell an Stellenwert. Dann muss die Infrastruktur bzgl. Kapazität, Performance und Verfügbarkeit skaliert werden.&lt;/p&gt;
&lt;p&gt;Sofern die Anwendung nicht in einer Public Cloud wie AWS, Azure, oder OpenShift betrieben wird, wäre ein Cluster-Betriebssystem wünschenswert, das den IT-Betrieb bei dieser Herausforderung unterstützt.&lt;/p&gt;
&lt;h3&gt;DC/OS als Cloud-Betriebssystem&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://mesosphere.com/product/&quot;&gt;DC/OS&lt;/a&gt; ist eine Integrationsplattform für den Betrieb von containerisierten Anwendungen und Services. Das &amp;ldquo;DC&amp;rdquo; für &amp;ldquo;Distributed Computing&amp;rdquo; weist schon auf das Ziel hin, eine verteilte Umgebung über viele Server und Standorte zu schaffen &amp;mdash; egal ob Public-Cloud oder eigenes Rechenzentrum.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*kUZ08-I1nEITGfCihng6Pw.png&quot; alt=&quot;DC/OS Architektur
(Quelle)&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Der Unterbau für DC/OS ist &lt;a href=&quot;http://mesos.apache.org/&quot;&gt;Apache Mesos&lt;/a&gt;=ein verteilter System-Kernel, der sich ähnlich wie der Linux-Kernel um die Verwaltung von CPUs, Speicher und Prozessen kümmert &amp;mdash; nur eben nicht auf einer Maschine, sondern verteilt. Mesos kann von Haus aus mit Containerformaten umgehen, und über eine HTTP-API, oder ein (nicht ganz so schickes) Frontend gesteuert werden.&lt;/p&gt;
&lt;h3&gt;DC/OS ist mehr als Apache Mesos&lt;/h3&gt;
&lt;p&gt;Die Entwickler von DC/OS Mesosphere haben das Frontend von Mesos durch eine eigene Weboberfläche ersetzt, die in der aktuellen Version 1.11 keine Wünsche offen lässt. Hiermit lassen sich bereits vorgefertigte Pakete aus einem Repository installieren, was ähnlich einfach funktioniert, wie eine App aus einem App-Store zu installieren. Während der Installation kann der Administrator angeben, auf wie vielen Instanzen der Service installiert werden soll.&lt;/p&gt;
&lt;p&gt;DC/OS entscheidet selbst anhand verschiedener Kriterien auf welchen Knoten der Service in welcher Anzahl deployt wird. Hierfür zeichnet sich die Anwendung &lt;a href=&quot;https://mesosphere.github.io/marathon/&quot;&gt;Marathon&lt;/a&gt; verantwortlich, die neben dem Deployment von Services und Anwendungen auch die Hochverfügbarkeit steuert.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*D__DumFiPARcUKt36hfN2Q.png&quot; alt=&quot;Marathon
in Aktion&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Neben Services aus dem Repository kann Marathon auch Docker-Images aus Container-Registries deployen. Hier ist Docker-Hub bereits angebunden, der Betrieb einer eigenen Docker-Registry ist ebenso möglich.&lt;/p&gt;
&lt;h3&gt;DC/OS im eigenen Rechenzentrum oder der Cloud&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Apache_Mesos#Users&quot;&gt;Einige große Internetplattformen&lt;/a&gt; wie &lt;a href=&quot;http://mesos.apache.org/documentation/latest/powered-by-mesos/&quot;&gt;Twitter, Airbnb, eBay oder Apple&lt;/a&gt; nutzen Apache Mesos, um ihre Infrastruktur und Anwendungen zu verwalten. Wem dieser Weg zu aufwändig ist, für den hat Mesosphere mit DC/OS eine Plattform entwickelt, die den Einsatz im eigenen Rechenzentrum, oder der Public Cloud einfach macht. Neben Amazon bieten auch &lt;a href=&quot;https://azuremarketplace.microsoft.com/en-us/marketplace/apps/mesosphere.enterprise-dcos?tab=Overview&quot;&gt;Microsoft&lt;/a&gt; und Oracle Unterstützung für DC/OS in ihren Cloud-Lösungen an.&lt;/p&gt;
&lt;p&gt;Einen schnellen Einstieg bietet z.B. Amazon mit der Möglichkeit, einen &lt;a href=&quot;https://aws.amazon.com/de/blogs/apn/announcing-mesosphere-dcos-on-aws/&quot;&gt;DC/OS Cluster in AWS aufzusetzen&lt;/a&gt;. Das ist chic, hat allerdings auch seinen Preis (€€€). Wer lieber kleiner anfangen möchte, für den gibt es auch Skripte zum Aufsetzen eines &lt;a href=&quot;https://github.com/dcos/dcos-vagrant&quot;&gt;Clusters&lt;/a&gt; mit Vagrant.&lt;/p&gt;
&lt;p&gt;Mesosphere Inc. stellt kommerziellen Support für Apache Mesos und das zugrunde liegende Öko-System bereit. Die freie Variante von DC/OS fast wichtigen Funktionen, lediglich die erweiterte Rechteverwaltung und Multi-Cloud-Unterstützung für noch höhere Verfügbarkeit sind der kommerziellen Enterprise-Version vorbehalten.&lt;/p&gt;
&lt;h3&gt;Fazit&lt;/h3&gt;
&lt;p&gt;Vergleicht man eine Container-basierte Systemlandschaft mit großen Hafenterminals wie Hamburg oder Rotterdam, wird klar, dass sich eine große Menge von Containern nicht mehr ausschließlich manuell steuern lässt.&lt;/p&gt;
&lt;p&gt;Lagerplätze für Container sind nur noch Koordinaten auf einem überdimensionalen Schachbrett. Der Disponent entscheidet, wann, wie viele und in welcher Reihenfolge Container abgelegt werden. Diese Rolle übernimmt im Rechenzentrum DC/OS=es kümmert um eine bestmögliche Nutzung aller Ressourcen der Systeme.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>SD-Karten verhindern MacBook Standby</title>
      <link>https://kivio.org/blog/entry/2018/05/31/sd-karten-verhindern-macbook-standby.html</link>
      <pubDate>Thu, 31 May 2018 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2018/05/31/sd-karten-verhindern-macbook-standby.html</guid>
      	<description>
	&lt;p&gt;In meinem &lt;a href=&quot;../../../2016/12/31/itunes-bibliothek-auf-transcend-jetdrive.html&quot;&gt;Post vom 31.12.2016&lt;/a&gt; habe ich gezeigt, dass die iTunes Bibliothek auf eine externe SD-Karte ausgelagert werden kann. Allerdings hat das dauerhafte Mounten einer SD-Karte den Nachteil, dass das MacBook nicht mehr in den Standby-Modus wandert.&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;Seit einiger Zeit habe ich mich gewundert, dass nach einem halben Tag das MacBook in der Tasche ca. 25 Prozent an Akku-Leistung verloren hat. Normalerweise verbraucht ein MacBook bei zugeklappten Deckel ca. ein Prozent Akku-Leistung je Stunde.&lt;/p&gt;
&lt;p&gt;Nach drei Stunden geht das MacBook in den Standard-Einstellungen in den Tiefschlaf und reduziert dabei die CPU-Leistung sofern keine Dienste im Hintergrund laufen, die den Tiefschlaf (nicht mit dem Hibernate-Modus zu verwechseln) verhindern.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://support.apple.com/de-de/HT202124&quot;&gt;Apple hat am 12.10.2017 ein Dokument veröffentlicht&lt;/a&gt; und weist darauf hin, dass eine dauerhaft gemountete SD-Karte den Tiefschlaf verhindert und somit die Akkuleistung schneller schwindet.&lt;/p&gt;
&lt;p&gt;Die dauerhafte Einbinung eines JetDrives für die Auslagerung der iTunes-Datenbank sorgt folglich dafür, dass der Standby-Modus nicht mehr genutzt werden kann.&lt;/p&gt;
&lt;p&gt;Um den Akku zu schonen kann also die SD-Karte ausgeworfen oder das MacBook bei längerer Nicht-Nutzung ausgeschaltet werden. Umgerechnet ist ansonsten mit ca. 3 Prozent Leistungsschwund je Stunde bei dauerhaft eingebundener SD-Karte zu rechnen.&lt;/p&gt;
&lt;p&gt;Im Internet kursieren auch Tipps, um Den Standby-Modus des MacBooks zu beeinflussen. Ich persönlich rate allerdings davon ab, die Powermanagement-Einstellungen des MacBooks über die Kommandozeile zu beeinflussen, wenn man sich nicht der Konsequenzen bewusst ist.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>Let&apos;s Encrypt mit Nginx Proxy im Docker Container</title>
      <link>https://kivio.org/blog/entry/2018/05/26/lets-encrypt-mit-nginx-proxy-im-docker-container.html</link>
      <pubDate>Sat, 26 May 2018 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2018/05/26/lets-encrypt-mit-nginx-proxy-im-docker-container.html</guid>
      	<description>
	&lt;p&gt;In diesem Tutorial beschreibe ich, wie man in einem 1&amp;amp;1 Cloud-Server in einem Nginx Reverse Proxy in einem Docker Container ein Let&amp;rsquo;s Encrypt-Zertifikat für die SSL-verschlüsselte Verbindung einbindet.&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;Eine Anmerkung möchte ich vorweg zu diesem Tutorial geben=Die Zertifikatseinbindung findet auf dem &lt;em&gt;nackten&lt;/em&gt; Host statt und nicht über den Let&amp;rsquo;s Encrypt Docker container. Hierzu gibt es einen sehr ausführlichen Blog-Beitrag bei &lt;a href=&quot;https://manas.tech/blog/2016/01/25/letsencrypt-certificate-auto-renewal-in-docker-powered-nginx-reverse-proxy.html&quot;&gt;Manas Tech&lt;/a&gt;, den ich ebenfalls sehr empfehlen kann.&lt;/p&gt;
&lt;p&gt;Dieses Tutorial basiert auf der sehr rudimentären &lt;a href=&quot;https://www.1and1.com/cloud-community/learn/networking/ssl-certificates/install-a-lets-encrypt-ssl-certificate-on-a-11-cloud-server-with-linux/&quot;&gt;Anleitung von 1&amp;amp;1&lt;/a&gt; zur Installation eines Let&amp;rsquo;s Encrypt Zertifikats in den standardmäßig auf einem Cloud-Server installierten Apache-Server. Ich persönlich habe Nginx dem Apache aufgrund des schonenderen Umgangs mit den Hardware-Ressourcen und der einfacheren Konfiguration vorgezogen. Die Konfiguration für den Nginx reverse proxy liegt bei &lt;a href=&quot;https://github.com/rollinhand/kivio-proxy&quot;&gt;GitHub&lt;/a&gt;. Ich werde in diesem Post auf besondere Details der Konfiguration eingehen.&lt;/p&gt;
&lt;h3&gt;Let&amp;rsquo;s Encrypt auf dem Cloud Server installieren&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s Encrypt ist eine freie SSL Certificate Authority - auch Root Authority genannt, die freie und kostenlose Zertifikate verteilt. Die Zertifikate sind in der Regel 90 Tage gültig und müssen spätestens dann aktualisiert werden. Am Ende des Tutorials zeige ich ebenfalls einen Weg, wie das Zertifikat regelmäßig aktualisiert werden kann.&lt;/p&gt;
&lt;p&gt;Für die Installation des Zertifikats setze ich auf den hauseigenen Client von Let&amp;rsquo;s Encrypt. Über diesen lassen sich neue Zertifikate ausstellen und bereits vorhandene jederzeit aktualisieren. Damit der Client genutzt werden kann, ist die Installation von Git auf dem Cloud-Server notwendig. Hierzu werden &lt;em&gt;root&lt;/em&gt;-Rechte benötigt.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo apt-get install git
cd /opt
sudo git clone https://github.com/letsencrypt/letsencrypt
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Im Verzeichnis &lt;code&gt;/opt/letsencrypt&lt;/code&gt; liegen mehrere Scripte mit denen sich automatisiert signierte Zertifikate erstellen lassen. Für uns interessant ist hier &lt;code&gt;letsencrypt-auto&lt;/code&gt;. Mit dem Parameter &lt;code&gt;--help&lt;/code&gt; lassen sich die möglichen Parameter anzeigen.&lt;/p&gt;
&lt;p&gt;Damit bei der automatischen Installation des Zertifikats auch eine Validierung durchgeführt werden kann, sollte der Nginx Proxy kurzfristig gestoppt werden, da die Ports 80 und 443 für die Validierung frei sein sollten.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker stop kivio-proxy
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Das Zertifikat soll für die Domäne depot.kivio.org erzeugt werden. Es ist zu beachten, dass bei der Ausführung des Scripts Let&amp;rsquo;s Encrypt hingeht und noch einige zusätzliche Pakete unter Linux installiert. Zu diesen Paketen gehört bspw. auch Python 3.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./letsencrypt-auto certonly --standalone -d depot.kivio.org 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Dabei gibt &lt;em&gt;certonly&lt;/em&gt; an, dass kein Webserver konfiguriert werden und nur das Zertifikat installiert werden soll. Über den Parameter &lt;em&gt;&amp;ndash;standalone&lt;/em&gt; wird temporär ein Webserver gestartet, mit dem die Domain validiert wird. Mit &lt;em&gt;-d&lt;/em&gt; werden die Domänen angegeben, für die das Zertifikat gültig ist. Jede weitere wird dabei zu den alternativen Namen aufgenommen, wenn die Validierung erfolgreich ist.&lt;/p&gt;
&lt;p&gt;Beim Aufruf des Clients muss eine E-Mail-Adresse hinterlegt und die Nutzungsbedingungen akzeptiert werden. Die hinterlegte E-Mail-Adresse dient zur Kontaktaufnahme bei Sicherheitsproblemen oder einer anstehenden Zertifikatsverlängerung.&lt;/p&gt;
&lt;p&gt;Sollte die Validierung der Domäne fehlschlagen, so kann über eine erneute Ausführung von &lt;code&gt;letsencrypt-auto&lt;/code&gt; ein erneuter Versuch gestartet werden. Der Installer ist entsprechend fehlertolerant.&lt;/p&gt;
&lt;p&gt;Die fertigen Zertifikatsdateien liegen anschließend unter&lt;/p&gt;
&lt;p&gt;&lt;code&gt;/etc/letsencrypt/live/depot.kivio.org&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;bzw. unter dem Namen der primären Domäne die bei der Registrierung angegeben worden ist.&lt;/p&gt;
&lt;p&gt;Zeit für einen kleinen Exkurs zu den abgelegten Dateien.&lt;/p&gt;
&lt;h3&gt;Exkurs=Zertifikatsdateien von Let`s Encrypt&lt;/h3&gt;
&lt;p&gt;War die Installation erfolgreich, dann liegen in dem Zertifikatsordner vier Dateien. Auf deren Bedeutung möchte ich im Folgenden etwas genauer eingehen, denn ein tiefergehendes Verständnis für die Dateien, hilft bei der Konfiguration von Nginx.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;cert.pem&lt;/strong&gt;=Server-Zertifikat, welches für die sichere Kommunikation zwischen Browser und Server notwendig ist. Dieses kann auch selbst ausgestellt werden und gilt dann meist als nicht vertrauenswürdig.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;chain.pem&lt;/strong&gt;=Intermediate Zertifikat, welches die Vertrauenswürdigkeit des Server-Zertifikats sicherstellt. Ist das Intermediate-Zertifikat nicht vorhanden, wird das Zertifikat nicht als vertrauenswürdig eingestuft. Eine entsprechende Warnung des Browsers wird aufgerufen. Die CA - in diesem Falle Let&amp;rsquo;s Encrypt stellt sicher, dass der Server vertrauenswürdig ist. Aus diesem Grund muss die Validierung durch das Auto-Tool ausgeführt werden.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;fullchain.pem&lt;/strong&gt;=Zusammengefügtes Zertifikat aus Server-Zertifikat und Intermediate-Zertifikat. Dieses Zertifikat wird später auch für die Konfiguration von Nginx benötigt.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;privkey.pem&lt;/strong&gt;=Privater Schlüssel&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Nginx konfigurieren&lt;/h3&gt;
&lt;p&gt;Hinter der Domäne &lt;em&gt;depot.kivio.org&lt;/em&gt; läuft aktuell ein TomEE-Server, der eine kleine JSF-Anwendung hostet. Bisher war dieser Server ausschließlich über den Nginx Proxy unverschlüsselt über den Port 80 zu erreichen.&lt;/p&gt;
&lt;p&gt;Die Konfiguration sieht bisher wie folgt aus (es handelt sich hierbei nur um einen Auszug):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;...
upstream depot-ee {
    server depot:8080;
}
...
server {
    listen       80;
    server_name  depot.kivio.org;

    location / {
         proxy_pass         http://depot-ee;
         proxy_redirect     off;
         proxy_set_header   Host $host;
         proxy_set_header   X-Real-IP $remote_addr;
         proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;
         proxy_set_header   X-Forwarded-Host $server_name;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ich nutze alle meine JEE Applikationsserver als Upstream-Server. Das hat den Vorteil, dass die SSL-Kommunikation nur bis zum jeweiligen Nginx-Server aufgebaut werden muss. Dies vereinfacht die Konfiguration der SSL-Kommunikation erheblich.&lt;/p&gt;
&lt;p&gt;Die oben gezeigte Konfiguration muss dahingehend angepasst werden, dass die Proxy-Konfiguration in den Server-Block für die Kommunikation über Port 443 verschoben bzw. die Portkonfiguration für den Block geändert werden muss. Zusätzlich muss Nginx mitgeteilt werden, wo das Zertifikat und der private Schlüssel zu finden sind.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;server {
    listen 443;
    listen [::]:443;
    server_name depot.kivio.org;

    ssl on;
    ssl_certificate /etc/letsencrypt/live/depot.kivio.org/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/depot.kivio.org/privkey.pem;
         
    location / {
        proxy_pass         http://depot-ee;
        ...
    }
} 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ab sofort wäre die Webseite nur noch über &lt;a href=&quot;https://depot.kivio.org&quot;&gt;https://depot.kivio.org&lt;/a&gt; zu erreichen. Damit die Webseite auch ohne Angabe des Protokolls erreicht werden kann, kann im Nginx noch etwas Feintuning vorgenommen werden und ein temporärer Redirect (HTTP Code 301) eingerichtet werden.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;server {
    listen 80;
    listen [::]:80;
    server_name depot.kivio.org;
    return 301 https://depot.kivio.org$request_uri;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Dieser Eintrag sorgt dafür, dass auch eine Eingabe von &lt;code&gt;depot.kivio.org&lt;/code&gt; in einem modernen Browser dafür sorgt, dass die Webseite korrekt über SSL aufgerufen wird. Der Besucher muss sich nicht merken, ob die Webseite über HTTP oder HTTPS aufgerufen wird.&lt;/p&gt;
&lt;p&gt;Die komplette &lt;a href=&quot;https://github.com/rollinhand/kivio-proxy/blob/master/src/main/docker/nginx.conf&quot;&gt;Konfiguration&lt;/a&gt; befindet sich auf GitHub.&lt;/p&gt;
&lt;h3&gt;SSL-Zertifikat verlängern&lt;/h3&gt;
&lt;p&gt;Bei den signierten Zertifikaten ist zu beachten, dass diese nur 90 Tage gültig sind. Verlängern lässt sich das Zertifikat ebenfalls über das bereits bekannte Script. So will Let&amp;rsquo;s Encrypt Unmut über die kurzen Laufzeiten der Zertifikate vermeiden.&lt;/p&gt;
&lt;p&gt;Allerdings ist zu berücksichtigen, dass für die Erneuerung des Zertifikats der Webserver gestoppt werden muss, da ansonsten das Zertifikat nicht verifiziert werden kann.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/opt/letsencrypt/letsencrypt-auto certonly --renew-by-default --standalone -d depot.kivio.org
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Die regelmäßige Verlängerung kann auch über einen Cronjob automatisiert werden. Dabei muss allerdings sichergestellt sein, dass bei der Verlängerung keine Interaktion notwendig ist.&lt;/p&gt;
&lt;p&gt;Zu diesem Zweck habe ich mir ein Script mit dem Namen &lt;a href=&quot;https://github.com/rollinhand/kivio-proxy/blob/master/update-certs.sh&quot;&gt;update-certs.sh&lt;/a&gt; geschrieben, dass über einen Cronjob sonntags nachts gestartet wird und für die Aktualisierung zuständig ist.&lt;/p&gt;
&lt;p&gt;Die &lt;em&gt;cron&lt;/em&gt; table wird mittels &lt;code&gt;sudo crontab -e&lt;/code&gt; aufgerufen und bspw. die folgende Zeile hinzugefügt:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;* 2 * * 7 /opt/update-certs.sh &amp;gt;&amp;gt; /var/log/update-certs.log
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;SSL Zertifikat widerrufen&lt;/h3&gt;
&lt;p&gt;Ein ausgestelltes Zertifikat kann auch widerrufen werden. Dies kann notwendig werden, wenn das Zertifikat nicht mehr benötigt wird.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/opt/letsencrypt/letsencrypt-auto revoke --cert-path /etc/letsencrypt/live/depot.kivio.org/fullchain.pem
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;Docker-Container öffnen&lt;/h3&gt;
&lt;p&gt;Die Nginx-Konfiguration wird in dem Standard Docker-Container verwendet. Damit auf dem Cloud-Server der Nginx auch über den Port 443 zu erreichen ist, muss er seinen Port noch nach außen freigeben.&lt;/p&gt;
&lt;p&gt;Das passiert beim Starten des Containers. Ebenfalls wird beim Start auch das Zertifikatsverzeichnis eingebunden, sodass Nginx auch die Let&amp;rsquo;s Encrypt SSL-Zertifikate findet.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker run -d -p80:80 -p443:443 --restart unless-stopped --name kivio-proxy --network=kivio -v /etc/letsencrypt:/etc/letsencrypt kivio-proxy
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Mit diesem Kommando wird der Container mit dem Docker-Netzwerk &lt;em&gt;kivio&lt;/em&gt; verbunden. In diesem Netzwerk befinden sich die JEE-Applikationsserver, die über ihren Container-Namen in der Nginx-Konfiguration referenziert werden.&lt;/p&gt;
&lt;p&gt;Zusätzlich werden die Ports 80 und 443 nach außen exponiert, sodass der Nginx-Server auch von der Aussenwelt erreichbar ist.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>Redirect auf Favicon vermeiden</title>
      <link>https://kivio.org/blog/entry/2018/05/01/redirect-auf-favicon-vermeiden.html</link>
      <pubDate>Tue, 1 May 2018 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2018/05/01/redirect-auf-favicon-vermeiden.html</guid>
      	<description>
	&lt;p&gt;Bei einer mit Apache Shiro (oder ein anderem Framework) abgesicherten JSF-Seite wird der Anwender nach dem Login zunächst immer auf die Datei &lt;em&gt;favicon.ico&lt;/em&gt; weitergeleitet. Ursachen und deren Behebung habe ich in diesem Blog-Beitrag zusammengetragen.&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;Das oben beschriebene Problem tritt mit allen modernen Browsern auf. Vom Internet Explorer über Google Chrome bis hin zu Apples Safari. Hierfür können verschiedene Ursachen der Grund sein. Jeder der Browser sucht auf einer Webseite nach dem Favicon, dass sowohl in der URL-Zeile als auch beim Setzen eines Lesezeichens herangezogen wird.&lt;/p&gt;
&lt;p&gt;Warum aber wird der Anwender nun ausgerechnet nach dem Login auf &lt;em&gt;favicon.ico&lt;/em&gt; weitergeleitet statt auf die eigentliche Seite im Redirect?&lt;/p&gt;
&lt;h2&gt;Kein Favicon hinterlegt&lt;/h2&gt;
&lt;p&gt;Jede moderne Webseite sollte ein Favicon hinterlegt haben. Der Standard-Dateiname für das Icon ist &lt;em&gt;favicon.ico&lt;/em&gt; und der Browser sucht nach diesem Icon im Root- Verzeichnis der Web-Anwendung, wenn innerhalb der Seite kein anderes Ziel für das Icon hinterlegt ist (siehe nächsten Punkt).&lt;/p&gt;
&lt;p&gt;Nach dem Login versucht der Browser beim Redirect das Icon mittels HTTP GET zu laden und scheitert daran. Diesen Versuch bekommt der Anwender direkt mit.&lt;/p&gt;
&lt;h2&gt;Verweis auf Favicon ist falsch&lt;/h2&gt;
&lt;p&gt;Innerhalb der Webseite kann über&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;link rel=&amp;quot;shortcut icon&amp;quot; href=&amp;quot;/pics/favicon.ico&amp;quot;&amp;gt; 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ein Verweis auf den Speicherort des Icons angegeben werden. Häufig wird das Icon allerdings nicht mehr als 16-Bit ICO-Datei hinterlegt, sondern als PNG oder JPG, da moderne Browser keine Einschränkung mehr bei der Farbtiefe für die Bilder besitzen und auch PNG bspw. Transparenz unterstützt.&lt;/p&gt;
&lt;p&gt;Das bedeutet, dass in diesem Link auch der korrekte Dateiverweis hinterlegt sein sollte. Zusätzlich kann der Browser noch unterstützt werden, indem die Art der Bilddatei über das &lt;code&gt;type&lt;/code&gt;-Attribut mitgeteilt wird:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;link rel=&amp;quot;shortcut icon&amp;quot; href=&amp;quot;/pics/favicon.png&amp;quot; type=&amp;quot;image/png&amp;quot;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;Ressource liegt im geschützten Bereich&lt;/h2&gt;
&lt;p&gt;Ist die Web-Anwendung mit Apache Shiro oder einem anderen Security-Framework abgesichert, so sollte das Favicon, wie auch bspw. CSS-Dateien im ungeschützten Bereich liegen.&lt;/p&gt;
&lt;p&gt;In Apache-Shiro kann dies für eine JSF-Anwendung über die &lt;em&gt;shiro.ini&lt;/em&gt; erreicht werden:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/javax.faces.resource/** = anon
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Damit sind alle JSF-Ressourcen wie Bilder, CSS, etc. nicht mehr geschützt.&lt;/p&gt;
&lt;p&gt;Anhand dieser drei möglichen Ursachen sollte sich das fehlerhafte Routing auch in euren Web-Anwendungen schnell abstellen lassen.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>C3Faces 1.3 officially released</title>
      <link>https://kivio.org/blog/entry/2018/03/27/c3faces-1-dot-3-officially-released.html</link>
      <pubDate>Tue, 27 Mar 2018 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2018/03/27/c3faces-1-dot-3-officially-released.html</guid>
      	<description>
	&lt;p&gt;C3Faces is a chart library for JSF based on c3.js. I want to announce the third official version of this library released to &lt;a href=&quot;https://search.maven.org/#artifactdetails%7Corg.kivio%7Cc3faces%7C1.0%7Cjar&quot;&gt;Maven central&lt;/a&gt; coming with a small fix for older versions of JSF and pre-defined colors and themes.&lt;/p&gt;
&lt;!--more--&gt;
&lt;h2&gt;Fix for older versions of JSF&lt;/h2&gt;
&lt;p&gt;The configuration file &lt;em&gt;faces-config.xml&lt;/em&gt; was extended and is now declaring &lt;em&gt;components&lt;/em&gt; from the taglib. This requirement is defined by older versions of JSF and Spring Boot. Background information demanding this fix can be found &lt;a href=&quot;https://docs.oracle.com/cd/E19575-01/819-3669/bnawo/index.html&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Pre-defined colors and themes&lt;/h2&gt;
&lt;p&gt;It is now possible to select pre-defined colors and themes for much more harmonius colours in charts. Therefore the classes &lt;em&gt;C3Color&lt;/em&gt; and &lt;em&gt;C3Theme&lt;/em&gt; were introduced. &lt;em&gt;C3Theme&lt;/em&gt; contains themes used in Microsoft Excel or LibreOffice Spreadsheet. Showcase does not reflect this change so feel free playing around with this classes.&lt;/p&gt;
&lt;h2&gt;Further information&lt;/h2&gt;
&lt;p&gt;Changelog about further changes between previous version and the present one can be found in the official &lt;a href=&quot;https://github.com/rollinhand/c3faces/blob/master/CHANGELOG&quot;&gt;Changelog&lt;/a&gt; in the GitHub repository.&lt;/p&gt;
&lt;p&gt;Have fun while playing around with C3Faces and if you find any issues or have suggestions for new features please &lt;a href=&quot;https://github.com/rollinhand/c3faces/issues&quot;&gt;leave a comment&lt;/a&gt;.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>C3Faces 1.2 officially released</title>
      <link>https://kivio.org/blog/entry/2018/03/04/c3faces-1-dot-1-officially-released.html</link>
      <pubDate>Sun, 4 Mar 2018 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2018/03/04/c3faces-1-dot-1-officially-released.html</guid>
      	<description>
	&lt;p&gt;C3Faces is a chart library for JSF based on c3.js. I want to announce the second official version of this library released to &lt;a href=&quot;https://search.maven.org/#artifactdetails%7Corg.kivio%7Cc3faces%7C1.0%7Cjar&quot;&gt;Maven central&lt;/a&gt; coming with category-based axes and new elements in the taglib to manipulate axes.&lt;/p&gt;
&lt;!--more--&gt;
&lt;h2&gt;Version 1.2 now supports category-based axes.&lt;/h2&gt;
&lt;p&gt;Now you can choose between indexed and category-based axes. Therefore I introduced new elements in the taglib=axes, axisX and axisY.&lt;/p&gt;
&lt;p&gt;As with the elements of gridX and gridY, axisX and axisY enables you to adjust the type, height and visibility of your axes. The outer element axes supports rotation of the axes.&lt;/p&gt;
&lt;p&gt;Using a category based axis you might write something like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;c3:bar data=&amp;quot;#{chartTypesBean.data}&amp;quot;&amp;gt;
    &amp;lt;c3:axes&amp;gt;
        &amp;lt;c3:axisX type=&amp;quot;category&amp;quot; categories=&amp;quot;{&apos;Mon&apos;, &apos;Tue&apos;, &apos;Wed&apos;, &apos;Thu&apos;, &apos;Fri&apos;, &apos;Sat&apos;, &apos;Sun&apos;}&amp;quot; /&amp;gt;
        &amp;lt;c3:axisY show=&amp;quot;false&amp;quot; /&amp;gt;
    &amp;lt;/c3:axes&amp;gt;
&amp;lt;/c3:bar&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The X-axis will be no longer labeled with numbers from 1 to 7, but with labels from Mon to Sun in the order of the array&amp;rsquo;s elements.&lt;/p&gt;
&lt;p&gt;If you use categories programmatically there is a new class called &lt;em&gt;C3Category&lt;/em&gt; which takes a list or an array of Strings as constructor parameter. &lt;strong&gt;But note:&lt;/strong&gt; The returning value inside is always a Set of strings. Duplicates are not taken into account because categories should be always unique. Additional details can be found in the &lt;a href=&quot;http://c3js.org/reference.html#axis-x-categories&quot;&gt;official documentation of C3.js&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In the above example Y-axis is not visible in the diagram.&lt;/p&gt;
&lt;h2&gt;Showcase update&lt;/h2&gt;
&lt;p&gt;If you want to see version 1.2 with axis configuration in action, please visit the &lt;a href=&quot;http://c3faces.kivio.org&quot;&gt;official showcase&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Further information&lt;/h2&gt;
&lt;p&gt;Changelog about further changes between previous version and the present one can be found in the official &lt;a href=&quot;https://github.com/rollinhand/c3faces/blob/master/CHANGELOG&quot;&gt;Changelog&lt;/a&gt; in the GitHub repository.&lt;/p&gt;
&lt;p&gt;This post was updated to version 1.2 because prior version contained a bug which lead to non working axis configuration.&lt;/p&gt;
&lt;p&gt;Have fun while playing around with C3Faces and if you find any issues or have suggestions for new features please &lt;a href=&quot;https://github.com/rollinhand/c3faces/issues&quot;&gt;leave a comment&lt;/a&gt;.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>C3Faces 1.0 officially released</title>
      <link>https://kivio.org/blog/entry/2018/01/22/c3faces-1-dot-0-officially-released.html</link>
      <pubDate>Mon, 22 Jan 2018 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2018/01/22/c3faces-1-dot-0-officially-released.html</guid>
      	<description>
	&lt;p&gt;C3Faces is a chart library for JSF based on c3.js. I want to announce the first official version of this library released to &lt;a href=&quot;https://search.maven.org/#artifactdetails%7Corg.kivio%7Cc3faces%7C1.0%7Cjar&quot;&gt;Maven central&lt;/a&gt;.&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;This version is based on the work of Martin Linha who started the project in 2015 but do not maintains it any longer. There were several requests which voted for an official release to Maven central making it easy to declare it as dependency in an webapps pom.&lt;/p&gt;
&lt;p&gt;I forked this library and and refactored some internals preparing the library for some additions coming with version 1.1 which is planned for February.&lt;/p&gt;
&lt;p&gt;Changelog about further changes between the original version and the forked one can be found in the official &lt;a href=&quot;https://github.com/rollinhand/c3faces/blob/master/CHANGELOG&quot;&gt;Changelog&lt;/a&gt; in the GitHub repository.&lt;/p&gt;
&lt;p&gt;A showcase presenting the yet implemented features can be found on &lt;a href=&quot;http://c3faces.kivio.org&quot;&gt;http://c3faces.kivio.org&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Have fun while playing around with C3Faces and if you find any issues or have suggestions for new features please &lt;a href=&quot;https://github.com/rollinhand/c3faces/issues&quot;&gt;leave a comment&lt;/a&gt;.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>NetBeans 9 vermisst</title>
      <link>https://kivio.org/blog/entry/2017/12/31/netbeans-9-vermisst.html</link>
      <pubDate>Sun, 31 Dec 2017 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2017/12/31/netbeans-9-vermisst.html</guid>
      	<description>
	&lt;p&gt;Java 9 ist seit geraumer Zeit in der finalen Version verfügbar. NetBeans 9 lässt allerdings nach wie vor noch auf sich warten. Der Umzug zu Apache ist aufwändiger als gedacht.&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;Bislang wurden neue Major-Version von Java und NetBeans fast zeitgleich veröffentlicht, sodass NetBeans immer die erste IDE war, die neue Sprachfeatures unterstützt hat. Geplant war die Veröffentlichung der Version 9.0 bereits für &lt;a href=&quot;http://wiki.netbeans.org/NetBeans_9&quot;&gt;Juni 2017&lt;/a&gt;. Durch die von Oracle initiierte Übergabe von NetBeans an das Apache-Projekt konnten diese ambitionierten Ziele nicht eingehalten werden.&lt;/p&gt;
&lt;h2&gt;Module müssen überprüft werden&lt;/h2&gt;
&lt;p&gt;NetBeans besteht aus zahlreichen Modulen, die die gesamte IDE ausmachen. Bevor ein Projekt offiziell unter das Dach der Apache Foundation schlüpfen kann, ist zu gewährleisten, dass die Software frei von Rechten Dritter ist und das der Code den Anforderungen der Apache 2.0-Lizenz entspricht. Das sieht auch vor, dass im Quellcode entsprechende Header-Passagen eingefügt sind.&lt;/p&gt;
&lt;p&gt;Zum aktuellen Zeitpunkt ist die Community rund um NetBeans mehr mit der Apache-Kompatibilität als mit neuen Features beschäftigt. Damit die Arbeit an der Prüfung der Module schneller voran geht, hat die &lt;a href=&quot;https://cwiki.apache.org/confluence/display/NETBEANS/List+of+Modules+to+Review&quot;&gt;Community einen Aufruf gestartet&lt;/a&gt; und sucht freiwillige Helfer, die ebenfalls Module auf lizenzrechtliche Gültigkeit prüfen.&lt;/p&gt;
&lt;p&gt;Auf der eingerichteten Wiki-Seite kann ebenfalls nachvollzogen werden, wie viele Module und deren Abhängigkeiten noch zu prüfen sind. Demnach sieht es für ein baldiges Release schlecht aus.&lt;/p&gt;
&lt;h2&gt;NetBeans als IDE abgehängt&lt;/h2&gt;
&lt;p&gt;Während IntelliJ und Eclipse bereits neue Versionen ihrer IDE mit Unterstützung für Sprachfeatures von Java 9 wie dem Modulsystem Jigsaw veröffentlicht haben, ist NetBeans immer noch mit sich selbst beschäftigt.&lt;/p&gt;
&lt;p&gt;Dabei zeigt sich, dass Oracle aus seiner Transition von OpenOffice zu Apache nichts gelernt hat. Nachdem OpenOffice heute keine Bedeutung mehr hat - alle wichtigen Linux-Distributionen unterstützen LibreOffice - könnte NetBeans das gleiche Schicksal drohen.&lt;/p&gt;
&lt;p&gt;Meine noch im März geäußerte Euphorie ist aktuell mächtig gedämpft.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>Oracle 12.2 veröffentlicht</title>
      <link>https://kivio.org/blog/entry/2017/09/12/oracle-12-dot-2-veroffentlicht.html</link>
      <pubDate>Tue, 12 Sep 2017 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2017/09/12/oracle-12-dot-2-veroffentlicht.html</guid>
      	<description>
	&lt;p&gt;Nachdem die Oracle-Datenbank in der Version 12.2 bis vor Kurzem nur in Oracles Cloud Services verfügbar war, ist die aktuelle Version der Datenbank nun für alle zum &lt;a href=&quot;http://www.oracle.com/technetwork/database/enterprise-edition/downloads/index.html&quot;&gt;Download&lt;/a&gt; verfügbar. Der Artikel beschreibt in Kürze die neuen Features.&lt;/p&gt;
&lt;!--more--&gt;
&lt;h2&gt;Multitenant-Architektur&lt;/h2&gt;
&lt;p&gt;Mit der Version 12.2 setzt Oracle nun vollständig auf die &lt;strong&gt;Multitenant-Architektur&lt;/strong&gt; und setzt damit voll auf den Trend Software in der Cloud zu betreiben. Mit den Pluggable Databases (PDB) soll es möglich sein, Ressourcen und damit Kosten einzusparen.&lt;/p&gt;
&lt;p&gt;Das Prinzip sieht vor, dass sich mehrere PDB innerhalb einer Container-Datenbank (CDB) gemeinsame Ressourcen teilen. War bisher nur vorgesehen, dass sich PDBs den Hauptspeicher teilen, ist der Schritt in Version 12.2 weiter gedacht und es besteht die Möglichkeit, dass sich PDBs auch das gleiche Datenmodell und sogar statische Anwendungsdaten teilen können.&lt;/p&gt;
&lt;p&gt;Operationen wie das Verschieben und Klonen von Datenbanken (PDB) sind nun online möglich. Damit allerdings das Verschieben von Datenbanken (Relocate) fast vollständig ohne Downtime funktioniert, sind eine Menge Besonderheiten beim Aufsetzen der jeweiligen Container-Datenbank zu berücksichtigen. Ohne eine kurze Downtime, wie beim Verschieben von virtuellen Maschinen in VMWares VSphere, ist die Relocation allerdings nicht möglich.&lt;/p&gt;
&lt;h2&gt;Adaptive Features&lt;/h2&gt;
&lt;p&gt;Die adaptiven Features in Oracle 12.2 wurden verbessert - man könnte auch sagen, die adaptiven Features sollen nun endlich wie gewünscht funktionieren. Vielfach haben frustrierte Datenbankadministratoren in der Community berichtet, dass sie die adaptiven Feature deaktiviert haben, da nicht nachvollziehbar war, wie der Optimizer beeinflusst wurde.&lt;/p&gt;
&lt;p&gt;Die ersten Erfahrungsberichte der Oracle 12.2-Datenbank bleiben abzuwarten.&lt;/p&gt;
&lt;h2&gt;Neue Features für Entwickler&lt;/h2&gt;
&lt;p&gt;Bisher lästig war die &lt;strong&gt;Zeichenbeschränkung&lt;/strong&gt; von 30 Bytes für Bezeichner. Diese Grenze wurde nun auf 128 Bytes angehoben, sodass auch aussagekräfte Namen vergeben werden können. Auch wird die Migration zum Beispiel von PostgreSQL-Datenbanken zu Oracle damit einfacher.&lt;/p&gt;
&lt;p&gt;Bereits besonders ausgereift war das Zugreifen auf abgelegte XML-Daten; mit 12.1 kam die Möglichkeit hinzu auch &lt;strong&gt;JSON-Daten&lt;/strong&gt; abzulegen und mittels Abfragen auf die Daten zuzugreifen. Richtig rund und ausgereift waren die zur Verfügung gestellten Funktionen allerdings noch nicht. Hier wurde neue und verbesserte Funktionen zur Verfügung gestellt.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Ausführliche Details zu Oracle 12.2 finden sich in der Ausgabe 4/2017 des Red Stack Magazins der DOAG&lt;/em&gt;&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>OEPE=Projekte mit Maven erstellen</title>
      <link>https://kivio.org/blog/entry/2017/08/24/oepe-projekte-mit-maven-erstellen.html</link>
      <pubDate>Thu, 24 Aug 2017 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2017/08/24/oepe-projekte-mit-maven-erstellen.html</guid>
      	<description>
	&lt;p&gt;ADF-Projekte werden nach den Oracle-Tutorials nicht unbedingt mit einem allgemeinen Build-Tool wie Maven erstellt. In Oracles Enterprise Pack for Eclipse (OEPE) verstecken sich allerdings auch Maven-Archetypen, um ein typisches ADF-Projekt zu erstellen.&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;Oracle liefert in OEPE einen Maven archetype mit, um eine ADF Basic Application erstellen zu können. Dieses auf Basis von Maven erstellte Projekt lässt sich dann problemlos in Eclipse (OEPE) importieren.&lt;/p&gt;
&lt;p&gt;Der Archetyp befindet sich im Installationsverzeichnis von oepe unter &lt;code&gt;plugins\oracle.eclipse.tools.adf_7.4.0.201504081335\maven\ADF Basic Application Archetype&lt;/code&gt;&lt;/p&gt;
&lt;h3&gt;Archetype installieren&lt;/h3&gt;
&lt;p&gt;Auf der Kommandozeile werden in diesem Verzeichnis nacheinander die folgenden Kommandos ausgeführt, um den Archetypen in das lokale Maven-Repository zu integrieren:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mvn clean install
mvn archetype:update-local-catalog
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;Projekt initial erstellen&lt;/h3&gt;
&lt;p&gt;Um ein initiales Projekt mit diesem Archetypen anzulegen, kann der folgende Befehl auf der Kommandozeile abgesetzt werden:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;mvn archetype:generate -DarchetypeGroupId=com.oracle.adf.archetype -DarchetypeArtifactId=adf-basic-application -DarchetypeVersion=12.1.2-0-0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;/p&gt;
&lt;h3&gt;Besserer OEPE Archetype&lt;/h3&gt;
&lt;p&gt;Da es immer wieder Probleme mit dem mitgelieferten Archetypen von Oracle gegeben hat, weil die Templates nicht korrekt waren oder Abhängigkeiten nicht mit der verwendeten OEPE- bzw. ADF-Version überein stimmten, habe ich einen eigenen Archetype erzeugt, der ein sofort funktionales ADF Projekt erzeugt.&lt;/p&gt;
&lt;p&gt;Das Projekt findet sich auf &lt;a href=&quot;https://github.com/rollinhand/oepe&quot;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>Einbindung von Glassfish in OEPE</title>
      <link>https://kivio.org/blog/entry/2017/08/24/einbindung-von-glassfish-in-oepe.html</link>
      <pubDate>Thu, 24 Aug 2017 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2017/08/24/einbindung-von-glassfish-in-oepe.html</guid>
      	<description>
	&lt;p&gt;In Eclipse gibt es in der Perspektive Java EE den View Servers über den verschiedene Java EE Server gemanagt werden könne. Auch der Glassfish 3 und Glassfish 4 können darüber lokal und remote verwaltet werden.&lt;/p&gt;
&lt;!--more--&gt;
&lt;h3&gt;Hintergrundinformationen&lt;/h3&gt;
&lt;p&gt;Eigentlich ist die Entwicklung von ADF-Anwendungen hart an Oracles Weblogic-Server gekoppelt. Allerdings stehen mit den ADF Essentials auch die Basisbibliotheken kostenlos zur Verfügung und können in einen Java EE-Server deployt werden, der das Full-Profile unterstützt.&lt;/p&gt;
&lt;p&gt;Für die Entwicklung mit OEPE bietet sich hier der Glassfish- oder Payara-Server an. Aufgrund der vielen offenen Bugs in Glassfish 4, sollte Payara in dieser Version der Vorzug gegeben werden. Der zu Java EE 6-kompatible Glassfish 3 funktioniert problemlos mit OEPE 12.1.3.&lt;/p&gt;
&lt;h3&gt;Einrichtung der lokalen Glassfish-Installation&lt;/h3&gt;
&lt;p&gt;Damit ein Glassfish-Server remote verwaltet werden kann, ist zusätzlich immer eine lokale Glassfish-Installation notwendig, da aus der Installation für das Remote-Management der &lt;em&gt;asadmin&lt;/em&gt; benötigt wird. Eclipse setzt hier nicht wie JDeveloper auf eine eigene Implementierung für die Steuerung und das Management.&lt;/p&gt;
&lt;p&gt;Die Einrichtung in diesem Tutorial bezieht sich auf einen Mac und die Einrichtung des Glassfish-Server lokal und in einer virtuellen Maschine.&lt;/p&gt;
&lt;p&gt;Auf dem Mac ist das ZIP-Archiv für den Glassfish-Server in das Verzeichnis &lt;code&gt;/opt&lt;/code&gt; extrahiert worden, so dass in Eclipse der Server Root &lt;code&gt;/opt/glassfish3/glassfish&lt;/code&gt; lautet. &lt;/p&gt;
&lt;h3&gt;Einbindung in Eclipse&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Tipp:&lt;/em&gt; Eclipse sollte vor der Installation geschlossen sein, denn die Umgebung sucht die Standardpfade nach installierten Runtime-Umgebungen ab, sodass die Einrichtung der Serververbindungen deutlich vereinfacht werden kann.&lt;/p&gt;
&lt;p&gt;In Eclipse legt man unter den Servern zunächst den lokalen Glassfish-Server an, damit es später keine Probleme beim Einrichten der Domäne gibt.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;glassfish01.png&quot; alt=&quot;Neuen Server anlegen&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Anschließend können die Credentials für den administrativen Login hinterlegt werden:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;glassfish02.png&quot; alt=&quot;Credentials hinterlegen&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Die Einstellungen zur Verwaltung eines Remote-Servers unterscheiden sich nicht großartig von denen eines lokalen Glassfish-Servers:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;glassfish03.png&quot; alt=&quot;Remote Server anlegen&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Lediglich die Credentials werden um den Admin-Port erweitert. Über Test Connection kann geprüft werden, ob die Einstellungen korrekt sind und eine Verbindung zum Server hergestellt werden kann.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;glassfish04.png&quot; alt=&quot;Remote Credentials hinterlegen&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Tipp:&lt;/em&gt; Über das Kontextmenü eines Servers können auch die ADF Essentials automatisch deployt werden.&lt;/p&gt;
&lt;h3&gt;Weitere Ressourcen&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Auf &lt;a href=&quot;https://github.com/rollinhand/lgmj-server&quot;&gt;GitHub&lt;/a&gt; existiert ein Projekt von mir, dass einen &lt;a href=&quot;https://github.com/rollinhand/lgmj-server&quot;&gt;initialen Entwicklungsserver für OEPE&lt;/a&gt; aufsetzt.&lt;/li&gt;
&lt;/ul&gt;

	</description>
    </item>
    <item>
      <title>Runtastic Daten nach Garmin Connect umziehen</title>
      <link>https://kivio.org/blog/entry/2017/04/12/runtastic-daten-nach-garmin-connect-umziehen.html</link>
      <pubDate>Wed, 12 Apr 2017 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2017/04/12/runtastic-daten-nach-garmin-connect-umziehen.html</guid>
      	<description>
	&lt;p&gt;Aktivitätsdaten von Runtastic zu einem anderen Anbieter umzuziehen ist nicht leicht. Welche Fallstricke bei einem Umzug nach &lt;a href=&quot;http://connect.garmin.com&quot;&gt;Garmin Connect&lt;/a&gt; zu erwarten sind, zeige ich in diesem Beitrag.&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;Vorab ist zu sagen, dass die &lt;a href=&quot;https://blog.dafb-o.de/massenexport-von-runtastic-aktivitaeten/&quot;&gt;einschlägigen Lösungen für einen Massenexport&lt;/a&gt; der bei Runtastic gespeicherten Daten seit einigen Monaten nicht mehr möglich ist. Der Anwender bekommt bei einem mehrfachen Download von Aktivitäten im Format TCX oder GPX ein Google-Captcha angezeigt. Runtastic verifiziert damit, dass der Download nicht durch einen Roboter durchgeführt wird. Implizit soll durch diese Hürde natürlich der Umzug zu einem anderen Portal wie &lt;a href=&quot;http://www.strava.com&quot;&gt;Strava&lt;/a&gt; oder &lt;a href=&quot;http://connect.garmin.com&quot;&gt;Garmin Connect&lt;/a&gt; erschwert werden.&lt;/p&gt;
&lt;h3&gt;Was ist beim Umzug nach Garmin Connect zu berücksichtigen?&lt;/h3&gt;
&lt;p&gt;Hat man sich letztendlich doch dazu entschieden, die einzelnen Aktivitäten nach Garmin oder Strava umzuziehen, so sollte nach Möglichkeit als Export-Format &lt;strong&gt;TCX&lt;/strong&gt; gewählt werden. In diesem Format lässt sich die Aktivität auch klassifizieren. Dies hilft dabei, dass bei Garmin Connect oder Strava die Aktivität nicht noch manuell klassifiziert werden muss, sondern beim Import automatisch korrekt erkannt wird.&lt;/p&gt;
&lt;p&gt;Allerdings gibt es beim Export von Runtastic noch einen weiteren Pferdfuß über den ich gestolpert bin. Die durch Runtastic vorgenommene Klassifikation in den TCX-Dateien ist nicht mit den bei Garmin hinterlegten Aktivitäten kompatibel.&lt;/p&gt;
&lt;p&gt;Daher ist es notwendig, die Dateien nach dem Export zu bearbeiten. Für die Aktivität Laufen muss dabei die Klassifikation &lt;em&gt;running&lt;/em&gt; durch &lt;em&gt;Running&lt;/em&gt; und beim Radfahren die Klassifikation &lt;em&gt;cycling&lt;/em&gt; durch &lt;em&gt;Biking&lt;/em&gt; ersetzt werden. Schnell und einfach geht das unter macOS oder Linux in einem Terminal mit den folgenden zwei Zeilen Code:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;for file in $( ls ); do sed -i &apos;&apos; &apos;s/running/Running/g&apos; $file; done
for file in $( ls ); do sed -i &apos;&apos; &apos;s/Swimming/Other/g&apos; $file; done
for file in $( ls ); do sed -i &apos;&apos; &apos;s/cycling/Biking/g&apos; $file; done
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ebenfalls zu beachten ist, das bei einem Export die Zwischenzeiten nicht übernommen werden. Allerdings sollte dies für ältere Aktivitäten verschmerzbar sein.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>NetBeans kommt bei Apache voran</title>
      <link>https://kivio.org/blog/entry/2017/03/11/netbeans-kommt-bei-apache-voran.html</link>
      <pubDate>Sat, 11 Mar 2017 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2017/03/11/netbeans-kommt-bei-apache-voran.html</guid>
      	<description>
	&lt;p&gt;Geertjan Wielenga als Principal Product Manager bei Oracle verantwortlich für die Entwickler-Tools hat in seinem &lt;a href=&quot;https://blogs.oracle.com/geertjan/entry/netbeans_and_apache1&quot;&gt;Blog&lt;/a&gt; über den Fortschritt des Wechsels von NetBeans zur Apache Foundation berichtet.&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;Demnach schreitet die Migration der Sourcen von Mercurial zu Git voran. Zeitgleich muss jede Menge alter Quellcode überprüft werden, ob dieser mit der Apache Lizenz kompatibel ist und keine Urheberrechte Dritter verletzt werden. Oracle kann nur die Sourcen an die Apache Foundation übergeben, an denen Oracle auch die Rechte besitzt und bei denen das Copyright klar ersichtlich ist.&lt;/p&gt;
&lt;p&gt;Bei einem Repository, dass Sourcen aus gegenwärtig 20 Jahren Entwicklung beinhaltet, ist dies keine leichte Aufgabe, die zeitaufwändig ist. Um den Fortschritt der Integration von NetBeans in den Projekt-Stack von Apache zu veranschaulichen, hat die Gruppe eine &lt;a href=&quot;https://cwiki.apache.org/confluence/display/NETBEANS/Apache+Transition&quot;&gt;Webseite ins Netz&lt;/a&gt; gestellt, auf denen jeder Interessierte den Fortschritt in den unterschiedlichen Arbeitspaketen verfolgen kann.&lt;/p&gt;
&lt;p&gt;Es besteht weiterhin das Ziel NetBeans 8.3 bereits als Apache Incubator zu veröffentlichen. Spätestens allerdings mit NetBeans 9 soll die Entwicklungsumgebung ein reines Apache-Projekt sein. Das würde bedeuten, dass alle Transition-Arbeiten im Juli abgeschlossen sein müssen.&lt;/p&gt;
&lt;p&gt;Das neue JDK 9 soll &lt;a href=&quot;https://jaxenter.de/java-9-release-48310&quot;&gt;laut Oracle Ende Juli 2017&lt;/a&gt; erscheinen. Zeitgleich mit einem Major-Release von Java ist auch immer eine neue Major-Version von NetBeans erschienen, die bereits alle neuen Funktionen und Sprach-Features von Java unterstützt hat. Die vorläufige &lt;a href=&quot;https://netbeans.org/community/releases/roadmap.html&quot;&gt;Roadmap&lt;/a&gt; sieht vor, dass NetBeans 9 Ende Juli 2017 verfügbar sein wird.&lt;/p&gt;
&lt;p&gt;Es bleibt abzuwarten, ob der ehrgeizige Plan von den Entwicklern eingehalten werden kann.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>Internal Server Error durch fehlerhafte EL Expression</title>
      <link>https://kivio.org/blog/entry/2017/02/13/internal-server-error.html</link>
      <pubDate>Mon, 13 Feb 2017 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2017/02/13/internal-server-error.html</guid>
      	<description>
	&lt;p&gt;Einen internen Serverfehler (Fehler 500) in einer ADF-Anwendung zu finden, ist nicht immer trivial. Die Erfahrung hat mich allerdings gelehrt, dass der Fehler in 90 Prozent aller Fälle auf eine fehlerhafte Interpretation einer EL-Expression oder fehlende Ressourcen zurückzuführen ist.&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;In den häufigsten Fällen handelt es sich bei ADF um eine fehlgeschlagene Auswertung einer EL-Expression, weil nicht der korrekte Datentyp bei der Evaluierung berücksichtigt worden ist.&lt;/p&gt;
&lt;p&gt;Wird bspw. eine Variable vom Typ &lt;em&gt;DBSequence&lt;/em&gt; ausgewertet, so reicht es nicht, als Anweisung folgendes zu schreiben: &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{pageFlowScope.sequence &amp;gt; 0}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Es muss auf den Wert und nicht den Objekttyp für die Evaluation des Ausdrucks zugegriffen werden. Hierzu sollte in den meisten Fällen &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#{pageFlowScope.sequence.value &amp;gt; 0} 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ausreichen. Es gibt auch die Möglichkeit die Rückgabe des Datentyps zu beeinflussen, indem &lt;em&gt;intValue()&lt;/em&gt; oder &lt;em&gt;doubleValue()&lt;/em&gt; genutzt wird. Eine andere Möglichkeit für die Evaluation des Wertes besteht im expliziten Aufruf der Methode &lt;em&gt;toString()&lt;/em&gt;. Unterstützt der Objekttyp diese Konvertierung aber nicht, so wird null zurückgegeben.&lt;/p&gt;
&lt;p&gt;Null ist in der EL-Sprache nicht bekannt und führt so bei der Evaluation zu null &amp;gt; 0 und einer Exception. Diese wiederum resultiert in einem Fehler 500.&lt;/p&gt;
&lt;p&gt;Um eine EL-Expression im Vorfeld zu testen, kann im Debug-Modus der EL-Evaluator des JDeveloper genutzt werden. Hier kann detailliert geprüft werden, wie eine EL-Expression funktioniert und in welchem Ergebnis ein Ausdruck resultiert.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>iTunes Bibliothek auf Transcend JetDrive Lite</title>
      <link>https://kivio.org/blog/entry/2016/12/31/itunes-bibliothek-auf-transcend-jetdrive.html</link>
      <pubDate>Sat, 31 Dec 2016 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2016/12/31/itunes-bibliothek-auf-transcend-jetdrive.html</guid>
      	<description>
	&lt;p&gt;Gerade die mobilen Macs der neuen Generation mit SSD haben meist zu wenig Speicherplatz, um eine große Musikbibliothek aufzunehmen. Die Verlagerung der iTunes-Bibliothek auf eine SD-Karte oder externe Platte liegt dabei nahe und kann mitunter Fallstricke bieten.&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;Die Apple Foren sind voll mit den Meldungen, dass die Verlagerung der iTunes Bibliothek auf eine SD-Karte oder externe USB-Festplatte zu extremen Performance-Einbußen führt. Bei der Bedienung von iTunes ist häufig der Beachball zu sehen.&lt;/p&gt;
&lt;p&gt;Das Problem soll an einem &lt;a href=&quot;https://de.transcend-info.com/apple/jetdrivelite/&quot;&gt;Transcend JetDrive Lite&lt;/a&gt; näher beleuchtet werden, denn es bietet eine kostengünstige und platzsparende Möglichkeit an, seine iTunes Bibliothek auszulagern.&lt;/p&gt;
&lt;p&gt;Damit iTunes effizient auf seine Bibliothek zugreifen kann, ist es wichtig, dass die SD-Karte mit dem Dateisystem &lt;strong&gt;HFS+&lt;/strong&gt; und nicht &lt;strong&gt;exFAT&lt;/strong&gt; formatiert ist. Im Auslieferzustand sind die JetDrive-Karten mit exFAT formatiert, um auch unter Windows und Linux genutzt werden zu können. Die Abbildung zeigt, wie die korrekte Formatierung unter macOS auszusehen hat.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;hdd-transcend.png&quot; alt=&quot;Korrekte Formatierung einer SD-Karte&quot; /&gt; &lt;em&gt;Abb. 1=Korrekte Formatierung einer SD-Karte&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Scheinbar läuft iTunes auf einem Dateisystem mit Journaling performanter. Bei länger andauernden Schreiboperationen auf einem Laufwerk mit Journaling kann beobachtet werden, dass iTunes eine Datei mit dem Namen &lt;em&gt;iTunes Library.itl.journaled&lt;/em&gt; anlegt. Technisch lassen sich bei Apple zu diesen Beobachtungen keine Hinweise finden. Der Unterschied der Geschwindigkeit ist allerdings messbar.&lt;/p&gt;
&lt;p&gt;Sofern die SD-Karte nicht also auch unter einem anderen Betriebssystem parallel genutzt werden soll, bietet es sich an, ein Transcend JetDrive direkt mit dem Dateisystem HFS+ zu formatieren.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>Oracle reicht NetBeans an Apache weiter</title>
      <link>https://kivio.org/blog/entry/2016/12/29/oracle-reicht-netbeans-an-apache-weiter.html</link>
      <pubDate>Thu, 29 Dec 2016 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2016/12/29/oracle-reicht-netbeans-an-apache-weiter.html</guid>
      	<description>
	&lt;p&gt;Bereits im September hat Oracle beschlossen, sich von &lt;a href=&quot;http://www.netbeans.org&quot;&gt;NetBeans&lt;/a&gt; zu trennen. Die IDE soll zur Weiterentwicklung an die Apache Software Foundation wechseln. Der Transfer von OpenOffice an die ASF hat das Ende der Bürosuite eingeläutet. Welche Zukunft wird NetBeans haben - ein paar Gedanken dazu.&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;Bis vor wenigen Wochen hat Oracle sich den Luxus gegönnt, drei Java IDEs selbst zu entwickeln bzw. die Entwicklung zu unterstützen. Neben dem &lt;a href=&quot;http://www.oracle.com/technetwork/developer-tools/jdev/overview/index.html&quot;&gt;JDeveloper&lt;/a&gt; und NetBeans hat Oracle noch das &lt;a href=&quot;http://www.oracle.com/technetwork/developer-tools/eclipse/overview/index.html&quot;&gt;Oracle Enterprise Pack for Eclipse (OEPE)&lt;/a&gt; im Angebot. Der JDeveloper und OEPE sind extrem stark auf die Entwicklung mit Oracles Application Development Framework (ADF) ausgerichtet. Auch wenn die Entwickler des OEPE deutlich agiler und neue Funktionen deutlich schneller über den Update-Mechanismus der Eclipse-Umgebung zur Verfügung stellen, ist der JDeveloper immer noch das Entwicklungswerkzeug der ersten Wahl bei Oracle.&lt;/p&gt;
&lt;p&gt;Es sieht nun so aus, als habe sich Oracle dazu entschlossen, die Weiterentwicklung von NetBeans in die Hände der ASF zu legen. Ein Proposal zur Aufnahme in den &lt;a href=&quot;https://wiki.apache.org/incubator/NetBeansProposal&quot;&gt;Incubator&lt;/a&gt; wurde seitens des ASF akzeptiert. Einer Version von NetBeans unter der Ägide der ASF steht also lediglich die Bereinigung des Source-Codes im Wege. Denn noch enthält die IDE einen Teil an Code, der nicht kompatibel mit der Apache-Lizenz ist.&lt;/p&gt;
&lt;p&gt;Parallelen zur Übergabe von OpenOffice an die ASF wecken hierbei ein ungutes Gefühl. Mit dem Unterschied zu OpenOffice könnte Oracle allerdings ein echtes Interesse am Fortbestand der IDE haben. NetBeans ist die Basis für einige Produkte, die Oracle seinen Anwendern zur Verfügung stellt=Hierzu gehören der JDeveloper und der &lt;a href=&quot;http://www.oracle.com/technetwork/developer-tools/sql-developer/overview/index.html&quot;&gt;SQLDeveloper&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Laut dem Proposal will Oracle ein Team von namhaften Entwicklern zur Verfügung stellen. Die Weiterentwicklung soll so in Zusammenarbeit mit der Community gewährleistet werden. Vielleicht erhält NetBeans somit eine neue Zukunft, die weitere Committer anzieht, die rund um die IDE professionelle Bündel schnüren, denn NetBeans war schon immer deutlich leichtgewichtiger als Eclipse.&lt;/p&gt;
&lt;p&gt;Sollte Oracle die Unterstützung langfristig aufrechterhalten, um sich nicht der Basis für die hauseigenen Produkte zu berauben, dürfte NetBeans einen neuen Frühling erleben. Andernfalls wird die IDE wahrscheinlich das gleiche Schicksal ereilen wie die Bürosuite OpenOffice von der heute kaum noch jemand spricht. Hier hat sich die Community zum Glück selbst geholfen und den erfolgreichen Fork LibreOffice geschaffen. Bleibt zu hoffen, dass die Community in dem Falle des Liebesentzuges durch Oracle, die Unterstützung für NetBeans kompensieren und Vielfalt der Java-IDEs aufrechterhalten kann.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>Feed für Jekyll-basierten Blog erstellen</title>
      <link>https://kivio.org/blog/entry/2016/12/26/feed-fuer-jekyll-erstellen.html</link>
      <pubDate>Mon, 26 Dec 2016 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2016/12/26/feed-fuer-jekyll-erstellen.html</guid>
      	<description>
	&lt;p&gt;Ein Blog mit redaktionellen Inhalten benötigt einen Feed. Leser können so bequem die Inhalte über einen Feed-/News-Reader abonnieren. Wie es mit Jekyll funktioniert, verrät dieser Beitrag.&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;Seit 2005 haben sich zwei Formate für News-Feeds etabliert=RSS 2.0 und Atom. Um alle Leser eines Blogs oder Nachrichtenportals abzuholen, bietet es sich an, beide Formate zum Abonnement auf der Webseite anzubieten. Beide Formate sind unterschiedlich und haben ihre Stärken und Schwächen.&lt;/p&gt;
&lt;p&gt;Einen &lt;a href=&quot;https://meiert.com/de/publications/translations/intertwingly.net/rss-2.0-and-atom-1.0/&quot;&gt;guten Überblick über die Unterschiede&lt;/a&gt; der beiden Formate bietet die Übersetzung eines Artikels von Sam Ruby auf der Webseite von Jens Oliver Meiert.&lt;/p&gt;
&lt;p&gt;Von Haus aus bringt &lt;a href=&quot;http://jekyllrb.com&quot;&gt;Jekyll&lt;/a&gt; zunächst keine Feedunterstützung mit. Auf der Webseite des Projekts finden sich zwar Plugins zum Generieren von RSS 2.0- und Atom-Feeds; allerdings lassen sich nicht alle Plugins mit GitHub Pages verwenden.&lt;/p&gt;
&lt;p&gt;Die entsprechenden XML-Dateien für einen Feed basierend auf dem Atom- oder RSS 2.0-Format zu erstellen, ist in wenigen Minuten selbst erledigt und benötigt keine zusätzlichen Plugins. Die beiden zur Verfügung stehenden Feeds von kivio.org sollen für diesen Beitrag als Beispiel dienen.&lt;/p&gt;
&lt;p&gt;Die Sourcen können direkt im Repository bei GitHub eingesehen werden:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/rollinhand/rollinhand.github.io/blob/master/blog/feed/atom.xml&quot;&gt;atom.xml&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/rollinhand/rollinhand.github.io/blob/master/blog/feed/rss.xml&quot;&gt;rss.xml&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Beide Format definieren einen festen Teil, der als Header bezeichnet werden könnte und einen variablen Teil, der ein Listing der Blog-Einträge darstellt. Ich möchte an dieser Stelle nicht so sehr auf das Format der beiden Feeds eingehen, sondern eher auf die Fallstricke, die sich bei der Erstellung ergeben haben.&lt;/p&gt;
&lt;p&gt;Während Atom sich sehr stark an dem XML-Standard orientiert und auch die Möglichkeit besteht, das Textformat des Feeds vorzugeben, gibt es bei RSS 2.0 zwei Fallstricke zu beachten:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Das &lt;strong&gt;Datumsformat&lt;/strong&gt; für pubDate entspricht nicht dem XML-Schema, sondern ist nach RFC 822 einzugeben. Nach strftime-Notation für Ruby bedeutet das &lt;code&gt;%a, %d %b %Y %H:%M:%S %z&lt;/code&gt;. Dadurch ergibt sich ein Datum nach dem Muster &lt;em&gt;Mit, 02 Okt 2002 08:00:00 +0200&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Die Angabe zum &lt;strong&gt;Autor&lt;/strong&gt; ist bei RSS 2.0 nicht in zwei getrennten XML-Elementen vorzunehmen, sondern im &lt;em&gt;author&lt;/em&gt;-Element ist zunächst die Email-Adresse und gefolgt in Klammern der Klarname anzugeben.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Damit auch RSS- und Atom-fähige Browser erkennen, dass die Webseite entsprechende Feeds anbieten, lassen sich diese über link-Referenzen im Header bekannt machen:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-html&quot;&gt;&amp;lt;html&amp;gt;
  &amp;lt;head&amp;gt;
    [...]
    &amp;lt;!-- Feeds --&amp;gt;
    &amp;lt;link rel=&amp;quot;alternate&amp;quot; type=&amp;quot;application/rss+xml&amp;quot; 
          title=RSS&amp;quot; href=&amp;quot;/blog/feed/rss.xml /&amp;gt;
    &amp;lt;link rel=&amp;quot;alternate&amp;quot; type=&amp;quot;application/atom+xml&amp;quot; 
          title=Atom&amp;quot; href=&amp;quot;/blog/feed/atom.xml /&amp;gt;
  &amp;lt;/head&amp;gt;
  &amp;lt;body&amp;gt;
    [...]
  &amp;lt;/body&amp;gt;	
&amp;lt;/html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Viel Spaß beim Nachbauen.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>Blog zu GitHub pages umgezogen</title>
      <link>https://kivio.org/blog/entry/2016/12/23/blog-umgezogen.html</link>
      <pubDate>Fri, 23 Dec 2016 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2016/12/23/blog-umgezogen.html</guid>
      	<description>
	&lt;p&gt;Meinen Blog &lt;a href=&quot;http://kivio.org&quot;&gt;Kivio&lt;/a&gt; habe ich zum Ende des Jahres zu &lt;a href=&quot;http://github.com&quot;&gt;GitHub pages&lt;/a&gt; umgezogen. Die Gründe finden sich in diesem Post.&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;Bisher wurde das Blog mit &lt;a href=&quot;http://roller.apache.org&quot;&gt;Apache Roller&lt;/a&gt; auf einem virtuellen Server bei 1&amp;amp;1 gehostet. Da es aber wenige dynamische Inhalte in dem Blog gibt und nur eine Instanz des Blogs gehostet wird, ist der Betrieb eines eigenen Webservers nicht nur unwirtschaftlich sondern überdimensioniert.&lt;/p&gt;
&lt;p&gt;GitHub bietet mit GitHub Pages eine einfache und komfortable Lösung, statische Seiten zu hosten. Angetrieben wird GitHub Pages von &lt;a href=&quot;http://jekyllrb.com&quot;&gt;Jekyll&lt;/a&gt; einem auf Ruby basierenden statischen Webseiten-Generator. Als Autor besteht die Möglichkeit seine Sourcen bei GitHub in einem Repository abzulegen oder aber nur die kompilierte statische Seite.&lt;/p&gt;
&lt;p&gt;Ich habe mich für die erste Variante entschieden, denn somit kann ich auch meine Sourcen versionieren und Jekyll übernimmt die Übersetzung der Seite auf Seiten von GitHub. Allerdings bringt diese Variante auch Einschränkungen mit sich=Es können nur durch GitHub ausgewählte Plugins mit Jekyll verwendet werden. Damit keine bösen Überraschungen beim Veröffentlichen auftreten und es zu Fehlern bei der Bereitstellung kommt, bietet es sich an, ein &lt;em&gt;Gemfile&lt;/em&gt; anzulegen und dort, das &lt;em&gt;github-pages&lt;/em&gt; gem einzubinden:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;source &amp;quot;https://rubygems.org&amp;quot;
gem &apos;github-pages&apos;, &apos;109&apos;, group=:jekyll_plugins
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Das Repository zu &lt;a href=&quot;https://github.com/github/pages-gem&quot;&gt;github-pages&lt;/a&gt; enthält eine ausführliche README und Verweise, welche Plugins unterstützt werden.&lt;/p&gt;
&lt;p&gt;Einen guten Einstieg zu GitHub pages bieten die beiden folgenden Quellen:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://help.github.com/articles/setting-up-your-github-pages-site-locally-with-jekyll/&quot;&gt;Setting up your GitHub Pages site locally with Jekyll&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://jmcglone.com/guides/github-pages/&quot;&gt;Creating and Hosting a Personal Site on GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Der Übertrag der alten Posts aus Apache Roller gestaltete sich allerdings nicht als sonderlich trivial. Apache Roller fristet inzwischen ein Nischendasein und findet kaum Berücksichtigung. Somit bietet auch Jekyll keine Möglichkeit automatisch Blog-Posts zu übernehmen. Für weiter verbreitete Blogging-Lösungen wie Wordpress, Joomla oder Typo bietet Jekyll Importer. Aber dazu in einem später folgenden Beitrag mehr Details.&lt;/p&gt;
&lt;p&gt;Die Übertragung der Posts unter kivio.org ist daher noch nicht vollständig und fehlende Posts werden in den kommenden Wochen noch ergänzt&amp;hellip;&lt;/p&gt;
&lt;p&gt;Viel Spaß beim Lesen.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>Fehlerbehebung im Glassfish-Server</title>
      <link>https://kivio.org/blog/entry/2016/03/31/fehlerbehebung-im-glassfish-server.html</link>
      <pubDate>Thu, 31 Mar 2016 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2016/03/31/fehlerbehebung-im-glassfish-server.html</guid>
      	<description>
	&lt;p&gt;Kryptische Fehlermeldungen bei der Entwicklung von Webanwendungen auf dem Glassfish-Server sind nicht immer einfach zu entschlüsseln und deren Ursache zu beheben. Dieser Artikel geht auf einige häufige Fehler, deren Ursachen und die Behebung ein.&lt;/p&gt;
&lt;!--more--&gt; 
&lt;p&gt;Werden Web-Anwendungen mit dem Glassfish-Server 3.2.X entwickelt, so lassen sich diese mit den entsprechenden Tools (z. B. Glassfish-Tools für Eclipse) relativ schnell und einfach immer wieder neu auf dem Entwicklungsserver publizieren.&lt;/p&gt;
&lt;p&gt;Allerdings machen Entwickler Fehler, die wiederum zu einem fehlerhaften Deployment führen können. Solche Fehler verzeiht der Glassfish-Server nicht immer und es kommt zu kryptischen Fehlermeldungen, deren Beseitigung einige Zeit in Anspruch nehmen kann - vorausgesetzt es ist nicht bekannt, an welchen Stellen zu suchen ist.&lt;/p&gt;
&lt;p&gt;In diesem Artikel stelle ich einige der kryptischen Meldungen und deren häufigste Ursache vor. Damit einhergehend wird auch die Lösung erläutert. Die Beispiele beziehen sich auf die Entwicklung mit Eclipse und den Glassfish-Tools.&lt;/p&gt;
&lt;h3&gt;Nachträgliches Ändern einer Managed Bean&lt;/h3&gt;
&lt;p&gt;Wird der Scope einer Managed Bean (@Named) nachträglich vom Request Scope zum Session Scope geändert, so muss das Interface &lt;em&gt;Serializable&lt;/em&gt; implementiert werden. Wird dies vergessen, so wird das Deployment der Managed Bean durch WELD verhindert und eine Fehlermeldung ausgegeben.&lt;/p&gt;
&lt;p&gt;Mit einer einfachen Korrektur und dem erneuten Deployment ist es anschließend nicht getan. Der Glassfish-Server verhindert das Deployment mit einer Exception:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;com.sun.enterprise.container.common.spi.util.InjectionException=Fehler beim Erstellen des verwalteten Objekts für Klasse=class org.jboss.weld.servlet.WeldListener&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Abhilfe kann hier geschaffen werden, indem der Glassfish-Server gestoppt und das Deployment-Verzeichnis bereinigt wird. Untrügliche Anzeichen für ein fehlgeschlagenes Deployment ist ein Verzeichnis beginnend mit dem Namen &lt;strong&gt;_xfer&lt;/strong&gt;.&lt;/p&gt;
&lt;h3&gt;Deployment einer Webanwendung (WAR) schlägt fehl&lt;/h3&gt;
&lt;p&gt;In diesem Szenario schlägt das Hot Deployment einer Webanwendung innerhalb von Eclipse mittels Publish (Strg+Alt+P) fehl. Das Glassfish-Logfile meldet, dass das Webarchiv (WAR) noch vorhanden ist.&lt;/p&gt;
&lt;p&gt;Betrachtet man das Applikationsverzeichnis auf dem lokalen Glassfish-Server unter &lt;code&gt;$DOMAINDIR/applications/$meine-app&lt;/code&gt; so befindet sich dort eine Datei mit der Bezeichnung &lt;strong&gt;.staleFiles&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;In dieser Datei sind Dateien und Verzeichnisse gelistet, die nicht automatisch vom Glassfish undeployt werden konnten. Bei einem Redeployment der Anwendung über die Glassfish-Tools wird in der Regel die Anwendung vollständig inkl. aller abhängigen Bibliotheken entfernt.&lt;/p&gt;
&lt;p&gt;Damit das Deployment wieder lauffähig ist, kann nur Abhilfe durch Stoppen des Glassfish-Servers und manuellem Löschen der Anwendung geschaffen werden.&lt;/p&gt;
&lt;p&gt;Damit das Deployment wiederholt erfolgreich funktioniert, ist zu prüfen, ob zusätzlich dem Projekt hinzugefügte Bibliotheken nicht entfernt werden konnten. Ist das WAR Teil einer Enterprise-Applikation (EAR), dann gehören die Bibliotheken in das lib-Verzeichnis des EAR und nicht in das WAR. Ansonsten kann der Glassfish-Server die abhängigen Bibliotheken nicht entfernen.&lt;/p&gt;
&lt;h3&gt;CommandException während des Deployments&lt;/h3&gt;
&lt;p&gt;Eine Fehlermeldung, die mir bisher nur in Verbindung mit Eclipse und den Glassfish-Tools untergekommen ist, ist die CommandException. Während des ersten oder eines erneuten Deployment erscheint die Meldung:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;org.glassfish.tools.ide.admin.CommandException=Can not read HTTP response, caught IOException Schwerwiegend=EJB-Modul kann nicht geladen werden. DeploymentContext enthält kein EJB.&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Meine Projekte baue ich meist mit Maven. Erscheint diese Meldung beim Deployment innerhalb der Eclipse nach einer Änderung an der pom.xml, so ist das Eclipse-Projekt nicht mehr korrekt synchronisiert. Abhilfe schafft hier in einem Großteil der Fälle die Option &lt;em&gt;Maven &amp;gt; Update Project&lt;/em&gt; (Alt + F5).&lt;/p&gt;
&lt;p&gt;Sie befindet sich im Kontextmenü des Projekts.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>Get rid of Maven directory in your WAR</title>
      <link>https://kivio.org/blog/entry/2016/03/17/get-rid-of-maven-directory.html</link>
      <pubDate>Thu, 17 Mar 2016 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2016/03/17/get-rid-of-maven-directory.html</guid>
      	<description>
	&lt;p&gt;While you are packaging your web application with Maven you might have encountered, that your pom.xml and other Maven related files are also packed into your archive. To get rid of this directory adopt your pom.xml and configure the maven-war-plugin:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;plugin&amp;gt;
  &amp;lt;groupId&amp;lt;org.apache.maven.plugins&amp;lt;/groupId&amp;gt;
  &amp;lt;artifactId&amp;lt;maven-war-plugin&amp;lt;/artifactId&amp;gt;
  &amp;lt;version&amp;lt;2.2&amp;lt;/version&amp;gt;
  &amp;lt;configuration&amp;gt;
    &amp;lt;archive&amp;gt;
      &amp;lt;addMavenDescriptor&amp;gt;false&amp;lt;/addMavenDescriptor&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With adding &lt;code&gt;addMavenDescriptor=false&lt;/code&gt; WAR packaging will dismiss the the pom.xml in your archive.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>Inhalte aus Evernote nach OneNote umziehen</title>
      <link>https://kivio.org/blog/entry/2016/03/17/inhalte-aus-evernote-nach-onenote.html</link>
      <pubDate>Thu, 17 Mar 2016 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2016/03/17/inhalte-aus-evernote-nach-onenote.html</guid>
      	<description>
	&lt;p&gt;Kein direktes Thema für DevOps, aber interessant für alle, die einen einfachen Weg suchen, ihre Notizen von Evernote nach OneNote umzuziehen.&lt;/p&gt;
&lt;!--more--&gt;
Microsoft hat ein [Werkzeug zur Verfügung gestellt ](https://www.onenote.com/import-evernote-to-onenote) 
mit dem der Umzug von Inhalten von Evernote nach Microsoft OneNote spielend einfach vonstatten geht. 
Für die Migration der Inhalte ist ein Microsoft-Konto (Live, Hotmail oder Outlook.com) notwendig. 
Der Evernote Windows-Client muss nicht zwingend installiert sein, beschleunigt das Kopieren der Inhalte 
allerdings um ein Vielfaches.
&lt;p&gt;Zu beachten ist, dass das Tool derzeit nur für Windows ab Windows 7 verfügbar ist. An einer Version für Apples OS X wird laut Aussage von Microsoft gearbeitet, ein genaues Veröffentlichungsdatum ist derzeit nicht bekannt.&lt;/p&gt;
&lt;p&gt;Im &lt;a href=&quot;https://www.onenote.com/import-evernote-to-onenote&quot;&gt;Gegensatz zu Evernote&lt;/a&gt; bietet OneNote in der kostenlosen Variante mehr Speicherplatz an, bietet innerhalb der Smartphone- und Tablet-Apps automatische Handschriftenerkennung und hat auch ohne Premium-Account die Möglichkeit Inhalte offline zur Verfügung zu stellen. Apps sind sowohl für Windows 10, Windows 10 Mobile, Android, iOS und OS X von Apple vorhanden.&lt;/p&gt;
&lt;h3&gt;Was passiert bei der Übertragung?&lt;/h3&gt;
&lt;p&gt;Notizbücher in Evernote werden ebenfalls zu Notizbüchern in OneNote, einzelne Notizen werden zu Seiten in einem Notizbuch.&lt;/p&gt;
&lt;p&gt;Wer bei der Migration auch die Berücksichtigung von Tags in Evernote anhakt, bekommt innerhalb des Notizbuches auch die sogenannten Abschnitte eingerichtet. Hierbei berücksichtigt das Tool das erste Tag das bei einer Notiz hinterlegt ist und erstellt daraus einen Abschnitt. Notizen (Seiten) ohne ein Tag landen unter dem Abschnitt Pages.&lt;/p&gt;
&lt;p&gt;Werden innerhalb eines Notizbuches viele unterschiedliche Tags verwendet, so kann dies nach der Migration nach OneNote zu einem unübersichtlichen Chaos führen. Der Haken sollte also mit Bedacht gesetzt werden.&lt;/p&gt;
&lt;p&gt;Die Übertragung der Daten kann je nach Geschwindigkeit der Internetverbindung und der Größe der Notizbücher einige Zeit in Anspruch nehmen.&lt;/p&gt;
&lt;p&gt;Nach Abschluss der Migration können die Notizbücher automatisch in den jeweiligen Desktop- oder Mobilanwendungen synchronisiert werden. Praktisch hierbei ist, dass in den Mobilanwendungen der Anwender die Möglichkeit bekommt, die zu synchronisierenden Notizbücher auszuwählen. Einzelne Seiten werden einmalig erst geladen, wenn sie aufgerufen worden sind. Anschließend stehen sie offline zur Verfügung.&lt;/p&gt;
&lt;h3&gt;Weitere Onlinequellen:&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;http://www.zdnet.de/88263141/microsoft-macht-evernote-importwerkzeug-verfuegbar/&quot;&gt;ZDNet&lt;/a&gt;&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>Nicht unterbuttern lassen...</title>
      <link>https://kivio.org/blog/entry/2016/03/08/nicht-unterbuttern-lassen.html</link>
      <pubDate>Tue, 8 Mar 2016 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2016/03/08/nicht-unterbuttern-lassen.html</guid>
      	<description>
	&lt;p&gt;Das JSF-Framework ButterFaces ist neu am Markt und will einiges anders machen als die bereits etablierten.&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;Eigentlich gibt es schon genügend JSF-Frameworks auf dem Markt. Neben den populären und etablierten wie PrimeFaces und OmiFaces haben sich einige kleinere Frameworks (BootsFaces, ICEFaces) etabliert. Bedarf es da noch eines weiteren Frameworks?&lt;/p&gt;
&lt;p&gt;ButterFaces setzt auf Bootstrap und jQuery auf, um Responsive Web-Design zu unterstützen. Im Gegensatz zu anderen Frameworks stellt ButterFaces keinen Wrapper für jede Bootstrap-Komponente zur Verfügung. Lediglich bei Komponenten, wo ein JSF-Wrapper sinnvoll ist (Visualisierung und Eingabe von Daten), werden entsprechende JSF-Komponenten zur Verfügung gestellt.&lt;/p&gt;
&lt;p&gt;Alle anderen Bootstrap-Komponenten wie Jumbotron, Navbar, Flex-Grid und Glyphicons können direkt verwendet werden. Nicht nur der JSF-Komponentenbaum wird dadurch weniger aufgebläht, sondern auch die in das Projekt einzubindende Bibliothek bleiben klein und schlank. Gerade wenn es um die Laufzeit von Anwendungen geht, ein nicht zu unterschätzender Vorteil.&lt;/p&gt;
&lt;p&gt;Neben einer guten Dokumentation befindet sich auf der Webseite der beiden Entwickler Lars Michaelis und Stephan Zerhusen ein Showcase, der die Funktionalitäten der einzelnen JSF-Komponenten und den Einfluss der zu konfigurierenden Attribute eindrücklich demonstriert.&lt;/p&gt;
&lt;p&gt;Andere Frameworks wie ICEFaces oder PrimeFaces bringen noch Komponenten mit, um Charts rendern zu lassen. Auch auf diese Komponenten verzichtet ButterFaces und konzentriert sich nur auf das Wichtigste. Wer dennoch Charts in seiner Anwendung benötigt, kann ButterFaces mit HighFaces oder HighCharts kombinieren.&lt;/p&gt;
&lt;h3&gt;Fazit&lt;/h3&gt;
&lt;p&gt;Das Framework macht auch in der sehr frühen Version schon einen robusten Eindruck. Aufgrund des hervorragenden Showcase ist der Einstieg leicht gemacht. In der Dokumentation finden sich ebenfalls Exkurse wie ButterFaces mit Komponenten aus BootsFaces oder PrimeFaces genutzt werden können - für all diejenigen, denen der Standard nicht genügt.&lt;/p&gt;
&lt;p&gt;Es bleibt spannend in welche Richtung sich dieses Framework noch entwickeln wird&amp;hellip;&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>GitHub plugin 1.0 for Apache Roller 5 released</title>
      <link>https://kivio.org/blog/entry/2016/02/08/github-plugin-1-0-released.html</link>
      <pubDate>Mon, 8 Feb 2016 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2016/02/08/github-plugin-1-0-released.html</guid>
      	<description>
	&lt;p&gt;The first official version of the GitHub plugin for &lt;a href=&quot;http://roller.apache.org/&quot;&gt;Apache Roller 5&lt;/a&gt; was released today. This short announcement describes the implemented functionality.&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;This is the first official version of the GitHub plugin for &lt;a href=&quot;http://roller.apache.org/&quot;&gt;Apache Roller 5&lt;/a&gt; which can be used to integrate listings of your repositories and profile in your personal weblog.&lt;/p&gt;
&lt;p&gt;Listing of your current activities should be used with some caution. The used implementation is not yet ready for production environments.&lt;/p&gt;
&lt;p&gt;If you want to see the plugin in action, visit &lt;a href=&quot;http://www.kivio.org&quot;&gt;www.kivio.org&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;See the &lt;a href=&quot;https://github.com/rollinhand/roller-github-plugin/blob/master/README.md&quot;&gt;README at GitHub&lt;/a&gt; for more details how to get and use the plugin. A binary version will be made available soon.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>Glassfish-Server hinter einem Proxy betreiben</title>
      <link>https://kivio.org/blog/entry/2016/01/15/glassfish-server-hinter-einem-proxy.html</link>
      <pubDate>Fri, 15 Jan 2016 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2016/01/15/glassfish-server-hinter-einem-proxy.html</guid>
      	<description>
	&lt;p&gt;Wie nutzt man den NGINX effizient als Proxy für einen Glassfish und wie bekommt man den Port 8080 dauerhaft aus Links seiner Web-Anwendung entfernt? Die Antworten liefert dieser Beitrag.&lt;/p&gt;
&lt;!--more--&gt;
Der NGINX Webserver ist ein kleiner, schlanker Webserver, der sich hervorragend als Proxy-Server 
für einen schwergewichtigen Applikationsserver wie den Glassfish nutzen lässt. Einen 
Proxy-Server vor einen Applikationsserver soll zum einen dafür sorgen, den Applikationsserver 
abzusichern aber auch statische Inhalte schneller auszuliefern.
&lt;p&gt;Mit einem Proxy-Server ist es somit möglich alle Anfragen über den Port 80 an den Applikationsserver weiterzuleiten und auch ein URL-Rewriting vorzunehmen. Beides war notwendig als ich Apache Roller für meine neue Domain &lt;a href=&quot;http://www.kivio.org&quot;&gt;www.kivio.org&lt;/a&gt; einsetzen wollte. Und das waren die Bedingungen, die NGINX als Proxy erfüllen sollte:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Alle Aufrufe sollten über den Port 80 laufen, sodass der Well-known Port 8080 durch die Firewall geschützt werden kann und die Requests intern auf dem Server weitergereicht werden.&lt;/li&gt;
&lt;li&gt;Apache Roller erstellt Blog-URLs nach dem Schema &lt;a href=&quot;http://domain/roller/&quot;&gt;http://domain/roller/&lt;/a&gt;&lt;em&gt;blog-name.&lt;/em&gt; Natürlich sollten die Inhalte der Frontpage bzw. des primären Blog natürlich über &lt;a href=&quot;http://www.kivio.org&quot;&gt;www.kivio.org&lt;/a&gt; erreichbar sein.&lt;/li&gt;
&lt;li&gt;Die Anfragen an die alte Domain &lt;a href=&quot;http://www.berg-systeme.de&quot;&gt;www.berg-systeme.de&lt;/a&gt; sollten auf eine vordefinierte, statische Landing-Page geroutet werden.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Mit diesen Bedingungen im Hinterkopf, war die Erstkonfiguration schnell erledigt.&lt;/p&gt;
&lt;p&gt;In der Konfigurationsdatei /etc/nginx/sites-available/default habe ich folgende Anpassungen vorgenommen:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;server {
   listen 80 default_server;
   listen [::]:80 default_server ipv6only=on;

   index index.html index.htm;

   # Make site accessible from http://localhost/
   server_name www.kivio.org www.kivio.biz www.kivio.eu;

   location / {
        proxy_pass http://www.kivio.org:8080/;
   }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Nach einem Neustart des NGINX bzw. einem Neueinlesen der Konfiguration mittels /etc/init.d/nginx reload werden alle Anfragen auf die Startseite des Glassfish-Servers weitergeleitet. Mit Aufruf der URL &lt;a href=&quot;http://www.kivio.org/roller/blog&quot;&gt;www.kivio.org/roller/blog&lt;/a&gt; passierte es allerdings, dass alle erzeugten Links und verlinkten Ressourcen in der Anwendung immer noch den Port 8080 beinhaltet haben. Sobald der Port gesperrt werden würde, wäre es natürlich nicht möglich die Ressourcen wie CSS oder JavaScript zu laden, geschweige denn die verlinkten Seiten zu besuchen.&lt;/p&gt;
&lt;h3&gt;Was also tun?&lt;/h3&gt;
&lt;p&gt;Der Virtaul Server des Glassfish schafft hier Abhilfe. Er muss eh noch konfiguriert werden, sodass Apache Roller immer als Standardanwendung geladen wird, wenn ein Besucher die URL einfach aufruft.&lt;/p&gt;
&lt;p&gt;Über die Admin Konsole kann unter &lt;strong&gt;Configurations &amp;gt; server-config &amp;gt; Virtual Servers&lt;/strong&gt; die Konfiguration geändert werden. Unter server sind die Konfigurationen für HTTP-Requests (http-listener-1) und HTTPS-Requests (http-listener-2) zusammengefasst.&lt;/p&gt;
&lt;p&gt;Über &lt;strong&gt;Default Web Module&lt;/strong&gt; kann festgelegt werden, welche bereitgestellte Anwendung standardmäßig genutzt werden soll.&lt;/p&gt;
&lt;p&gt;Da über den http-listener-1 die einfachen HTTP-Anfragen einlaufen, muss dieser nun auch noch konfiguriert werden. Über HTTP-Service &amp;gt; Http Listeners &amp;gt; http-listener-1 kann ein Alias-Name für den Rücktransfer der Daten an den Client festgelegt werden.&lt;/p&gt;
&lt;p&gt;Unter &lt;strong&gt;Server Name&lt;/strong&gt; wird einfach &lt;a href=&quot;http://www.kivio.org:80&quot;&gt;www.kivio.org:80&lt;/a&gt; eingetragen und der Glassfish neu gestartet.&lt;/p&gt;
&lt;p&gt;Nach dem Neustart ist der Port aus allen URL-Angaben verschwunden.&lt;/p&gt;
&lt;p&gt;Fehlt also nur noch die Erfüllung der Anforderung für die statische Weiterleitung von &lt;a href=&quot;http://www.berg-systeme.de&quot;&gt;www.berg-systeme.de&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Statische Weiterleitung&lt;/h3&gt;
&lt;p&gt;Die statische Weiterleitung auf die Landing page ist nach den vorherigen Anpassungen kein Problem mehr. Damit der NGINX auf die Domäne &lt;a href=&quot;http://www.berg-systeme.de&quot;&gt;www.berg-systeme.de&lt;/a&gt; reagiert wird eine eigene Server-Passage in die Konfigurationsdatei eingefügt:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;server {
   listen 80;
   server_name www.berg-systeme.de;

   location / {
      proxy_pass http://localhost:8080/roller/kivio/page/de/bergsysteme;
      break;
   }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Damit findet eine transparente Weiterleitung statt.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>Wix Toolset plugin 1.12 for Jenkins released</title>
      <link>https://kivio.org/blog/entry/2015/07/18/wix-toolset-plugin-1-12.html</link>
      <pubDate>Sat, 18 Jul 2015 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2015/07/18/wix-toolset-plugin-1-12.html</guid>
      	<description>
	&lt;p&gt;A new version of Wix Toolset plugin was released on July 18th. The new version is automatically available via Jenkins update manager. This announcement describes the latest changes.&lt;/p&gt;
&lt;!--more--&gt;
Release 1.12 is a minor bugfix release with fixes to the internal logging routines and the 
handling of directory paths:
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;github #6:&lt;/strong&gt; A percent in a path or environment variable could cause the plugin to crash if the values where printed with the internal ToolsetLogger. The internal printf was changed to println.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;github #6:&lt;/strong&gt; The bugfix for handling of directory paths introduced with 1.11 was changed again. If a directory path ends with a backslash, the last backslash in directory path is removed. Otherwise a quotation mark could get casted by the backslash if directory path contains whitespaces and that would fail the Jenkins Process Builder.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;p&gt;A complete list of all changes is available at &lt;a href=&quot;https://github.com/jenkinsci/wix-plugin/blob/master/CHANGELOG.md&quot;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>Wix Toolset plugin 1.11 for Jenkins released</title>
      <link>https://kivio.org/blog/entry/2015/07/07/wix-toolset-plugin-1-11.html</link>
      <pubDate>Tue, 7 Jul 2015 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2015/07/07/wix-toolset-plugin-1-11.html</guid>
      	<description>
	&lt;p&gt;A new version of Wix Toolset plugin was released on July 8th. The new version is automatically available via Jenkins update manager. This announcement describes the latest changes.&lt;/p&gt;
&lt;!--more--&gt;
Release 1.11 is a major bugfix release due to problems with running Wix Toolset on a Windows slave:
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;github #5:&lt;/strong&gt; The commands calling candle.exe and light.exe are now using supporting Jenkins remote path and the native Jenkins Launcher for remote processes. A lot of thanks go to @pulphix who tested and tested and tested&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;p&gt;A complete list of all changes is available at &lt;a href=&quot;https://github.com/jenkinsci/wix-plugin/blob/master/CHANGELOG.md&quot;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>Wix Toolset plugin 1.10 for Jenkins released</title>
      <link>https://kivio.org/blog/entry/2015/07/01/wix-toolset-plugin-1-10.html</link>
      <pubDate>Wed, 1 Jul 2015 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2015/07/01/wix-toolset-plugin-1-10.html</guid>
      	<description>
	&lt;p&gt;A new version of Wix Toolset plugin was released on June 1st. The new version is automatically available via Jenkins update manager. This announcement describes the latest changes.&lt;/p&gt;
&lt;!--more--&gt;
&lt;h3&gt;Changes&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Minimum required version of Jenkins is now 1.579&lt;/li&gt;
&lt;li&gt;Installation path can be left empty. Wix Toolset plugin is then expecting that the Wix Tools are added to the system environment variable &lt;em&gt;PATH&lt;/em&gt; on Windows master or slave.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;github #4:&lt;/strong&gt; Environment variables containing pathes are no longer rejected by default.&lt;/li&gt;
&lt;li&gt;Some refactoring and code cleanup&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Bugfixes&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Environment variables which contain a path which ends on a backslash are now escaped. This will avoid errors like &lt;em&gt;CNDL0103 =The system cannot find the file &amp;lsquo;XXX&amp;rsquo; with type &amp;lsquo;Source&amp;rsquo;&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;github #5:&lt;/strong&gt; The commands calling candle.exe and light.exe are now using relative paths instead of absolute paths. That should avoid a leading slash before the command if Jenkins master is running on Linux.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;p&gt;A complete list of all changes is available at &lt;a href=&quot;https://github.com/jenkinsci/wix-plugin/blob/master/CHANGELOG.md&quot;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>Wix Toolset plugin 1.9 for Jenkins released</title>
      <link>https://kivio.org/blog/entry/2014/12/29/wix-toolset-plugin-1-9.html</link>
      <pubDate>Mon, 29 Dec 2014 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2014/12/29/wix-toolset-plugin-1-9.html</guid>
      	<description>
	&lt;p&gt;A new version of Wix Toolset plugin was released on December 19th. The new version is automatically available via Jenkins update manager. This announcement describes the latest changes.&lt;/p&gt;
&lt;!--more--&gt;
&lt;h3&gt;Changes&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Automatic addition of environment variables as parameters to candle and light is now globally configurable.&lt;/li&gt;
&lt;li&gt;Administrators can decide which environment variables should not be taken into account as parameter.&lt;/li&gt;
&lt;li&gt;Every log file from WiX Toolset plugin is now prefixed with &lt;em&gt;wix&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Bugfixes&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;An empty filename for the MSI output is expanded to &lt;em&gt;setup.msi&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Changed global settings are immediately active.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;p&gt;A complete list of all changes is available at &lt;a href=&quot;https://github.com/jenkinsci/wix-plugin/blob/master/CHANGELOG.md&quot;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>Virtuelle Maschinen in VirtualBox umziehen</title>
      <link>https://kivio.org/blog/entry/2014/11/12/virtuelle-maschinen-in-virtualbox.html</link>
      <pubDate>Wed, 12 Nov 2014 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2014/11/12/virtuelle-maschinen-in-virtualbox.html</guid>
      	<description>
	&lt;p&gt;Virtuelle Maschinen in VirtuialBox auf einen externen Datenträger zu verlagern ist einfach. Dieses Post zeigt, welche Schritte zu beachten sind, um die Maschinen auf unterschiedlichen Systemen verwenden zu können.&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;Sollen Virtual Machine Images in VirtualBox auf unterschiedlichen Hostsystemen genutzt werden, so bietet es sich an, die eigentlichen Images auf eine externe Festplatte auszulagern. Das dargestellte Szenario und die damit einhergehenden Schritte können auch angwendet werden, wenn einfach Festplattenspeicher freigegeben werden soll bzw. die Maschinen ausgelagert werden sollen.&lt;/p&gt;
&lt;p&gt;Virtualbox speichert den Lagerort der Virtual Machine Images in einer Konfigurationsdatei, die im Verzeichnis des jeweiligen Benutzers liegt:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Windows:&lt;/strong&gt; %USERPROFILE%.VirtualBox\VirtualBox.xml&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Linux:&lt;/strong&gt; ~/.VirtualBox/VirtualBox.xml&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mac:&lt;/strong&gt; ~/Library/VirtualBox/VirtualBox.xml&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Damit die Konfigurationsdatei geändert werden kann, sollte VirtualBox nicht laufen und alle virtuellen Maschinen gestoppt sein. Danach sind die folgenden Schritte auszuführen, die im Einzelnen genauer erläutert werden:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Alle Virtual Machine Images an den neuen Zielort verschieben.&lt;/li&gt;
&lt;li&gt;Standardspeicherort für die Images auf den neuen Zielort ändern.&lt;/li&gt;
&lt;li&gt;Vorhandene Speicherorte in der Konfigurationsdatei anpassen.&lt;/li&gt;
&lt;li&gt;Überprüfen der Änderung.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Die durchzuführenden Änderungen können an einem praktischen Beispiel nachvollzogen werden.&lt;/p&gt;
&lt;h3&gt;Virtual Machine Images verschieben&lt;/h3&gt;
&lt;p&gt;Wurden die Standardeinstellungen von VirtualBox nicht geändert, so landen alle neuen virtuellen Maschinen automatisch in einem vorausgewählten Verzeichnis. In diesem Verzeichnis wiederum befindet sich für jede virtuelle Maschine ein eigener Ordner:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Windows:&lt;/strong&gt; %USERPROFILE%\VirtualBox VMs&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mac/Linux:&lt;/strong&gt; ~/VirtualBox VMs&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Das Beispiel bezieht sich auf Windows. Die untergeordneten Verzeichnisse unter VirtualBox VMs werden in diesem Beispiel an den neuen Speicherort D:\Virtualbox verschoben. Unter Mac/Linux könnte das neue Verzeichnis unter einem beliebigen Mountpunkt liegen.&lt;/p&gt;
&lt;h3&gt;Konfigurationsdatei editieren&lt;/h3&gt;
&lt;p&gt;Während das Betriebssystem die Ordner und die Images an den neuen Zielort verschiebt, kann die Konfigurationsdatei mit einem Texteditor bearbeitet werden. Die XML-Datei ist klar strukturiert aufgebaut. So befinden sich die Standardeinstellung für den Speicherort unter dem Tag SystemProperties. Hier muss das Attribut defaultMachineFolder angepasst werden. Das sollte dann in etwa so aussehen:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;SystemProperties defaultMachineFolder=&amp;quot;D:\Virtualbox&amp;quot; defaultHardDiskFormat=&amp;quot;VDI&amp;quot; .../&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Für jede virtuelle Maschine gibt es in der MachineRegistry einen eigenen Eintrag mit Verweis auf den entsprechenden Ordner. Hier müssen die Pfade auch noch an den neuen Zielort angepasst werden. Das kann dann wie folgt aussehen:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;MachineRegistry&amp;gt;
&amp;lt;MachineEntry uuid=&amp;quot;{947fa526-2336-4f29-be56-492873cecd8d}&amp;quot; src=&amp;quot;D:\Virtualbox\Service Delivery Platform\Service Delivery Platform.vbox&amp;quot;/&amp;gt;
&amp;lt;MachineEntry uuid=&amp;quot;{c722b767-60d1-4a5c-91e2-8cd0a02b29c2}&amp;quot; src=&amp;quot;D:\Virtualbox\Weblogic 12.1.1\Weblogic 12.1.1 (Original Oracle-Image).vbox&amp;quot;/&amp;gt;
...
&amp;lt;/MachineRegistry&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Nachdem die Konfigurationsdatei gespeichert worden ist, kann mit den Tests weitergemacht werden.&lt;/p&gt;
&lt;h3&gt;Testen der Modifikationen&lt;/h3&gt;
&lt;p&gt;Der einfachste Test - nachdem die Ordner verschoben worden sind - ist, die Oberfläche von Virtualbox aufzurufen und eine virtuelle Maschine zu starten. Funktioniert dies nicht mehr, ist der Kopiervorgang fehlgeschlagen oder es liegt ein Konfigurationsfehler vor.&lt;/p&gt;
&lt;p&gt;Sind die Daten zunächst nur kopiert worden, so sollte der Originalordner umbenannt werden und dann mit (1) fortgefahren werden.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>Wenn der JDeveloper 12c richtig klemmt...</title>
      <link>https://kivio.org/blog/entry/2014/10/08/jdeveloper-12c-klemmt.html</link>
      <pubDate>Wed, 8 Oct 2014 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2014/10/08/jdeveloper-12c-klemmt.html</guid>
      	<description>
	&lt;p&gt;Oracles JDeveloper ist kein Performance-Wunder. Neben Performanceengpässen hilft manchmal nur das &amp;ldquo;Abschießen&amp;rdquo; aller zum JDeveloper gehörigen Prozesse, um weiterarbeiten zu können. Abhilfe ist da&amp;hellip;&lt;/p&gt;
&lt;!--more--&gt;
&lt;h3&gt;Beim Debugging einer ADF-Anwendung&lt;/h3&gt;
&lt;p&gt;Beim Starten des Debuggers in einer ADF-Anwendung startet der Debugger und ggf. wird noch die Einstiegsseite für das Debugging geladen. Danach ist allerdings Feierabend. Der JDeveloper reagiert auf keine Eingaben mehr und im Task-Manager bzw. der Aktivitätsanzeige ist zu sehen, wie die Speicherauslastung kontinuierlich ansteigt.&lt;/p&gt;
&lt;p&gt;Dieses Verhalten ist sowohl unter Windows als auch OS X zu beobachten.&lt;/p&gt;
&lt;p&gt;Grund für diesen &amp;ldquo;Freeze&amp;rdquo; ist das Fenster &lt;strong&gt;ADF Structure&lt;/strong&gt;, das in der Debug-Ansicht mit geöffnet wird. Es bietet sich an, während des Startens diesen View zu schließen und sobald die Debug-Session vollständig geöffnet ist, kann der View wieder über das Menü &lt;strong&gt;Window &amp;gt; Debugger &amp;gt; ADF Structure&lt;/strong&gt; geöffnet werden.&lt;/p&gt;
&lt;h3&gt;Auf einem MacBook Retina&lt;/h3&gt;
&lt;p&gt;Will man eine JSF-Seite im im grafischen Editor im JDeveloper bearbeiten, so erscheint unter OS X auf einem MacBook Pro mit Retina-Display dauerhaft die Meldung &lt;code&gt;Waiting for Designer to initialize...&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Auch mit viel Geduld hat ein Entwickler keine Chance. Der Designer erscheint nicht.&lt;/p&gt;
&lt;p&gt;Zugegeben, die Lösung zeigt, dass das Problem nicht der JDeveloper ist, sondern neuere Java Versionen unter OS X, die die Retina-Displays unterstützen. Erstmalig bietet Java SE 7 u40 Retina-Unterstützung. Alle Versionen größer bzw. gleich u40 sorgen für den nicht startenden Designer im JDeveloper.&lt;/p&gt;
&lt;p&gt;Die letzte funktionsfähige Version ist das Release u25. Die Version sollte auf den Download-Seiten von Oracle heruntergeladen und installiert werden.&lt;/p&gt;
&lt;p&gt;Nach der Installation muss die &lt;strong&gt;jdev.conf&lt;/strong&gt; im Verzeichnis &lt;strong&gt;JDEV_HOME/jdeveloper/jdev/bin/&lt;/strong&gt; angepasst werden.&lt;/p&gt;
&lt;p&gt;Die Einstellung &lt;strong&gt;SetJavaHome&lt;/strong&gt; sollte auf das neu installierte JDK 7 u25 verweisen:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;SetJavaHome /Library/Java/JavaVirtualMachines/jdk1.7.0_21.jdk/Contents/Home
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Danach funktioniert der JDeveloper wieder wie gewohnt. Allerdings müssen Abstriche bei der Ansicht gemacht werden. Auf einem hochauflösenden Display sieht die Anwendung ziemlich verwaschen aus.&lt;/p&gt;
&lt;p&gt;Der Bug im JDK scheint auch in neueren Versionen nicht gelöst zu sein. Auch mit dem u65 startet der Designer nicht. Das JDK 8 ist auch keine Lösung, denn damit startet der JDeveloper überhaupt nicht.&lt;/p&gt;
&lt;p&gt;Das von Apple weiterhin unterstützte JDK 6 hat die Retina-Optimierung fehlerfrei implementiert, kann aber nicht mit dem JDeveloper 12c verwendet werden.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>Wix Toolset plugin 1.8 for Jenkins released</title>
      <link>https://kivio.org/blog/entry/2014/09/29/wix-toolset-plugin-1-8.html</link>
      <pubDate>Mon, 29 Sep 2014 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2014/09/29/wix-toolset-plugin-1-8.html</guid>
      	<description>
	&lt;p&gt;A new version of Wix Toolset plugin was released today. The new version will be automatically available via Jenkins update manager in a few hours. This announcement describes the latest changes.&lt;/p&gt;
&lt;!--more--&gt;
&lt;h3&gt;Changes between Wix Toolset plugin 1.7 and 1.8&lt;/h3&gt;
&lt;h4&gt;Minor changes&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Added french translation. Thanks to &lt;em&gt;mildis&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Added new help file for MSI Output.&lt;/li&gt;
&lt;li&gt;MSI Output can be also an executable (*.exe) if used together with bootstrapper.&lt;/li&gt;
&lt;li&gt;Some minor refactoring.&lt;/li&gt;
&lt;/ol&gt;
&lt;hr /&gt;
&lt;p&gt;A complete list of all changes is available at &lt;a href=&quot;https://github.com/jenkinsci/wix-plugin/blob/master/CHANGELOG.md&quot;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>Wix Toolset plugin 1.7 for Jenkins released</title>
      <link>https://kivio.org/blog/entry/2014/08/06/wix-toolset-plugin-1-7.html</link>
      <pubDate>Wed, 6 Aug 2014 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2014/08/06/wix-toolset-plugin-1-7.html</guid>
      	<description>
	&lt;p&gt;A new version of Wix Toolset plugin was released today. The new version will be automatically available via Jenkins update manager in a few hours. This announcement describes the latest changes.&lt;/p&gt;
&lt;!--more--&gt;
&lt;h3&gt;Changes between Wix Toolset plugin 1.5 and 1.7&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Versions prior to 1.7 had problems with whitespaces in the installation directory of WiX Toolset. The Builder for executing the command is changed to wrap the commands candle.exe and light.exe with double quotes.&lt;/li&gt;
&lt;li&gt;Version 1.5 contained a critical error which made it impossible to build any setup with WiX Toolset. This error was produced while resolving a translated message.&lt;/li&gt;
&lt;/ol&gt;
&lt;hr /&gt;
&lt;p&gt;A complete list of all changes is available at &lt;a href=&quot;https://github.com/jenkinsci/wix-plugin/blob/master/CHANGELOG.md&quot;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>Tipps für den Einsatz des JDeveloper 12c</title>
      <link>https://kivio.org/blog/entry/2014/07/08/tipps-jdeveloper-12c.html</link>
      <pubDate>Tue, 8 Jul 2014 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2014/07/08/tipps-jdeveloper-12c.html</guid>
      	<description>
	&lt;p&gt;Die Maven-Unterstützung im JDeveloper 12.1.2 ist wenig gelungen. Wer auf die Version festgelegt ist, findet in diesem Post Wege, um die Maven-Unterstützung trotzdem in vollem Umfang nutzen zu können.&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;Mit dem JDeveloper 12c hat Oracle die lang ersehnte Maven-Unterstützung integriert. In der Version 12.1.2 ist die Unterstützung allerdings fehleranfällig und es bedarf einiger manueller Eingriffe, um Maven plattformübergreifend und auf verschiedenen Entwicklungssystemen nutzen zu können. In diesem kleinen Beitrag werden die notwendigen Maßnahmen aufgezeigt, die für einen erfolgreichen und problemlosen Einsatz notwendig sind.&lt;/p&gt;
&lt;h2&gt;Oracle Synchronisation durchführen&lt;/h2&gt;
&lt;p&gt;Damit Maven als Build-Tool genutzt werden kann, müssen die Build-Werkzeuge &lt;code&gt;ojmake&lt;/code&gt; und &lt;code&gt;ojdeploy&lt;/code&gt;, sowie die für eine ADF-Anwendung notwendigen Bibliotheken im lokalen Maven-Repository oder einem Repository-Proxy (wie Archiva, Artifactory oder Nexus) bekannt gemacht werden.&lt;/p&gt;
&lt;p&gt;In [1] beschreibt Oracle sehr ausführlich, wie die Synchronisation der Tools und Plugins mit einem Maven-Repository durchgeführt werden kann. Allerdings ist die Anleitung für die Version 12.1.2 des JDevloper fehlerhaft. Die korrekten Befehle sind im folgenden dargestellt:&lt;/p&gt;
&lt;p&gt;JDeveloper ist unter Windows in den Standard-Pfad installiert worden. Das Synchronisations-Plugin befindet sich im Pfad &lt;em&gt;oracle_common\plugins\maven\com\oracle\maven\oracle-maven-sync\12.1.2&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mvn install:install-file -DpomFile=oracle-maven-sync.12.1.2.pom -Dfile=oracle-maven-sync.12.1.2.jar
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Mit diesem Befehl wird das Maven Synchronisationsplugin von Oracle in das lokale Repository geladen und kann mit dem Befehl ausgeführt werden:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mvn com.oracle.maven:oracle-maven-sync:push -Doracle-maven-sync.oracleHome=C:\Oracle\Middleware\Oracle_Home
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Hierbei ist darauf zu achten, dass die Umgebungsvariable entgegen der Anleitung &lt;strong&gt;oracle-maven-sync.oracleHome&lt;/strong&gt; lauten muss. Mit dem JDeveloper in der im Juni 2014 erschienen Version 12.1.3 ist dieser Fehler behoben. Eine Anleitung zur korrekten Synchronisation der Tools befindet sich unter [2]. Edwin Biemond beschreibt in seinem Blog auch die Synchronisation der Plugins mit dem Artefakt Repository Nexus.&lt;/p&gt;
&lt;h2&gt;Relative Pfade einführen&lt;/h2&gt;
&lt;p&gt;In der Version 12.1.2 werden in den POM für Maven grundsätzlich absolute Pfade genutzt. Für unterschiedlich installierte Entwicklermaschinen oder eine plattformübergreifende Entwicklung ist dieser Ansatz nicht zielführend. Aus diesem Grund müssen bestimmte Pfade in den POM-Dateien relativiert werden. [3] beschreibt diese Problematik ausführlich. Eine erzeugte POM sieht beispielsweise wie folgt aus:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;plugin&amp;gt;
  &amp;lt;groupId&amp;gt;com.oracle.adf.plugin&amp;lt;/groupId&amp;gt;
  &amp;lt;artifactId&amp;gt;ojmake&amp;lt;/artifactId&amp;gt;
  &amp;lt;version&amp;gt;12.1.2-0-0&amp;lt;/version&amp;gt;
  &amp;lt;configuration&amp;gt;
    &amp;lt;ojmake&amp;gt;
      C:\Oracle\Middleware\Oracle_Home\jdeveloper\jdev\bin\ojmake.exe
    &amp;lt;/ojmake&amp;gt;
    &amp;lt;files&amp;gt;
      C:\build\FogDash\FogDash.jws
    &amp;lt;/files&amp;gt;
    &amp;lt;usemaven&amp;gt;
      true
    &amp;lt;/usemaven&amp;gt;
  &amp;lt;/configuration&amp;gt;
  &amp;lt;executions&amp;gt;
    &amp;lt;execution&amp;gt;
      &amp;lt;phase&amp;gt;compile&amp;lt;/phase&amp;gt;
      &amp;lt;goals&amp;gt;
        &amp;lt;goal&amp;gt;compile&amp;lt;/goal&amp;gt;
      &amp;lt;/goals&amp;gt;
    &amp;lt;/execution&amp;gt;
  &amp;lt;/executions&amp;gt;
&amp;lt;/plugin&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Es ist aus dem Auszug der POM ersichtlich, dass die absoluten Pfade zu Komplikationen führen werden. Maven unterstützt für diesen Fall Variablen, sodass die Pfade in der POM relativ gesetzt werden können. Dabei können Umgebungsvariablen oder auch spezifische Maven-Variablen genutzt werden. Letztere lassen sich über die globalen Maven-Settings oder User-Settings (settings.xml) vordefinieren.&lt;/p&gt;
&lt;p&gt;Variablen in Maven folgen einem bestimmten Schema:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;${variable_name}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Maven kennt bereits einige vordefinierte Variablen wie &lt;em&gt;${basedir}&lt;/em&gt;. Diese Variable verweist auf das Verzeichnis in der sich die gerade verwendete POM befindet. Zusätzlich zu den vordefinierten Variablen kann Maven auf Umgebungsvariablen des Systems zugreifen. Dies erfolgt über die Synatx:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;${env.variable_name}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Mit diesen Mechanismen besteht also die Möglichkeit, die Pfade für den Maven-Build zu relativieren.&lt;/p&gt;
&lt;p&gt;Für die Build-Tools von Oracle kann vergleichbar bei Oracle-Datenbanken unter Linux (ORACLEHOME) eine Umgebungsvariable namens &lt;strong&gt;OJ_HOME&lt;/strong&gt; erstellt werden, die auf den Pfad &lt;em&gt;C:\Oracle\Middleware\Oracle_Home\jdeveloper\jdev\bin&lt;/em&gt; verweist. Auf diese Variable kann in der pom.xml über* ${env.OJ_HOME}* zugegriffen werden. Damit die Projektdatei FogDash.jws ebenfalls relativ zu den anderen Pfaden steht, wird die Variable &lt;em&gt;${basedir}&lt;/em&gt; genutzt.&lt;/p&gt;
&lt;p&gt;Es besteht die Möglichkeit auch &lt;strong&gt;OJ_HOME&lt;/strong&gt; als Maven-Variable zu definieren, sodass diese dynamisch bei einem Build gesetzt werden kann. Über die settings.xml eines Benutzers könnten sich die Einstellungen somit auch versionieren lassen.&lt;/p&gt;
&lt;p&gt;Die angepasste pom.xml (Auszug) sieht nach den Änderungen wie folgt aus:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;plugin&amp;gt;
  &amp;lt;groupId&amp;gt;com.oracle.adf.plugin&amp;lt;/groupId&amp;gt;
  &amp;lt;artifactId&amp;gt;ojmake&amp;lt;/artifactId&amp;gt;
  &amp;lt;version&amp;gt;12.1.2-0-0&amp;lt;/version&amp;gt;
  &amp;lt;configuration&amp;gt;
    &amp;lt;ojmake&amp;gt;
      ${env.OJ_HOME}\ojmake.exe
    &amp;lt;/ojmake&amp;gt;
    &amp;lt;files&amp;gt;
      ${basedir}\FogDash.jws
    &amp;lt;/files&amp;gt;
    &amp;lt;usemaven&amp;gt;
      true
    &amp;lt;/usemaven&amp;gt;
  &amp;lt;/configuration&amp;gt;
  &amp;lt;executions&amp;gt;
    &amp;lt;execution&amp;gt;
      &amp;lt;phase&amp;gt;compile&amp;lt;/phase&amp;gt;
      &amp;lt;goals&amp;gt;
        &amp;lt;goal&amp;gt;compile&amp;lt;/goal&amp;gt;
      &amp;lt;/goals&amp;gt;
    &amp;lt;/execution&amp;gt;
  &amp;lt;/executions&amp;gt;
&amp;lt;/plugin&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Mit dem JDeveloper 12.1.3 ist dieser Fehler ebenfalls gelöst [4]. Allerdings werden POM von einem mit JDeveloper 12.1.2 erstellen Projekt beim Speichern nicht automatisch angepasst, so dass manuelle Korrekturen unumgänglich sind.&lt;/p&gt;
&lt;h3&gt;Quellen:&lt;/h3&gt;
&lt;p&gt;[1] &lt;a href=&quot;http://docs.oracle.com/middleware/1212/core/MAVEN/config_maven.htm#MAVEN8853&quot;&gt;http://docs.oracle.com/middleware/1212/core/MAVEN/config_maven.htm#MAVEN8853&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[2] &lt;a href=&quot;http://biemond.blogspot.de/2014/06/maven-support-for-1213-service-bus-soa.html&quot;&gt;http://biemond.blogspot.de/2014/06/maven-support-for-1213-service-bus-soa.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[3] &lt;a href=&quot;https://blogs.oracle.com/blueberry/entry/jdeveloper_12c_using_relative_paths&quot;&gt;https://blogs.oracle.com/blueberry/entry/jdeveloper_12c_using_relative_paths&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[4] &lt;a href=&quot;http://www.oracle.com/technetwork/developer-tools/jdev/documentation/1213nf-2222743.html&quot;&gt;http://www.oracle.com/technetwork/developer-tools/jdev/documentation/1213nf-2222743.html&lt;/a&gt;&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>JDeveloper ohne Konsolenfenster starten</title>
      <link>https://kivio.org/blog/entry/2014/06/26/jdeveloper-ohne-konsolenfenster.html</link>
      <pubDate>Thu, 26 Jun 2014 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2014/06/26/jdeveloper-ohne-konsolenfenster.html</guid>
      	<description>
	&lt;p&gt;Nichts ist störender als neben der eigentlichen Anwendung noch ein Konsolenfenster geöffnet zu haben, das außer einer Ausgabe keine weitere Funktion hat. Dieser Post bringt Abhilfe.&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;Wird der JDeveloper unter Windows aus seinem Installationsverzeichnis mit &lt;strong&gt;jdeveloper.exe&lt;/strong&gt; gestartet, so öffnet sich im Hintergrund immer die Windows-Kommandozeile. Dies ist insofern praktisch, wenn man als Entwickler Crash-Meldungen im JDeveloper nachvollziehen möchte. Auf Dauer kann dies allerdings eher störend als hilfreich sein. Mit diesem einfachen Trick verschwindet das störende, zusätzliche Fenster.&lt;/p&gt;
&lt;p&gt;Im Unterverzeihnis &lt;strong&gt;jdev\bin&lt;/strong&gt; des Installationsverzeichnisses vom JDeveloper befinden sich plattformspezifische EXE-Dateien wie jdev.exe, jdev64.exe, jdevW.exe, jdev64W.exe.&lt;/p&gt;
&lt;p&gt;Wie bei jeder Java-Anwendung können die mit dem Postfix &lt;strong&gt;W&lt;/strong&gt; versehenen Binaries genutzt werden, um die Java Runtime ohne Konsolenfenster zu starten. Auf einem 64-Bit Windows kann der JDeveloper über jdev64W.exe ohne Konsolenfenster gestartet werden.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>Wix Toolset plugin 1.5 for Jenkins released</title>
      <link>https://kivio.org/blog/entry/2014/06/25/wix-toolset-plugin-1-5.html</link>
      <pubDate>Wed, 25 Jun 2014 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2014/06/25/wix-toolset-plugin-1-5.html</guid>
      	<description>
	&lt;p&gt;A new version of Wix Toolset plugin was released today. The new version will be automatically available via Jenkins update manager in a few hours. This announcement describes the latest changes.&lt;/p&gt;
&lt;!--more--&gt;
&lt;h2&gt;Changes between Wix Toolset plugin 1.4 and 1.5&lt;/h2&gt;
&lt;h3&gt;&lt;a href=&quot;https://github.com/jenkinsci/wix-plugin/blob/master/CHANGELOG.md#define-msi-package-name&quot;&gt;Define MSI package name&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;It is now possible to define a filename for the MSI package. If this &lt;em&gt;Advanced Setting&lt;/em&gt; is left blank the MSI package name defaults to &lt;em&gt;setup.msi&lt;/em&gt;. Environment variables (as long as defined) are expanded to their value. A package name like setup-${BUILD_NUMBER}.msi results for e.g. to setup-40.msi.&lt;/p&gt;
&lt;h3&gt;&lt;a href=&quot;https://github.com/jenkinsci/wix-plugin/blob/master/CHANGELOG.md#define-defaults-for-architecture&quot;&gt;Define defaults for architecture&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Set architecture defaults for package, components, etc. values=x86, x64, or ia64 (default=x86)&lt;/p&gt;
&lt;h3&gt;&lt;a href=&quot;https://github.com/jenkinsci/wix-plugin/blob/master/CHANGELOG.md#minor-changes&quot;&gt;Minor changes&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;On the system configuration page the plugin is now called Wix Toolset instead of Windows Installer Builder.&lt;/li&gt;
&lt;li&gt;Extended validation of installation directory. Checks now if directory contains compiler candle.exe und linker light.exe.&lt;/li&gt;
&lt;li&gt;English and german messages depending on your system settings.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A complete list of all changes is available at &lt;a href=&quot;https://github.com/jenkinsci/wix-plugin/blob/master/CHANGELOG.md&quot;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>WiX Plugin 1.4 for Jenkins released</title>
      <link>https://kivio.org/blog/entry/2014/06/20/wix-plugin-1-4-for.html</link>
      <pubDate>Fri, 20 Jun 2014 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2014/06/20/wix-plugin-1-4-for.html</guid>
      	<description>
	&lt;p&gt;Today I released a new version of the WiX plugin for Jenkins. This announcement describes the changes between the current and the former 1.3 release. The new version will be available on Jenkins update manager in a few hours.&lt;/p&gt;
&lt;!--more--&gt;
&lt;h3&gt;Changes&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Ant-style source pattern:&lt;/strong&gt; You can now define Ant-style source pattern instead of using the fully name of a source file. While using a source pattern it is now possible for Wix plugin to compile more than one source file into a single &lt;em&gt;wixobj&lt;/em&gt;-file. Simply use a pattern like *&lt;em&gt;&lt;em&gt;/&lt;/em&gt;.wxs&lt;/em&gt; to compile all available WiX source scripts.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Environment variables:&lt;/strong&gt; Defined environment variables in a build job are now passed as parameters to WiX Compiler (candle.exe) and WiX Linker (light.exe). This feature has severals restrictions. Environment variables containing pathes and illegal characters are not passed as parameters.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Refactoring:&lt;/strong&gt; A lot of code was rewritten for a better performance and easier code extension.&lt;/li&gt;
&lt;/ol&gt;

	</description>
    </item>
    <item>
      <title>Downgrade Jenkins Git Plugin</title>
      <link>https://kivio.org/blog/entry/2014/05/15/downgrade-jenkins-git-plugin.html</link>
      <pubDate>Thu, 15 May 2014 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2014/05/15/downgrade-jenkins-git-plugin.html</guid>
      	<description>
	&lt;p&gt;If you also encounter problems with Jenkins&amp;rsquo; Git plugin I tell you in this post how you can manually downgrade the plugin to a prior version. &lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;Many users on the mailing list of Jenkins encounter massive problems and missing features with the new Jenkins Git plugin since version 2.0. Very significant problems relate to the check mechanism for changes in sub-directories or the missing expansion of environment variables. These are all features you get back if you migrate to version 1.5.0. Here is the guide how to do it.&lt;/p&gt;
&lt;p&gt;To avoid side effects while downgrading the needed plugins, stop your standalone Jenkins server or the web container Jenkins is running in. Follow these steps:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Change to the plugins directory of Jenkins and remove the following files and directories= &lt;strong&gt;git-client.jpi, git-client, git.jpi, git&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Download git-client 1.9.0 and git 1.5.0 directly from Jenkins Update server and copy the files &lt;strong&gt;git-client.hpi&lt;/strong&gt; and &lt;strong&gt;git.hpi&lt;/strong&gt; into the plugins directory or use the upload feature in Jenkins. See attached Links at the end of the article for the right URLs to get the new plugins.&lt;/li&gt;
&lt;li&gt;Fire Jenkins up.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;After Jenkins is started, you have to reconfigure all your jobs using Git repositories. The section in config.xml for Git has changed in Git plugin 2.0 which is not compatible with prior versions. To ease up work on configurations change every line in &lt;strong&gt;config.xml&lt;/strong&gt; from &lt;strong&gt;&lt;a href=&quot;&amp;#109;a&amp;#105;&amp;#x6c;&amp;#x74;&amp;#x6f;&amp;#x3a;&amp;#103;&amp;#x69;&amp;#x74;@&amp;#50;&amp;#x2e;&amp;#50;.&amp;#49;&quot;&gt;&amp;#103;&amp;#105;t&amp;#64;2&amp;#x2e;&amp;#50;&amp;#x2e;&amp;#x31;&lt;/a&gt;&lt;/strong&gt; to &lt;strong&gt;&lt;a href=&quot;&amp;#109;&amp;#97;i&amp;#x6c;&amp;#x74;o&amp;#58;&amp;#x67;&amp;#x69;&amp;#116;&amp;#64;&amp;#49;&amp;#46;&amp;#53;&amp;#x2e;&amp;#x30;&quot;&gt;&amp;#103;&amp;#105;&amp;#116;&amp;#64;&amp;#x31;&amp;#46;&amp;#53;&amp;#46;&amp;#x30;&lt;/a&gt;&lt;/strong&gt; as shown below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;scm class=&amp;quot;hudson.plugins.git.GitSCM&amp;quot; plugin=&amp;quot;git@2.2.1&amp;quot;
scm class=&amp;quot;hudson.plugins.git.GitSCM&amp;quot; plugin=&amp;quot;git@1.5.0&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After changing these values your repository URLs are restored and most of the global settings. Specific settings like &amp;ldquo;Included Regions&amp;rdquo; or subdirectories for Checkout must be added manually.&lt;/p&gt;
&lt;p&gt;The changes take effect if you select the option &lt;strong&gt;Load configuration from disk&lt;/strong&gt; on &lt;strong&gt;Manage Jenkins&lt;/strong&gt;.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>Windows mit VirtualBox unter OS X Mavericks virtualisieren</title>
      <link>https://kivio.org/blog/entry/2014/04/21/virtualbox-osx-und-windows.html</link>
      <pubDate>Mon, 21 Apr 2014 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2014/04/21/virtualbox-osx-und-windows.html</guid>
      	<description>
	&lt;p&gt;Tests unter OS X Mavericks haben gezeigt, dass sich Windows-Systeme unter dem neuen Betriebssystem von Apple nicht mit VirtualBox virtualisieren lassen. Details zu meinem Test finden sich in diesem Posting.&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;Durchsucht man das Internet nach einem Hypervisor zur Virtualisierung eines Rechners unter OS X trifft man meist auf die drei Vertreter VMware Fusion, Parallels Desktop und Oracle Virtualbox. In vielen Foren und Artikeln wird Virtualbox bevorzugt, da das Programm kostenlos ist und stabil läuft.&lt;/p&gt;
&lt;p&gt;Leider trifft dies nicht auf alle Anwendungsfälle zu. An dieser Stelle ein Überblick, wann Virtualbox der richtige Hypervisor ist.&lt;/p&gt;
&lt;p&gt;Im Test kam Virtualbox 4.3.10 mit dem entsprechenden Extension Pack zum Einsatz. Die Hardware ist ein MacBook Pro mid 2010 mit 8 GB RAM und OS X 10.9.2 installiert. Installiert wurden die folgenden Betriebssysteme:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Oracle Linux Server 6.5.0 (64-Bit)&lt;/li&gt;
&lt;li&gt;Raspbian Wheezy (32-Bit)&lt;/li&gt;
&lt;li&gt;Windows 7 (32-Bit)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Linux-Systeme lassen sich problemlos unter Virtualbox installieren. Es sollte darauf geachtet werden, dass die Kernel Header Sourcen auf dem System verfügbar sind, ansonsten können die Virtualbox Additions nicht die entsprechenden Kernel-Module bauen.&lt;/p&gt;
&lt;p&gt;Leider funktioniert Virtualbox nur leidlich mit einem virtualisierten Windows-System.&lt;/p&gt;
&lt;p&gt;Die Installation geht zügig vonstatten. Allerdings wurde bei der ersten Installation eine Kernel panic in OS X erzeugt. Nach einer erneuten Installation von Windows 7 lief das System zunächst stabil. Allerdings stürzte es später beim Windows Update ab.&lt;/p&gt;
&lt;p&gt;Eine Suche in den Foren von Virtualbox und Apple hat ergeben, dass es scheinbar zu &lt;a href=&quot;https://discussions.apple.com/thread/5287447?start=15&amp;amp;tstart=0&quot;&gt;Problemen mit dem Treiber für die Grafikkarte&lt;/a&gt; kommt und dadurch eine Kernel panic erzeugt wird.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Fazit des Tests:&lt;/strong&gt; Für den Einsatz von virtualisierten Windows-Maschinen sollte auf VMware Fusion oder Parallels Desktop zurückgegriffen werden. Wer nur unixoide Systeme unter Virtualbox unter OS X virtualisieren will, sollte auf jeden Fall einen Blick auf Virtualbox werfen.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>Deploying GitBlit on JBoss/Wildfly</title>
      <link>https://kivio.org/blog/entry/2014/03/20/deploying-gitblit-on-jboss-wildfly.html</link>
      <pubDate>Thu, 20 Mar 2014 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2014/03/20/deploying-gitblit-on-jboss-wildfly.html</guid>
      	<description>
	&lt;p&gt;If you want to use GitBlit on a JBoss/Wildfly-based Java EE application server, deployment is a little bit tricky. This guide describes how you can deploy GitBlit with ease on JBoss/Wildfly.&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; In this detailed description I will always use Wildfly as synonym for Wildfly and JBoss servers. At the end of the article we will have a look at the special settings for Wildfly on Windows. The* gitblit-1.4.0.war* was renamed to &lt;em&gt;gitblit.war&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;GitBlit can be configured over its &lt;a href=&quot;http://gitblit.com/setup_war.html&quot; title=&quot;Setup documentation of GitBlit&quot;&gt;depoyment descriptor web.xml&lt;/a&gt; to use a persistent directory for its configuration files. This will also help to keep configuration if newer versions of GitBlit are deployed to Wildfly. But if you place your gitblit.war into the deployments directory of Wildfly, the deployed archive is not persistent. If you modify the web.xml and set the** env-entry** for the &lt;strong&gt;baseFolder&lt;/strong&gt; it is overwritten after redeployment.&lt;/p&gt;
&lt;p&gt;See example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;env-entry&amp;gt;
	&amp;lt;description&amp;gt;The base folder is used to specify the root location of your Gitblit data.&amp;lt;/description&amp;gt;
	&amp;lt;env-entry-name&amp;gt;baseFolder&amp;lt;/env-entry-name&amp;gt;
	&amp;lt;env-entry-type&amp;gt;java.lang.String&amp;lt;/env-entry-type&amp;gt;
	&amp;lt;env-entry-value&amp;gt;/opt/gitblit/cfg&amp;lt;/env-entry-value&amp;gt;
&amp;lt;/env-entry&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For further reading, I define GitBlit&amp;rsquo;s &lt;strong&gt;baseFolder&lt;/strong&gt; as &lt;em&gt;/opt/gitblit/cfg&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Therefore Wildfly does not allow or has a mechanism to reset environment entries with runtime settings, the solution to deploy GitBlit or any other web application with environment entries, is to define a &lt;a href=&quot;https://docs.jboss.org/author/display/WFLY8/Deployment+Overlays?_sscc=t&quot; title=&quot;JBoss documentation=Deployment Overlays&quot;&gt;deployment overlay&lt;/a&gt;. The Wildfly documentation states=&amp;ldquo;Deployment overlays are our way of &amp;lsquo;overlaying&amp;rsquo; content into an existing deployment, without physically modifying the contents of the deployment archive. Possible use cases include swapping out deployment descriptors, modifying static web resources to change the branding of an application, or even replacing jar libraries with different versions.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;Follow these steps to create your own deployment overlay for GitBlit and redeploy the web archive again:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Ensure your new configuration directory for GitBlit exists.&lt;/li&gt;
&lt;li&gt;Deploy GitBlit while copying the &lt;em&gt;gitblit.war&lt;/em&gt; to the Folder deployments under domain or standalone depending on the mode you drive Wildfly.&lt;/li&gt;
&lt;li&gt;After the archive is deployed, change to the extracted files under &lt;em&gt;tmp/vfs&lt;/em&gt;. For e.g.* tmp/vfs/temp/tempfa47ccfd18779c0f/gitblit.war-47947744fb40cde3*.&lt;/li&gt;
&lt;li&gt;Copy the file &lt;em&gt;WEB-INF/web.xml&lt;/em&gt; to &lt;em&gt;/opt/gitblit/web.xml&lt;/em&gt; or to your desired directory.&lt;/li&gt;
&lt;li&gt;Modify the copied &lt;em&gt;web.xml&lt;/em&gt; and change the &lt;strong&gt;env-entry-value&lt;/strong&gt; to your folder you expect the gitblit configuration to reside. In this example the value is changed to &lt;em&gt;/opt/gitblit/cfg&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Now comes the complicated part. You have to use the Wildfly command line interface to define your deployment overlay for GitBlit. Start Wildfly command line interface on the server with &lt;strong&gt;jboss-cli.sh -c&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Execute the following command (change parameters as needed):&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;deployment-overlay add --name=GitBlitOverlay --content=/WEB-INF/web.xml=/opt/gitblit/web.xml --deployments=gitblit.war --redeploy-affected.
&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;
&lt;li&gt;The overlay is created and the archive is deployed once again. GitBlit copies its &lt;em&gt;gitblit.properties&lt;/em&gt; and other files to the newly created directory &lt;em&gt;/opt/gitblit/cfg&lt;/em&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Now you can configure GitBlit as needed and your configuration is saved.&lt;/p&gt;
&lt;h3&gt;For Windows Users:&lt;/h3&gt;
&lt;p&gt;The jboss-cli on Windows behaves very strange. If you define an overlay on Windows, make sure you are on the top of the drive your newly created directory lives. Executed then the command line interface of Wildfly on root level:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd \
C:\wildfly\bin\jboss-cli.bat -c
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Execute the command from step 7 with relative path. Don&amp;rsquo;t use a drive letter.&lt;/p&gt;

	</description>
    </item>
    <item>
      <title>JNI - Exception-Handling unter Windows</title>
      <link>https://kivio.org/blog/entry/2010/07/13/jni-exception-handling.html</link>
      <pubDate>Tue, 13 Jul 2010 00:00:00 +0000</pubDate>
      <guid isPermaLink="false">blog/entry/2010/07/13/jni-exception-handling.html</guid>
      	<description>
	&lt;p&gt;Um Exceptions aus einem JNI-Interface abzufangen und strukturiert behandeln zu können, sind ein paar zusätzliche Handgriffe notwendig. Dieses Post gibt einen kurzen Einblick über die Fallstricke und wie sie umgangen werden können.&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;Bei der Programmierung mit dem Java Native Interface und dem Aufruf von Windows API-Funktionen bin ich auf Probleme gestoßen eine Exception abzufangen. Ein Try-Catch-Block war innerhalb von JNI nicht wirklich hilfreich.&lt;/p&gt;
&lt;p&gt;Will man in C++ eine Exception abfangen, so definiert man meist einen  Try-Catch-Block. Faule Programmierer schreiben dabei meist  eine Anweisung wie:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;try {
	// Eigentlich auszuführender  Funktionsrumpf
} catch(...) {
	// Irgendwie den Fehler behandeln
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Das funktioniert so lange gut, wie es sich um Ausnahmen in der eigenen Software handelt. Wird JNI zu Hilfe genommen, um z.B. mittels  Java Zugriff auf native API-Funktionen des Betriebssystems zu erlangen, dann stößt dieser Mechanismus an seine Grenzen und das Programm kann  diesen Fehler bzw. diese Ausnahme nicht behandeln.&lt;/p&gt;
&lt;h2&gt;Windows-Mechanismus für Ausnahmen&lt;/h2&gt;
&lt;p&gt;Unter Windows wird der mechanismus für die Behandlung von Software- und Hadrware-Ausnahmen als &lt;strong&gt;Structured Exception Handling&lt;/strong&gt; (SEH) bezeichnet. Diese stackframe-basierte Ausnahmebehandlung kann mit dem Exceptionhandling in C++ bzw. Java verglichen werden, nutzt aber innerhalb von C++ die Schlüsselwörter __try und __except. Mit diesen Schlüsselwörtern kann man den Codeblock einschließen, bei denen man eine Exception erwartet. Bei der Programmierung mit JNI, sollte man dementsprechend alle Codeblöcke, die einen nativen Call an die Windows  API machen, mit diesem Block-Fragment umschließen:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;__try {
	// Code
} __except(expression) {
	// Ausnahmebehandlung
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Als &lt;em&gt;expression&lt;/em&gt; können die folgenden Werte angegeben werden: &lt;strong&gt;EXCEPTION_CONTINUE_EXECUTION (-1)&lt;/strong&gt; Der Handler hat für die  Ausnahmebehandlung gesorgt und nicht der __except-Block.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;EXCEPTION_CONTINUE_SEARCH (0)&lt;/strong&gt; Der gerade aufgerufene  Handler kann die Ausnahme nicht behandeln und es wird auf den nächsten Handler gewartet bzw. danach gesucht. Diese Anweisung kann unter C++ / Java mit dem Umstand beschrieben werden, dass in einem Catch-Block eine Exception aufgetreten ist, die nicht durch den Block abgefangen wird.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;EXCEPTION_EXECUTE_HANDLER (1)&lt;/strong&gt; Der __except-Block wird  ausgeführt.&lt;/p&gt;
&lt;p&gt;Unter Windows sind die Konsole-Events und die Applikations-Threads asynchron. Die C-Runtime-Bibliothek ist dafür zuständig die auf der Konsole auftretenden Ereignisse mit den Windows-Ausnahmen zu gültigen Signalen zu vereinen. Bei der Softwareentwicklung mittels JNI, sollten also alle Windows API-Aufrufe in einen __try und __except-Block gepackt werden, damit fehlerhafte Aufrufe an die API abgefangen werden können und an die höher gelegenen Schichten wie die Konsole oder die Java-Anwendung (in Form  einer Exception) weiter gereicht werden können.&lt;/p&gt;

	</description>
    </item>

  </channel> 
</rss>
